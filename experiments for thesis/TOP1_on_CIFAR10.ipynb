{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ3X0yMFxZh4",
        "outputId": "b63186a0-267b-433c-d06e-04e44c9a67ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: CUDA\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Imports\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on device:\", DEVICE.upper())\n",
        "\n",
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR 10 dataset\n",
        "\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=normalize\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHs32YODxsE2",
        "outputId": "a3ea40f0-9d58-45ec-8fbc-0c67c7a9c975"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 49219286.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose random forget indecies from some class\n",
        "# Index of class\n",
        "class_index = 1 # cars\n",
        "class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "# Percantage of whole data ( from class )\n",
        "amount = 0.01 # 1 %\n",
        "amount_int = class_set.shape[0] * amount\n",
        "\n",
        "# Get indeces\n",
        "forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "# construct indices of retain from those of the forget set\n",
        "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "forget_mask[forget_idx] = True\n",
        "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "# split train set into a forget and a retain set\n",
        "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "# Generate forget and retain loaders\n",
        "forget_loader = torch.utils.data.DataLoader(\n",
        "    forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")\n",
        "retain_loader = torch.utils.data.DataLoader(\n",
        "    retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")"
      ],
      "metadata": {
        "id": "MuxSsnuaxuwo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add helping dicts\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": test_loader\n",
        "}\n",
        "\n",
        "dataset_sizes = {\"train\": len(train_set), \"val\": len(test_set)}"
      ],
      "metadata": {
        "id": "7D0yRMAYxyGA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(DEVICE)\n",
        "                    labels = labels.to(DEVICE)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model"
      ],
      "metadata": {
        "id": "FE71oSTZxzw0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train ResNet18\n",
        "\n",
        "model_train = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_train = model_train.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_train.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "W7itE9Hnx2xy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model_train = train_model(model_train, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SWnxyUvx4tn",
        "outputId": "023af233-87e2-49c2-beb8-f40ffef1432a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 1.3764 Acc: 0.5047\n",
            "val Loss: 1.1465 Acc: 0.5994\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.9597 Acc: 0.6594\n",
            "val Loss: 1.0416 Acc: 0.6310\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.7674 Acc: 0.7301\n",
            "val Loss: 1.0298 Acc: 0.6574\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.6471 Acc: 0.7721\n",
            "val Loss: 0.9014 Acc: 0.7001\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.5345 Acc: 0.8139\n",
            "val Loss: 0.9791 Acc: 0.6847\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.4418 Acc: 0.8452\n",
            "val Loss: 0.8407 Acc: 0.7266\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.3573 Acc: 0.8747\n",
            "val Loss: 0.8878 Acc: 0.7209\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.1505 Acc: 0.9553\n",
            "val Loss: 0.7803 Acc: 0.7688\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.0763 Acc: 0.9808\n",
            "val Loss: 0.8576 Acc: 0.7680\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.0448 Acc: 0.9904\n",
            "val Loss: 0.9417 Acc: 0.7685\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.0250 Acc: 0.9955\n",
            "val Loss: 1.0656 Acc: 0.7657\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.0133 Acc: 0.9979\n",
            "val Loss: 1.1865 Acc: 0.7654\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.0076 Acc: 0.9990\n",
            "val Loss: 1.3072 Acc: 0.7625\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.0046 Acc: 0.9994\n",
            "val Loss: 1.3864 Acc: 0.7628\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.0027 Acc: 0.9998\n",
            "val Loss: 1.3967 Acc: 0.7633\n",
            "\n",
            "Training complete in 5m 18s\n",
            "Best val Acc: 0.768800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model weights\n",
        "torch.save(model_train.state_dict(), \"model_train_params.pt\")\n",
        "# Save model weights\n",
        "torch.save(model_train.state_dict(), \"model_train_params_resnet18_cifar10.pt\")"
      ],
      "metadata": {
        "id": "VjZAqGDyx6_2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def accuracy(net, loader):\n",
        "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "print(f\"Train set accuracy: {100.0 * accuracy(model_train, train_loader):0.1f}%\")\n",
        "print(f\"Test set accuracy: {100.0 * accuracy(model_train, test_loader):0.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY9rVDrnzJNW",
        "outputId": "58daf66e-ca27-473d-ad1f-d5726fbed335"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 98.3%\n",
            "Test set accuracy: 76.9%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts,StepLR\n",
        "def kl_loss_sym(x,y):\n",
        "    kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
        "    return kl_loss(nn.LogSoftmax(dim=-1)(x),y)\n",
        "\n",
        "def unlearning(\n",
        "        net,\n",
        "        retain_loader,\n",
        "        forget_loader,\n",
        "        val_loader,\n",
        "):\n",
        "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
        "    print('-----------------------------------')\n",
        "    epochs = 8\n",
        "    retain_bs = 256\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.005,\n",
        "                          momentum=0.9, weight_decay=0)\n",
        "    optimizer_retain = optim.SGD(net.parameters(), lr=0.001*retain_bs/64, momentum=0.9, weight_decay=1e-2)\n",
        "    ##the learning rate is associated with the batchsize we used\n",
        "    optimizer_forget = optim.SGD(net.parameters(), lr=3e-4, momentum=0.9, weight_decay=0)\n",
        "    total_step = int(len(forget_loader)*epochs)\n",
        "    retain_ld = DataLoader(retain_loader.dataset, batch_size=retain_bs, shuffle=True)\n",
        "    retain_ld4fgt = DataLoader(retain_loader.dataset, batch_size=256, shuffle=True)\n",
        "    scheduler = CosineAnnealingLR(optimizer_forget, T_max=total_step, eta_min=1e-6)\n",
        "\n",
        "    net.train()\n",
        "    for sample in forget_loader: ##First Stage\n",
        "        inputs, output = sample\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        uniform_label = torch.ones_like(outputs).to(DEVICE) / outputs.shape[1] ##uniform pseudo label\n",
        "        loss = kl_loss_sym(outputs, uniform_label) ##optimize the distance between logits and pseudo labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    net.train()\n",
        "    for ep in range(epochs): ##Second Stage\n",
        "        net.train()\n",
        "        for sample_forget, sample_retain in zip(forget_loader, retain_ld4fgt):##Forget Round\n",
        "            t = 1.15 ##temperature coefficient\n",
        "            inputs_forget,inputs_retain = sample_forget[0],sample_retain[0]\n",
        "            inputs_forget, inputs_retain = inputs_forget.to(DEVICE), inputs_retain.to(DEVICE)\n",
        "            optimizer_forget.zero_grad()\n",
        "            outputs_forget,outputs_retain = net(inputs_forget),net(inputs_retain).detach()\n",
        "            loss = (-1 * nn.LogSoftmax(dim=-1)(outputs_forget @ outputs_retain.T/t)).mean() ##Contrastive Learning loss\n",
        "            loss.backward()\n",
        "            optimizer_forget.step()\n",
        "            scheduler.step()\n",
        "        for sample in retain_ld: ##Retain Round\n",
        "            inputs, labels = sample\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer_retain.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer_retain.step()\n",
        "\n",
        "    print('-----------------------------------')\n",
        "    return net"
      ],
      "metadata": {
        "id": "BhS8wXEmzQD-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define model from trained params\n",
        "\n",
        "model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_forget_ft.load_state_dict(torch.load(\"model_train_params.pt\"))\n",
        "model_forget_ft.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxd3SAEI0Kuj",
        "outputId": "4c4d8c6b-732c-4158-9202-4b23e85688e5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unlearn model\n",
        "%%time\n",
        "model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7xkfLb80MvL",
        "outputId": "4aeaef34-733e-45e4-ec51-ad6cf142bce2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n",
            "-----------------------------------\n",
            "CPU times: user 2min 12s, sys: 998 ms, total: 2min 13s\n",
            "Wall time: 2min 15s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compare accuracy\n",
        "print(f\"Retain set accuracy: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "print(f\"Test set accuracy: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEV71Ber0PhA",
        "outputId": "7584d41a-91d8-4c38-b9ed-269184467e8a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_losses(net, loader):\n",
        "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    all_losses = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        logits = net(inputs)\n",
        "        losses = criterion(logits, targets).numpy(force=True)\n",
        "        for l in losses:\n",
        "            all_losses.append(l)\n",
        "\n",
        "    return np.array(all_losses)\n",
        "\n",
        "\n",
        "train_losses = compute_losses(model_train, train_loader)\n",
        "test_losses = compute_losses(model_train, test_loader)"
      ],
      "metadata": {
        "id": "KkpeMq4X5tEa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_mia(sample_loss, members, n_splits=10, random_state=0):\n",
        "    \"\"\"Computes cross-validation score of a membership inference attack.\n",
        "\n",
        "    Args:\n",
        "      sample_loss : array_like of shape (n,).\n",
        "        objective function evaluated on n samples.\n",
        "      members : array_like of shape (n,),\n",
        "        whether a sample was used for training.\n",
        "      n_splits: int\n",
        "        number of splits to use in the cross-validation.\n",
        "    Returns:\n",
        "      scores : array_like of size (n_splits,)\n",
        "    \"\"\"\n",
        "\n",
        "    unique_members = np.unique(members)\n",
        "    if not np.all(unique_members == np.array([0, 1])):\n",
        "        raise ValueError(\"members should only have 0 and 1s\")\n",
        "\n",
        "    attack_model = linear_model.LogisticRegression()\n",
        "    cv = model_selection.StratifiedShuffleSplit(\n",
        "        n_splits=n_splits, random_state=random_state\n",
        "    )\n",
        "    return model_selection.cross_val_score(\n",
        "        attack_model, sample_loss, members, cv=cv, scoring=\"accuracy\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "D4rXeJ-s52iI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN MODEL\n",
        "# Get random test samples\n",
        "randomize = np.arange(len(test_losses))\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Compute forget losses on train dataset\n",
        "forget_losses = compute_losses(model_train, forget_loader)\n",
        "\n",
        "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "test_losses = test_losses[randomize][: len(forget_losses)]\n",
        "\n",
        "samples_mia = np.concatenate((test_losses, forget_losses)).reshape((-1, 1))\n",
        "labels_mia = [0] * len(test_losses) + [1] * len(forget_losses)\n",
        "\n",
        "mia_scores = simple_mia(samples_mia, labels_mia)\n",
        "\n",
        "print(\n",
        "    f\"The MIA has an accuracy of {mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-OnoUXc582D",
        "outputId": "7d0e2d4e-16f1-4236-8158-559f9225a32d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIA has an accuracy of 0.710 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FORGET MODEL\n",
        "\n",
        "# Compute forget losses for forget model\n",
        "forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "# make sure we have a balanced dataset for the MIA\n",
        "samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "\n",
        "print(\n",
        "    f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3yOUYi96Auj",
        "outputId": "783cb59f-4c5a-4783-f437-65856d0dd7ba"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIA has an accuracy of 0.810 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "ax1.set_title(f\"Pre-trained model.\\nAttack accuracy: {mia_scores.mean():0.2f}\")\n",
        "ax1.hist(test_losses, density=True, alpha=0.5, bins=5, label=\"Test set\")\n",
        "ax1.hist(forget_losses, density=True, alpha=0.5, bins=5, label=\"Forget set\")\n",
        "\n",
        "ax2.set_title(\n",
        "    f\"Unlearned by fine-tuning.\\nAttack accuracy: {mia_scores_fr.mean():0.2f}\"\n",
        ")\n",
        "ax2.hist(test_losses_fr, density=True, alpha=0.5, bins=5, label=\"Test set\")\n",
        "ax2.hist(forget_losses_fr, density=True, alpha=0.5, bins=5, label=\"Forget set\")\n",
        "\n",
        "ax1.set_xlabel(\"Loss\")\n",
        "ax2.set_xlabel(\"Loss\")\n",
        "ax1.set_ylabel(\"Frequency\")\n",
        "ax1.set_yscale(\"log\")\n",
        "ax2.set_yscale(\"log\")\n",
        "ax1.set_xlim((0, np.max(test_losses)))\n",
        "ax2.set_xlim((0, np.max(test_losses)))\n",
        "for ax in (ax1, ax2):\n",
        "    ax.spines[\"top\"].set_visible(False)\n",
        "    ax.spines[\"right\"].set_visible(False)\n",
        "ax1.legend(frameon=False, fontsize=14)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "U3RQAq-X6CuJ",
        "outputId": "c7219f4f-94d8-4ef8-f784-e608b4a3fd70"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ResNet18\n",
        "\n",
        "model_retain_ds = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_retain_ds = model_retain_ds.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_retain_ds.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "uPGJVwnQ6IRF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add helping dicts\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": retain_loader,\n",
        "    \"val\": test_loader\n",
        "}\n",
        "\n",
        "dataset_sizes = {\"train\": len(retain_set), \"val\": len(test_set)}\n",
        "\n",
        "# Train model\n",
        "model_retain_ds = train_model(model_retain_ds, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOGN0gge6OgF",
        "outputId": "5651245b-cac2-41f9-fbce-238e3845dd77"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 1.3737 Acc: 0.5055\n",
            "val Loss: 1.2962 Acc: 0.5442\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.9853 Acc: 0.6497\n",
            "val Loss: 1.0237 Acc: 0.6413\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.8054 Acc: 0.7131\n",
            "val Loss: 0.9900 Acc: 0.6651\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.6751 Acc: 0.7614\n",
            "val Loss: 0.9043 Acc: 0.6939\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.5648 Acc: 0.8004\n",
            "val Loss: 0.8196 Acc: 0.7239\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.4813 Acc: 0.8315\n",
            "val Loss: 0.8998 Acc: 0.7169\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.3935 Acc: 0.8605\n",
            "val Loss: 0.9093 Acc: 0.7240\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.1685 Acc: 0.9465\n",
            "val Loss: 0.8005 Acc: 0.7674\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.0910 Acc: 0.9743\n",
            "val Loss: 0.8670 Acc: 0.7680\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.0551 Acc: 0.9860\n",
            "val Loss: 0.9562 Acc: 0.7660\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.0349 Acc: 0.9922\n",
            "val Loss: 1.0740 Acc: 0.7634\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.0183 Acc: 0.9970\n",
            "val Loss: 1.1763 Acc: 0.7633\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.0101 Acc: 0.9984\n",
            "val Loss: 1.3107 Acc: 0.7600\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.0098 Acc: 0.9981\n",
            "val Loss: 1.4172 Acc: 0.7554\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.0046 Acc: 0.9995\n",
            "val Loss: 1.4239 Acc: 0.7582\n",
            "\n",
            "Training complete in 5m 27s\n",
            "Best val Acc: 0.768000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model weights\n",
        "torch.save(model_retain_ds.state_dict(), \"model_retrain_params_resnet18_cifar10.pt\")"
      ],
      "metadata": {
        "id": "AN4MHoIm6S84"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# MIA attack on retain model\n",
        "\n",
        "# Compute forget losses for forget model\n",
        "forget_losses_rt = compute_losses(model_retain_ds, forget_loader)\n",
        "test_losses_rt = compute_losses(model_retain_ds, test_loader)\n",
        "\n",
        "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "test_losses_rt = test_losses_rt[randomize][: len(forget_losses)]\n",
        "\n",
        "# make sure we have a balanced dataset for the MIA\n",
        "samples_mia_rt = np.concatenate((test_losses_rt, forget_losses_rt)).reshape((-1, 1))\n",
        "labels_mia_rt = [0] * len(test_losses_rt) + [1] * len(forget_losses_rt)\n",
        "\n",
        "mia_scores_rt = simple_mia(samples_mia_rt, labels_mia_rt)\n",
        "\n",
        "print(\n",
        "    f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji2eYmJH6P4-",
        "outputId": "88fb493f-3ddb-46a3-9700-f0dc082e425b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIA has an accuracy of 0.810 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "AD = np.linalg.norm(forget_losses_fr-forget_losses_rt)"
      ],
      "metadata": {
        "id": "MyjZdZcI78Gj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW2TC-rv8DJi",
        "outputId": "b65f6271-06ec-43d6-d5e4-e9d017394c13"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.1726"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.01 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeeiTyBX8FKx",
        "outputId": "cdf6d0ed-5dfd-4a93-a6ae-3d23a94a2e8d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 75.8%\n",
            "The MIA has an accuracy of 0.870 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.630 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.830 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 76.2%\n",
            "The MIA has an accuracy of 0.840 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 76.3%\n",
            "The MIA has an accuracy of 0.840 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.1%\n",
            "The MIA has an accuracy of 0.750 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.890 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.7%\n",
            "The MIA has an accuracy of 0.820 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 76.0%\n",
            "The MIA has an accuracy of 0.770 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 75.7%\n",
            "The MIA has an accuracy of 0.780 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR-3Ciez8UFz",
        "outputId": "753f1d28-039c-4f9e-bcce-e6b65f6b3f9c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8700000000000001, 0.6299999999999999, 0.8300000000000001, 0.8399999999999999, 0.8400000000000001, 0.75, 0.89, 0.8200000000000001, 0.7700000000000001, 0.78]\n",
            "[99.83583912233989, 99.88188188188188, 99.84584584584584, 99.7917917917918, 99.81581950311305, 99.87187187187187, 99.86786786786787, 99.85986266541211, 99.84985285579869, 99.77377377377378]\n",
            "[75.88000000000001, 75.94, 76.35, 76.08, 76.35, 75.67, 75.66000000000001, 75.99000000000001, 75.56, 75.81]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)"
      ],
      "metadata": {
        "id": "Ej1jtZwhCBoM"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvNUFJIKCDHk",
        "outputId": "f321e2bc-1626-473f-eead-9ffeb1e4c85a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8019999999999999\n",
            "99.83944071796968\n",
            "75.929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation 2 %\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.02 # 2 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GPBxmX9CEbD",
        "outputId": "5682a9ae-07b7-4c5f-dab7-0796fe0cdace"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.913 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.8%\n",
            "The MIA has an accuracy of 0.847 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 75.4%\n",
            "The MIA has an accuracy of 0.900 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.847 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 76.0%\n",
            "The MIA has an accuracy of 0.867 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.1%\n",
            "The MIA has an accuracy of 0.853 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.7%\n",
            "Test set accuracy: 75.5%\n",
            "The MIA has an accuracy of 0.860 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.0%\n",
            "The MIA has an accuracy of 0.873 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.7%\n",
            "The MIA has an accuracy of 0.913 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.0%\n",
            "The MIA has an accuracy of 0.887 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boPaCDMTCH8B",
        "outputId": "20a4b956-1f5f-49f8-ae18-aa6dff8afd2f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9133333333333334, 0.8466666666666667, 0.9, 0.8466666666666667, 0.8666666666666668, 0.8533333333333333, 0.86, 0.8733333333333333, 0.9133333333333334, 0.8866666666666667]\n",
            "[99.88777555110221, 99.87174862730953, 99.75952385723733, 99.88577383218772, 99.77555560008817, 99.87174862730953, 99.7154365643975, 99.86973947895792, 99.86773547094188, 99.87975951903807]\n",
            "[75.97, 75.91, 75.77000000000001, 75.78, 75.92999999999999, 75.69, 75.37, 75.82, 75.55, 76.09]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        ""
      ],
      "metadata": {
        "id": "xcRX5PUuGh1Y"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw-wk1NuGjXv",
        "outputId": "d56545f2-1805-46f1-d5bd-0f838e78e596"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8760000000000001\n",
            "99.83847971285698\n",
            "75.788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation 2 %\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.05 # 2 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bScCAlSrGkoo",
        "outputId": "c422dba1-20d4-4ada-bff7-139446dc573b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.880 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.2%\n",
            "The MIA has an accuracy of 0.887 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 76.4%\n",
            "The MIA has an accuracy of 0.890 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.0%\n",
            "The MIA has an accuracy of 0.873 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.6%\n",
            "Test set accuracy: 75.7%\n",
            "The MIA has an accuracy of 0.927 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.8%\n",
            "The MIA has an accuracy of 0.910 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.7%\n",
            "The MIA has an accuracy of 0.863 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.873 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.873 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 75.7%\n",
            "The MIA has an accuracy of 0.913 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw9PU1wxGn3o",
        "outputId": "6dbaa25f-af34-49ef-f819-2f7ee5623175"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8800000000000001, 0.8866666666666665, 0.89, 0.8733333333333334, 0.9266666666666667, 0.9099999999999999, 0.8633333333333333, 0.8733333333333334, 0.8733333333333334, 0.9133333333333334]\n",
            "[99.8713671262612, 99.85730077379158, 99.83518581794063, 99.90352340562379, 99.6121304688599, 99.88945390227725, 99.89748949769854, 99.87338464939607, 99.86132325749658, 99.79097578132851]\n",
            "[75.98, 76.28, 76.36, 76.07000000000001, 75.64999999999999, 75.42999999999999, 75.78, 75.74, 75.92, 75.77000000000001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        ""
      ],
      "metadata": {
        "id": "f25ktgvFNcYr"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7HTX9GJNd38",
        "outputId": "b48a6fb8-aa23-4d6b-e313-c6473a8410ae"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.889\n",
            "99.8392134680674\n",
            "75.898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation 2 %\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.1 # 2 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djrP09ntNe8s",
        "outputId": "eeb6f0ab-89f6-4127-fffb-03f4f7730a10"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 75.8%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.1%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.1%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.1%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 75.8%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 75.7%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBSMXpmJNiLu",
        "outputId": "e066aca2-b5f2-40b2-eca3-e13e49794f64"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909]\n",
            "[99.77186465315351, 99.89094213874583, 99.91721687160539, 99.85262052814342, 99.80412745850329, 99.85864011793453, 99.84252286446872, 99.86268729049715, 99.83442371375494, 99.89095315024232]\n",
            "[75.9, 76.22, 75.96000000000001, 75.83, 76.1, 75.97, 75.96000000000001, 75.62, 75.59, 75.99000000000001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)"
      ],
      "metadata": {
        "id": "Spd9ZTFHNkEv"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w_mQIjbNlbp",
        "outputId": "5de6f5e4-7f05-4663-ec3c-ebd060454097"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.909090909090909\n",
            "99.85259987870491\n",
            "75.91400000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mmkqv03aNmnk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}