{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMN22w4MTbx-",
        "outputId": "0d0ecac4-3d78-4c73-8476-fb79299885a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on device:\", DEVICE.upper())\n",
        "\n",
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data"
      ],
      "metadata": {
        "id": "oiz4Jx9STtGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CIFAR 10 dataset\n",
        "\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=normalize\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5VyZKPgTsyD",
        "outputId": "8f4cb1c6-9588-4f81-e176-f959663f675c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29135231.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NykHdWHSTs2z",
        "outputId": "1d94844b-6ef7-4d2e-ebfa-54355ac610e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose random forget indecies from some class\n",
        "# Index of class\n",
        "class_index = 1 # cars\n",
        "class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "# Percantage of whole data ( from class )\n",
        "amount = 0.01 # 1 %\n",
        "amount_int = class_set.shape[0] * amount\n",
        "\n",
        "# Get indeces\n",
        "forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "# construct indices of retain from those of the forget set\n",
        "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "forget_mask[forget_idx] = True\n",
        "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "# split train set into a forget and a retain set\n",
        "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "# Generate forget and retain loaders\n",
        "forget_loader = torch.utils.data.DataLoader(\n",
        "    forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")\n",
        "retain_loader = torch.utils.data.DataLoader(\n",
        "    retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")"
      ],
      "metadata": {
        "id": "nbD4rJVLTrRh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add helping dicts\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": test_loader\n",
        "}\n",
        "\n",
        "dataset_sizes = {\"train\": len(train_set), \"val\": len(test_set)}"
      ],
      "metadata": {
        "id": "TLN-G2k9T-nj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_loss = 1000\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(DEVICE)\n",
        "                    labels = labels.to(DEVICE)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_loss < best_loss:\n",
        "                    best_loss = epoch_loss\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val loss: {best_loss:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "3yWjdU4eUCjx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ResNet18\n",
        "\n",
        "model_train = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_train = model_train.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_train.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "g6RsNI0EUaT7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))"
      ],
      "metadata": {
        "id": "dTGQgso_UggP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "024bab73-486d-46b2-e6e0-fab1328e3475"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check accuracy\n",
        "\n",
        "def accuracy(net, loader):\n",
        "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "print(f\"Train set accuracy: {100.0 * accuracy(model_train, train_loader):0.1f}%\")\n",
        "print(f\"Test set accuracy: {100.0 * accuracy(model_train, test_loader):0.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8zYw0twW30H",
        "outputId": "4d9da318-1ca6-4475-80c0-bc65ef0a6de1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 97.8%\n",
            "Test set accuracy: 76.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts,StepLR\n",
        "def kl_loss_sym(x,y):\n",
        "    kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
        "    return kl_loss(nn.LogSoftmax(dim=-1)(x),y)\n",
        "\n",
        "def unlearning(\n",
        "        net,\n",
        "        retain_loader,\n",
        "        forget_loader,\n",
        "        val_loader,\n",
        "):\n",
        "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
        "    print('-----------------------------------')\n",
        "    epochs = 8\n",
        "    retain_bs = 256\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.005,\n",
        "                          momentum=0.9, weight_decay=0)\n",
        "    optimizer_retain = optim.SGD(net.parameters(), lr=0.001*retain_bs/64, momentum=0.9, weight_decay=1e-2)\n",
        "    ##the learning rate is associated with the batchsize we used\n",
        "    optimizer_forget = optim.SGD(net.parameters(), lr=3e-4, momentum=0.9, weight_decay=0)\n",
        "    total_step = int(len(forget_loader)*epochs)\n",
        "    retain_ld = DataLoader(retain_loader.dataset, batch_size=retain_bs, shuffle=True)\n",
        "    retain_ld4fgt = DataLoader(retain_loader.dataset, batch_size=256, shuffle=True)\n",
        "    scheduler = CosineAnnealingLR(optimizer_forget, T_max=total_step, eta_min=1e-6)\n",
        "\n",
        "    net.train()\n",
        "    for sample in forget_loader: ##First Stage\n",
        "        inputs, output = sample\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        uniform_label = torch.ones_like(outputs).to(DEVICE) / outputs.shape[1] ##uniform pseudo label\n",
        "        loss = kl_loss_sym(outputs, uniform_label) ##optimize the distance between logits and pseudo labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    net.train()\n",
        "    for ep in range(epochs): ##Second Stage\n",
        "        net.train()\n",
        "        for sample_forget, sample_retain in zip(forget_loader, retain_ld4fgt):##Forget Round\n",
        "            t = 1.15 ##temperature coefficient\n",
        "            inputs_forget,inputs_retain = sample_forget[0],sample_retain[0]\n",
        "            inputs_forget, inputs_retain = inputs_forget.to(DEVICE), inputs_retain.to(DEVICE)\n",
        "            optimizer_forget.zero_grad()\n",
        "            outputs_forget,outputs_retain = net(inputs_forget),net(inputs_retain).detach()\n",
        "            loss = (-1 * nn.LogSoftmax(dim=-1)(outputs_forget @ outputs_retain.T/t)).mean() ##Contrastive Learning loss\n",
        "            loss.backward()\n",
        "            optimizer_forget.step()\n",
        "            scheduler.step()\n",
        "        for sample in retain_ld: ##Retain Round\n",
        "            inputs, labels = sample\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer_retain.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer_retain.step()\n",
        "\n",
        "    print('-----------------------------------')\n",
        "    return net"
      ],
      "metadata": {
        "id": "6wc09qONYMDE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_losses(net, loader):\n",
        "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    all_losses = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        logits = net(inputs)\n",
        "        losses = criterion(logits, targets).numpy(force=True)\n",
        "        for l in losses:\n",
        "            all_losses.append(l)\n",
        "\n",
        "    return np.array(all_losses)"
      ],
      "metadata": {
        "id": "KkBF3J-5YOwN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MIA score\n",
        "\n",
        "\n",
        "def simple_mia(sample_loss, members, n_splits=10, random_state=0):\n",
        "    \"\"\"Computes cross-validation score of a membership inference attack.\n",
        "\n",
        "    Args:\n",
        "      sample_loss : array_like of shape (n,).\n",
        "        objective function evaluated on n samples.\n",
        "      members : array_like of shape (n,),\n",
        "        whether a sample was used for training.\n",
        "      n_splits: int\n",
        "        number of splits to use in the cross-validation.\n",
        "    Returns:\n",
        "      scores : array_like of size (n_splits,)\n",
        "    \"\"\"\n",
        "\n",
        "    unique_members = np.unique(members)\n",
        "    if not np.all(unique_members == np.array([0, 1])):\n",
        "        raise ValueError(\"members should only have 0 and 1s\")\n",
        "\n",
        "    attack_model = linear_model.LogisticRegression()\n",
        "    cv = model_selection.StratifiedShuffleSplit(\n",
        "        n_splits=n_splits, random_state=random_state\n",
        "    )\n",
        "    return model_selection.cross_val_score(\n",
        "        attack_model, sample_loss, members, cv=cv, scoring=\"accuracy\"\n",
        "    )"
      ],
      "metadata": {
        "id": "EjaFXOXbYTME"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unlearning algorithm\n",
        "def unlearning_by_epochs(net, retain, forget, validation, epochs=5):\n",
        "    \"\"\"Unlearning by fine-tuning.\n",
        "\n",
        "    Fine-tuning is a very simple algorithm that trains using only\n",
        "    the retain set.\n",
        "\n",
        "    Args:\n",
        "      net : nn.Module.\n",
        "        pre-trained model to use as base of unlearning.\n",
        "      retain : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the retain set. This is the subset\n",
        "        of the training set that we don't want to forget.\n",
        "      forget : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the forget set. This is the subset\n",
        "        of the training set that we want to forget. This method doesn't\n",
        "        make use of the forget set.\n",
        "      validation : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the validation set. This method doesn't\n",
        "        make use of the validation set.\n",
        "    Returns:\n",
        "      net : updated model\n",
        "    \"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    net.train()\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for inputs, targets in retain:\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    net.eval()\n",
        "    return net"
      ],
      "metadata": {
        "id": "w3j59gBstFbI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = compute_losses(model_train, train_loader)\n",
        "test_losses = compute_losses(model_train, test_loader)\n",
        "\n",
        "# TRAIN MODEL\n",
        "# Get random test samples\n",
        "randomize = np.arange(len(test_losses))\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Compute forget losses on train dataset\n",
        "forget_losses = compute_losses(model_train, forget_loader)\n",
        "\n",
        "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "test_losses = test_losses[randomize][: len(forget_losses)]\n",
        "\n",
        "samples_mia = np.concatenate((test_losses, forget_losses)).reshape((-1, 1))\n",
        "labels_mia = [0] * len(test_losses) + [1] * len(forget_losses)\n",
        "\n",
        "mia_scores = simple_mia(samples_mia, labels_mia)\n",
        "\n",
        "print(\n",
        "    f\"The MIA has an accuracy of {mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtD2G9oKZPjP",
        "outputId": "284a452d-f2d4-4154-8100-294ac382da53"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIA has an accuracy of 0.790 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- 1 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.01 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJYSFgoGYVt6",
        "outputId": "32c357b8-ac90-4aaa-efae-8a896e740545"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 1 PERCENT -------\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.7%\n",
            "Test set accuracy FORGET model: 74.9%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.780 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.7%\n",
            "Test set accuracy FORGET model: 75.2%\n",
            "Forget set accuracy FORGET model: 14.0%\n",
            "The MIA has an accuracy of 0.780 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.8%\n",
            "Test set accuracy FORGET model: 75.6%\n",
            "Forget set accuracy FORGET model: 16.0%\n",
            "The MIA has an accuracy of 0.760 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.4%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.830 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.8%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.790 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.8%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.860 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.7%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.840 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 98.8%\n",
            "Test set accuracy FORGET model: 74.5%\n",
            "Forget set accuracy FORGET model: 6.0%\n",
            "The MIA has an accuracy of 0.860 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.8%\n",
            "Test set accuracy FORGET model: 75.5%\n",
            "Forget set accuracy FORGET model: 18.0%\n",
            "The MIA has an accuracy of 0.820 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.8%\n",
            "Test set accuracy FORGET model: 75.5%\n",
            "Forget set accuracy FORGET model: 10.0%\n",
            "The MIA has an accuracy of 0.750 on forgotten vs unseen images on FORGET model\n",
            "[0.78, 0.78, 0.76, 0.8300000000000001, 0.7899999999999999, 0.8600000000000001, 0.8400000000000001, 0.86, 0.82, 0.75]\n",
            "[99.6436507777622, 99.68368368368368, 99.84384384384384, 99.83984304618527, 99.8898898898899, 99.88788788788789, 99.847850893876, 98.83083083083083, 99.87587587587588, 99.85385677964405]\n",
            "[12.0, 14.000000000000002, 16.0, 12.0, 12.0, 12.0, 12.0, 6.0, 18.0, 10.0]\n",
            "[74.94, 74.83, 75.5, 75.38, 75.72, 75.87, 75.73, 74.4, 75.71, 75.44]\n",
            "MEANS\n",
            "0.807\n",
            "99.71972135094795\n",
            "12.4\n",
            "75.352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- 2 PERCANTAGES -----\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.02 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mac5VywIfiQL",
        "outputId": "69cd17a1-6857-4565-8a58-6ce048f1fcbe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 2 PERCANTAGES -----\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.8%\n",
            "Test set accuracy FORGET model: 75.2%\n",
            "Forget set accuracy FORGET model: 16.0%\n",
            "The MIA has an accuracy of 0.840 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.7%\n",
            "Test set accuracy FORGET model: 75.4%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.840 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.7%\n",
            "Test set accuracy FORGET model: 75.2%\n",
            "Forget set accuracy FORGET model: 11.0%\n",
            "The MIA has an accuracy of 0.840 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.6%\n",
            "Forget set accuracy FORGET model: 10.0%\n",
            "The MIA has an accuracy of 0.887 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.8%\n",
            "Test set accuracy FORGET model: 75.4%\n",
            "Forget set accuracy FORGET model: 9.0%\n",
            "The MIA has an accuracy of 0.887 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.4%\n",
            "Forget set accuracy FORGET model: 7.0%\n",
            "The MIA has an accuracy of 0.860 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.6%\n",
            "Forget set accuracy FORGET model: 9.0%\n",
            "The MIA has an accuracy of 0.847 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.4%\n",
            "Forget set accuracy FORGET model: 8.0%\n",
            "The MIA has an accuracy of 0.860 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.6%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.773 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.6%\n",
            "Forget set accuracy FORGET model: 5.0%\n",
            "The MIA has an accuracy of 0.773 on forgotten vs unseen images on FORGET model\n",
            "[0.8400000000000001, 0.8400000000000001, 0.8400000000000001, 0.8866666666666665, 0.8866666666666667, 0.86, 0.8466666666666667, 0.86, 0.7733333333333334, 0.7733333333333332]\n",
            "[99.7935871743487, 99.68336673346694, 99.7434869739479, 99.90380761523045, 99.85771543086173, 99.87976433810269, 99.87976192861866, 99.92785715717119, 99.8917857357568, 99.88778229765745]\n",
            "[16.0, 12.0, 11.0, 10.0, 9.0, 7.000000000000001, 9.0, 8.0, 12.0, 5.0]\n",
            "[75.14, 75.06, 75.33, 75.48, 75.05, 75.33, 75.48, 75.64999999999999, 75.31, 75.68]\n",
            "MEANS\n",
            "0.8406666666666668\n",
            "99.84489153851625\n",
            "9.9\n",
            "75.351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- 5 PERCANTAGES -----\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.05 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQdsk6KTfl9q",
        "outputId": "1788e9b8-8321-42d8-a94f-a1178ffe91cd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 5 PERCANTAGES -----\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.8%\n",
            "Test set accuracy FORGET model: 75.3%\n",
            "Forget set accuracy FORGET model: 15.2%\n",
            "The MIA has an accuracy of 0.883 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.2%\n",
            "Forget set accuracy FORGET model: 13.2%\n",
            "The MIA has an accuracy of 0.877 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.3%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.907 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.5%\n",
            "Forget set accuracy FORGET model: 10.4%\n",
            "The MIA has an accuracy of 0.927 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.5%\n",
            "Forget set accuracy FORGET model: 8.0%\n",
            "The MIA has an accuracy of 0.910 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.8%\n",
            "Test set accuracy FORGET model: 75.1%\n",
            "Forget set accuracy FORGET model: 12.8%\n",
            "The MIA has an accuracy of 0.873 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.7%\n",
            "Forget set accuracy FORGET model: 12.4%\n",
            "The MIA has an accuracy of 0.870 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.8%\n",
            "Test set accuracy FORGET model: 74.9%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.943 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.8%\n",
            "Forget set accuracy FORGET model: 10.4%\n",
            "The MIA has an accuracy of 0.913 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.8%\n",
            "Test set accuracy FORGET model: 75.6%\n",
            "Forget set accuracy FORGET model: 10.8%\n",
            "The MIA has an accuracy of 0.900 on forgotten vs unseen images on FORGET model\n",
            "[0.8833333333333334, 0.8766666666666667, 0.9066666666666668, 0.9266666666666667, 0.9099999999999999, 0.8733333333333334, 0.8699999999999999, 0.9433333333333334, 0.9133333333333334, 0.9]\n",
            "[99.77891669178976, 99.89146383132676, 99.91558467660892, 99.8914660127829, 99.85126823973953, 99.74274459361685, 99.90153326768885, 99.75881820922521, 99.88946278915529, 99.83518581794063]\n",
            "[15.2, 13.200000000000001, 12.0, 10.4, 8.0, 12.8, 12.4, 12.0, 10.4, 10.8]\n",
            "[75.26, 75.36, 75.19, 75.89, 75.56, 75.37, 75.66000000000001, 75.4, 75.39, 75.42]\n",
            "MEANS\n",
            "0.9003333333333334\n",
            "99.84564441298747\n",
            "11.72\n",
            "75.44999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- 10 % -----\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.1 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bBQIyMflpv8",
        "outputId": "1d2608eb-6ef6-45d5-f035-2bf41ce1fa75"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 10 % -----\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.5%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.4%\n",
            "Forget set accuracy FORGET model: 15.8%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.6%\n",
            "Forget set accuracy FORGET model: 12.6%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.5%\n",
            "Forget set accuracy FORGET model: 10.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.8%\n",
            "Forget set accuracy FORGET model: 11.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.7%\n",
            "Test set accuracy FORGET model: 75.0%\n",
            "Forget set accuracy FORGET model: 8.8%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.0%\n",
            "Forget set accuracy FORGET model: 10.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.8%\n",
            "Forget set accuracy FORGET model: 11.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.7%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.9%\n",
            "Test set accuracy FORGET model: 75.6%\n",
            "Forget set accuracy FORGET model: 11.2%\n",
            "The MIA has an accuracy of 0.907 on forgotten vs unseen images on FORGET model\n",
            "[0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.907272727272727]\n",
            "[99.90509460250793, 99.88290161716905, 99.90307729585656, 99.8848856935132, 99.89298334174659, 99.7051934415637, 99.87885885037049, 99.91721352852096, 99.88087305913946, 99.92529176594113]\n",
            "[11.600000000000001, 16.2, 12.4, 9.2, 10.8, 9.4, 10.8, 9.8, 11.4, 11.600000000000001]\n",
            "[75.49, 75.55, 75.75, 75.49, 75.76, 75.02, 75.53, 75.57000000000001, 75.87, 75.62]\n",
            "MEANS\n",
            "0.9089090909090908\n",
            "99.87763731963291\n",
            "11.320000000000002\n",
            "75.565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "# Define model from trained params\n",
        "\n",
        "model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "model_forget_ft.to(DEVICE)\n",
        "\n",
        "for epoch_num in range(10):\n",
        "\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.02 # 2 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning_by_epochs(model_forget_ft, retain_loader, forget_loader, test_loader, 1)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model epoch {epoch_num}: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model epoch {epoch_num}: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model {epoch_num}:: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvML-PLBqpsq",
        "outputId": "87174b2c-cae1-4abd-8653-b65d7ef0c01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retain set accuracy FORGET model epoch 0: 81.6%\n",
            "Test set accuracy FORGET model epoch 0: 70.8%\n",
            "Forget set accuracy FORGET model 0:: 81.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 1: 85.1%\n",
            "Test set accuracy FORGET model epoch 1: 72.0%\n",
            "Forget set accuracy FORGET model 1:: 95.0%\n",
            "The MIA has an accuracy of 0.767 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 2: 87.0%\n",
            "Test set accuracy FORGET model epoch 2: 71.5%\n",
            "Forget set accuracy FORGET model 2:: 81.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 3: 89.2%\n",
            "Test set accuracy FORGET model epoch 3: 72.9%\n",
            "Forget set accuracy FORGET model 3:: 85.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 4: 87.8%\n",
            "Test set accuracy FORGET model epoch 4: 71.9%\n",
            "Forget set accuracy FORGET model 4:: 83.0%\n",
            "The MIA has an accuracy of 0.640 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 5: 89.8%\n",
            "Test set accuracy FORGET model epoch 5: 72.2%\n",
            "Forget set accuracy FORGET model 5:: 97.0%\n",
            "The MIA has an accuracy of 0.687 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 6: 88.6%\n",
            "Test set accuracy FORGET model epoch 6: 71.3%\n",
            "Forget set accuracy FORGET model 6:: 90.0%\n",
            "The MIA has an accuracy of 0.693 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 7: 88.5%\n",
            "Test set accuracy FORGET model epoch 7: 70.1%\n",
            "Forget set accuracy FORGET model 7:: 93.0%\n",
            "The MIA has an accuracy of 0.707 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 8: 88.7%\n",
            "Test set accuracy FORGET model epoch 8: 71.1%\n",
            "Forget set accuracy FORGET model 8:: 86.0%\n",
            "The MIA has an accuracy of 0.647 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 9: 89.2%\n",
            "Test set accuracy FORGET model epoch 9: 70.8%\n",
            "Forget set accuracy FORGET model 9:: 88.0%\n",
            "The MIA has an accuracy of 0.660 on forgotten vs unseen images on FORGET model\n",
            "[0.6666666666666667, 0.7666666666666667, 0.6666666666666667, 0.6666666666666667, 0.6399999999999999, 0.6866666666666666, 0.6933333333333334, 0.7066666666666667, 0.6466666666666667, 0.6599999999999999]\n",
            "[81.64966633935191, 85.10049898799623, 87.01707277973709, 89.24291611558655, 87.84168336673346, 89.7639373171416, 88.60721442885772, 88.48496993987976, 88.71743486973948, 89.24091218788827]\n",
            "[81.0, 95.0, 81.0, 85.0, 83.0, 97.0, 90.0, 93.0, 86.0, 88.0]\n",
            "[70.78, 72.02, 71.55, 72.89999999999999, 71.87, 72.21, 71.26, 70.11, 71.11, 70.83]\n",
            "MEANS\n",
            "0.68\n",
            "87.56663063329121\n",
            "87.9\n",
            "71.464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9F7cNNckviux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}