{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMN22w4MTbx-",
        "outputId": "93e1efc2-daba-4b41-d122-3a2666451b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on device:\", DEVICE.upper())\n",
        "\n",
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data"
      ],
      "metadata": {
        "id": "oiz4Jx9STtGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CIFAR 10 dataset\n",
        "\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=normalize\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5VyZKPgTsyD",
        "outputId": "84b3e027-fb91-4939-9773-2fdace733752"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 82184495.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NykHdWHSTs2z",
        "outputId": "05c578b3-8948-4e69-ff30-52bf089096d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose random forget indecies from some class\n",
        "# Index of class\n",
        "class_index = 1 # cars\n",
        "class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "# Percantage of whole data ( from class )\n",
        "amount = 0.01 # 1 %\n",
        "amount_int = class_set.shape[0] * amount\n",
        "\n",
        "# Get indeces\n",
        "forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "# construct indices of retain from those of the forget set\n",
        "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "forget_mask[forget_idx] = True\n",
        "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "# split train set into a forget and a retain set\n",
        "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "# Generate forget and retain loaders\n",
        "forget_loader = torch.utils.data.DataLoader(\n",
        "    forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")\n",
        "retain_loader = torch.utils.data.DataLoader(\n",
        "    retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")"
      ],
      "metadata": {
        "id": "nbD4rJVLTrRh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add helping dicts\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": test_loader\n",
        "}\n",
        "\n",
        "dataset_sizes = {\"train\": len(train_set), \"val\": len(test_set)}"
      ],
      "metadata": {
        "id": "TLN-G2k9T-nj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_loss = 1000\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(DEVICE)\n",
        "                    labels = labels.to(DEVICE)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_loss < best_loss:\n",
        "                    best_loss = epoch_loss\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val loss: {best_loss:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "3yWjdU4eUCjx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ResNet18\n",
        "\n",
        "model_train = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_train = model_train.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_train.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "g6RsNI0EUaT7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f94VGw_Ucil",
        "outputId": "6cf9686e-b0ac-4041-a697-a3925f2c3e99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check accuracy\n",
        "\n",
        "def accuracy(net, loader):\n",
        "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "print(f\"Train set accuracy: {100.0 * accuracy(model_train, train_loader):0.1f}%\")\n",
        "print(f\"Test set accuracy: {100.0 * accuracy(model_train, test_loader):0.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8zYw0twW30H",
        "outputId": "fe7b496c-7abb-45b5-c590-2e1f57509a14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 97.7%\n",
            "Test set accuracy: 76.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.prune as prune\n",
        "from math import sqrt\n",
        "import json\n",
        "from copy import deepcopy\n",
        "\n",
        "def kl_loss_fn(outputs, dist_target):\n",
        "    kl_loss = F.kl_div(torch.log_softmax(outputs, dim=1), dist_target, log_target=True, reduction='batchmean')\n",
        "    return kl_loss\n",
        "\n",
        "def entropy_loss_fn(outputs, labels, dist_target, class_weights):\n",
        "    ce_loss = F.cross_entropy(outputs, labels, weight=class_weights)\n",
        "    entropy_dist_target = torch.sum(-torch.exp(dist_target) * dist_target, dim=1)\n",
        "    entropy_outputs = torch.sum(-torch.softmax(outputs, dim=1) * torch.log_softmax(outputs, dim=1), dim=1)\n",
        "    entropy_loss = F.mse_loss(entropy_outputs, entropy_dist_target)\n",
        "    return ce_loss + entropy_loss\n",
        "\n",
        "\n",
        "def unlearning(\n",
        "    net,\n",
        "    retain_loader,\n",
        "    forget_loader,\n",
        "    val_loader,\n",
        "    class_weights=None,\n",
        "):\n",
        "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
        "    epochs = 3.2\n",
        "    max_iters = int(len(retain_loader) * epochs)\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.0005,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "    initial_net = deepcopy(net)\n",
        "\n",
        "    net.train()\n",
        "    initial_net.eval()\n",
        "\n",
        "    def prune_model(net, amount=0.95, rand_init=True):\n",
        "        # Modules to prune\n",
        "        modules = list()\n",
        "        for k, m in enumerate(net.modules()):\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                modules.append((m, 'weight'))\n",
        "                if m.bias is not None:\n",
        "                    modules.append((m, 'bias'))\n",
        "\n",
        "        # Prune criteria\n",
        "        prune.global_unstructured(\n",
        "            modules,\n",
        "            #pruning_method=prune.RandomUnstructured,\n",
        "            pruning_method=prune.L1Unstructured,\n",
        "            amount=amount,\n",
        "        )\n",
        "\n",
        "        # Perform the prune\n",
        "        for k, m in enumerate(net.modules()):\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                prune.remove(m, 'weight')\n",
        "                if m.bias is not None:\n",
        "                    prune.remove(m, 'bias')\n",
        "\n",
        "        # Random initialization\n",
        "        if rand_init:\n",
        "            for k, m in enumerate(net.modules()):\n",
        "                if isinstance(m, nn.Conv2d):\n",
        "                    mask = m.weight == 0\n",
        "                    c_in = mask.shape[1]\n",
        "                    k = 1/(c_in*mask.shape[2]*mask.shape[3])\n",
        "                    randinit = (torch.rand_like(m.weight)-0.5)*2*sqrt(k)\n",
        "                    m.weight.data[mask] = randinit[mask]\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    mask = m.weight == 0\n",
        "                    c_in = mask.shape[1]\n",
        "                    k = 1/c_in\n",
        "                    randinit = (torch.rand_like(m.weight)-0.5)*2*sqrt(k)\n",
        "                    m.weight.data[mask] = randinit[mask]\n",
        "\n",
        "    num_iters = 0\n",
        "    running = True\n",
        "    prune_amount = 0.99\n",
        "    prune_model(net, prune_amount, True)\n",
        "    while running:\n",
        "        net.train()\n",
        "        for sample in retain_loader:\n",
        "            inputs = sample[0]\n",
        "            targets = sample[1]\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "            # Get target distribution\n",
        "            with torch.no_grad():\n",
        "                original_outputs = initial_net(inputs)\n",
        "                preds = torch.log_softmax(original_outputs, dim=1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = entropy_loss_fn(outputs, targets, preds, class_weights)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            num_iters += 1\n",
        "            # Stop at max iters\n",
        "            if num_iters > max_iters:\n",
        "                running = False\n",
        "                break\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    return net"
      ],
      "metadata": {
        "id": "6wc09qONYMDE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_losses(net, loader):\n",
        "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    all_losses = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        logits = net(inputs)\n",
        "        losses = criterion(logits, targets).numpy(force=True)\n",
        "        for l in losses:\n",
        "            all_losses.append(l)\n",
        "\n",
        "    return np.array(all_losses)"
      ],
      "metadata": {
        "id": "KkBF3J-5YOwN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MIA score\n",
        "\n",
        "\n",
        "def simple_mia(sample_loss, members, n_splits=10, random_state=0):\n",
        "    \"\"\"Computes cross-validation score of a membership inference attack.\n",
        "\n",
        "    Args:\n",
        "      sample_loss : array_like of shape (n,).\n",
        "        objective function evaluated on n samples.\n",
        "      members : array_like of shape (n,),\n",
        "        whether a sample was used for training.\n",
        "      n_splits: int\n",
        "        number of splits to use in the cross-validation.\n",
        "    Returns:\n",
        "      scores : array_like of size (n_splits,)\n",
        "    \"\"\"\n",
        "\n",
        "    unique_members = np.unique(members)\n",
        "    if not np.all(unique_members == np.array([0, 1])):\n",
        "        raise ValueError(\"members should only have 0 and 1s\")\n",
        "\n",
        "    attack_model = linear_model.LogisticRegression()\n",
        "    cv = model_selection.StratifiedShuffleSplit(\n",
        "        n_splits=n_splits, random_state=random_state\n",
        "    )\n",
        "    return model_selection.cross_val_score(\n",
        "        attack_model, sample_loss, members, cv=cv, scoring=\"accuracy\"\n",
        "    )"
      ],
      "metadata": {
        "id": "EjaFXOXbYTME"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = compute_losses(model_train, train_loader)\n",
        "test_losses = compute_losses(model_train, test_loader)\n",
        "\n",
        "# TRAIN MODEL\n",
        "# Get random test samples\n",
        "randomize = np.arange(len(test_losses))\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Compute forget losses on train dataset\n",
        "forget_losses = compute_losses(model_train, forget_loader)\n",
        "\n",
        "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "test_losses = test_losses[randomize][: len(forget_losses)]\n",
        "\n",
        "samples_mia = np.concatenate((test_losses, forget_losses)).reshape((-1, 1))\n",
        "labels_mia = [0] * len(test_losses) + [1] * len(forget_losses)\n",
        "\n",
        "mia_scores = simple_mia(samples_mia, labels_mia)\n",
        "\n",
        "print(\n",
        "    f\"The MIA has an accuracy of {mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtD2G9oKZPjP",
        "outputId": "e79add6a-19f8-462d-b77d-6b0601393e01"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIA has an accuracy of 0.730 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- 1 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.01 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJYSFgoGYVt6",
        "outputId": "27d967e5-5266-46e4-97c6-18b04569e0c2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 1 PERCENT -------\n",
            "Retain set accuracy FORGET model: 69.9%\n",
            "Test set accuracy FORGET model: 57.9%\n",
            "Forget set accuracy FORGET model: 62.0%\n",
            "The MIA has an accuracy of 0.610 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.2%\n",
            "Test set accuracy FORGET model: 57.6%\n",
            "Forget set accuracy FORGET model: 68.0%\n",
            "The MIA has an accuracy of 0.550 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 68.9%\n",
            "Test set accuracy FORGET model: 57.7%\n",
            "Forget set accuracy FORGET model: 38.0%\n",
            "The MIA has an accuracy of 0.720 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 68.2%\n",
            "Test set accuracy FORGET model: 56.4%\n",
            "Forget set accuracy FORGET model: 58.0%\n",
            "The MIA has an accuracy of 0.490 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 68.8%\n",
            "Test set accuracy FORGET model: 56.6%\n",
            "Forget set accuracy FORGET model: 54.0%\n",
            "The MIA has an accuracy of 0.490 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 70.3%\n",
            "Test set accuracy FORGET model: 58.1%\n",
            "Forget set accuracy FORGET model: 50.0%\n",
            "The MIA has an accuracy of 0.450 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 67.7%\n",
            "Test set accuracy FORGET model: 56.8%\n",
            "Forget set accuracy FORGET model: 76.0%\n",
            "The MIA has an accuracy of 0.510 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.1%\n",
            "Test set accuracy FORGET model: 57.3%\n",
            "Forget set accuracy FORGET model: 72.0%\n",
            "The MIA has an accuracy of 0.420 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.7%\n",
            "Test set accuracy FORGET model: 56.7%\n",
            "Forget set accuracy FORGET model: 64.0%\n",
            "The MIA has an accuracy of 0.490 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.3%\n",
            "Test set accuracy FORGET model: 56.9%\n",
            "Forget set accuracy FORGET model: 50.0%\n",
            "The MIA has an accuracy of 0.480 on forgotten vs unseen images on FORGET model\n",
            "[0.6100000000000001, 0.55, 0.72, 0.49000000000000005, 0.48999999999999994, 0.45, 0.51, 0.42000000000000004, 0.49000000000000005, 0.48]\n",
            "[69.9125142639787, 69.21583151488458, 68.90552741686852, 68.17217217217217, 68.82082082082081, 70.33033033033033, 67.67167167167167, 69.11573341875038, 69.66166166166167, 69.26526526526527]\n",
            "[62.0, 68.0, 38.0, 57.99999999999999, 54.0, 50.0, 76.0, 72.0, 64.0, 50.0]\n",
            "[57.92, 57.57, 57.68, 56.38999999999999, 56.63, 58.15, 56.8, 57.34, 56.66, 56.940000000000005]\n",
            "MEANS\n",
            "0.5210000000000001\n",
            "69.10715285364041\n",
            "59.2\n",
            "57.208000000000006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- 2 PERCANTAGES -----\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.02 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mac5VywIfiQL",
        "outputId": "8bc41cbe-3fa0-4897-a037-84e12cfcbd6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 2 PERCANTAGES -----\n",
            "Retain set accuracy FORGET model: 69.9%\n",
            "Test set accuracy FORGET model: 57.4%\n",
            "Forget set accuracy FORGET model: 56.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.9%\n",
            "Test set accuracy FORGET model: 57.2%\n",
            "Forget set accuracy FORGET model: 73.0%\n",
            "The MIA has an accuracy of 0.693 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 70.4%\n",
            "Test set accuracy FORGET model: 58.1%\n",
            "Forget set accuracy FORGET model: 42.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.9%\n",
            "Test set accuracy FORGET model: 57.3%\n",
            "Forget set accuracy FORGET model: 50.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 70.2%\n",
            "Test set accuracy FORGET model: 57.1%\n",
            "Forget set accuracy FORGET model: 52.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.4%\n",
            "Test set accuracy FORGET model: 56.6%\n",
            "Forget set accuracy FORGET model: 42.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 68.7%\n",
            "Test set accuracy FORGET model: 57.4%\n",
            "Forget set accuracy FORGET model: 63.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.6%\n",
            "Test set accuracy FORGET model: 57.2%\n",
            "Forget set accuracy FORGET model: 67.0%\n",
            "The MIA has an accuracy of 0.660 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 70.3%\n",
            "Test set accuracy FORGET model: 57.2%\n",
            "Forget set accuracy FORGET model: 72.0%\n",
            "The MIA has an accuracy of 0.647 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.5%\n",
            "Test set accuracy FORGET model: 56.6%\n",
            "Forget set accuracy FORGET model: 70.0%\n",
            "The MIA has an accuracy of 0.653 on forgotten vs unseen images on FORGET model\n",
            "[0.6666666666666667, 0.6933333333333334, 0.6666666666666667, 0.6666666666666667, 0.6666666666666667, 0.6666666666666667, 0.6666666666666667, 0.6599999999999999, 0.6466666666666667, 0.6533333333333333]\n",
            "[69.85030360113024, 69.89839882968278, 70.44147411875514, 69.88437105468829, 70.18697020099798, 69.44349812629007, 68.73872790669712, 69.63387507264383, 70.30661322645291, 69.52148124398846]\n",
            "[56.00000000000001, 73.0, 42.0, 50.0, 52.0, 42.0, 63.0, 67.0, 72.0, 70.0]\n",
            "[57.379999999999995, 57.19, 58.07, 57.29, 57.08, 56.620000000000005, 57.37, 57.18, 57.18, 56.620000000000005]\n",
            "MEANS\n",
            "0.6653333333333334\n",
            "69.79057133813268\n",
            "58.7\n",
            "57.198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- 5 PERCANTAGES -----\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.05 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQdsk6KTfl9q",
        "outputId": "69e481dc-d7ee-4092-c0d7-e74e7775b81f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 5 PERCANTAGES -----\n",
            "Retain set accuracy FORGET model: 69.3%\n",
            "Test set accuracy FORGET model: 57.0%\n",
            "Forget set accuracy FORGET model: 68.4%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 71.2%\n",
            "Test set accuracy FORGET model: 58.2%\n",
            "Forget set accuracy FORGET model: 69.2%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 70.8%\n",
            "Test set accuracy FORGET model: 58.2%\n",
            "Forget set accuracy FORGET model: 42.0%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.0%\n",
            "Test set accuracy FORGET model: 57.2%\n",
            "Forget set accuracy FORGET model: 38.4%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 70.9%\n",
            "Test set accuracy FORGET model: 57.3%\n",
            "Forget set accuracy FORGET model: 58.8%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.1%\n",
            "Test set accuracy FORGET model: 57.0%\n",
            "Forget set accuracy FORGET model: 46.4%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 70.2%\n",
            "Test set accuracy FORGET model: 57.9%\n",
            "Forget set accuracy FORGET model: 70.8%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.3%\n",
            "Test set accuracy FORGET model: 57.1%\n",
            "Forget set accuracy FORGET model: 58.4%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.4%\n",
            "Test set accuracy FORGET model: 56.9%\n",
            "Forget set accuracy FORGET model: 66.0%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.5%\n",
            "Test set accuracy FORGET model: 56.4%\n",
            "Forget set accuracy FORGET model: 65.2%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "[0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334]\n",
            "[69.33882636655949, 71.16992203199099, 70.76450018087543, 68.98062545220677, 70.87930861219978, 69.06364933577184, 70.22871613473752, 69.33295817673894, 69.43098908608526, 69.53935203794516]\n",
            "[68.4, 69.19999999999999, 42.0, 38.4, 58.8, 46.400000000000006, 70.8, 58.4, 66.0, 65.2]\n",
            "[56.989999999999995, 58.160000000000004, 58.199999999999996, 57.230000000000004, 57.330000000000005, 57.05, 57.86, 57.06, 56.87, 56.38999999999999]\n",
            "MEANS\n",
            "0.8333333333333333\n",
            "69.87288474151111\n",
            "58.360000000000014\n",
            "57.314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- 10 % -----\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.1 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bBQIyMflpv8",
        "outputId": "1e2b4015-99d9-45e9-cdaa-bdf528646eec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 10 % -----\n",
            "Retain set accuracy FORGET model: 69.5%\n",
            "Test set accuracy FORGET model: 55.9%\n",
            "Forget set accuracy FORGET model: 55.2%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 67.8%\n",
            "Test set accuracy FORGET model: 56.5%\n",
            "Forget set accuracy FORGET model: 54.8%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 70.0%\n",
            "Test set accuracy FORGET model: 57.4%\n",
            "Forget set accuracy FORGET model: 43.4%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.9%\n",
            "Test set accuracy FORGET model: 57.2%\n",
            "Forget set accuracy FORGET model: 34.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 70.3%\n",
            "Test set accuracy FORGET model: 57.8%\n",
            "Forget set accuracy FORGET model: 49.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 68.5%\n",
            "Test set accuracy FORGET model: 57.2%\n",
            "Forget set accuracy FORGET model: 46.2%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.4%\n",
            "Test set accuracy FORGET model: 56.2%\n",
            "Forget set accuracy FORGET model: 61.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.9%\n",
            "Test set accuracy FORGET model: 58.2%\n",
            "Forget set accuracy FORGET model: 63.4%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 69.7%\n",
            "Test set accuracy FORGET model: 57.6%\n",
            "Forget set accuracy FORGET model: 72.6%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 70.2%\n",
            "Test set accuracy FORGET model: 57.9%\n",
            "Forget set accuracy FORGET model: 57.4%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "[0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909]\n",
            "[69.51517476727986, 67.8477690288714, 69.98970175474022, 69.86713512640335, 70.31862052255381, 68.456972095465, 69.35767219271854, 69.90751958646312, 69.66539447910988, 70.17083316505796]\n",
            "[55.2, 54.800000000000004, 43.4, 34.0, 49.0, 46.2, 61.0, 63.4, 72.6, 57.4]\n",
            "[55.94, 56.54, 57.4, 57.17, 57.82000000000001, 57.199999999999996, 56.19, 58.18, 57.620000000000005, 57.89]\n",
            "MEANS\n",
            "0.909090909090909\n",
            "69.5096792718663\n",
            "53.7\n",
            "57.19499999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "# Define model from trained params\n",
        "\n",
        "model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "model_forget_ft.to(DEVICE)\n",
        "\n",
        "for epoch_num in range(10):\n",
        "\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.02 # 2 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning_by_epochs(model_forget_ft, retain_loader, forget_loader, test_loader, 1)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model epoch {epoch_num}: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model epoch {epoch_num}: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model {epoch_num}:: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvML-PLBqpsq",
        "outputId": "87174b2c-cae1-4abd-8653-b65d7ef0c01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retain set accuracy FORGET model epoch 0: 81.6%\n",
            "Test set accuracy FORGET model epoch 0: 70.8%\n",
            "Forget set accuracy FORGET model 0:: 81.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 1: 85.1%\n",
            "Test set accuracy FORGET model epoch 1: 72.0%\n",
            "Forget set accuracy FORGET model 1:: 95.0%\n",
            "The MIA has an accuracy of 0.767 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 2: 87.0%\n",
            "Test set accuracy FORGET model epoch 2: 71.5%\n",
            "Forget set accuracy FORGET model 2:: 81.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 3: 89.2%\n",
            "Test set accuracy FORGET model epoch 3: 72.9%\n",
            "Forget set accuracy FORGET model 3:: 85.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 4: 87.8%\n",
            "Test set accuracy FORGET model epoch 4: 71.9%\n",
            "Forget set accuracy FORGET model 4:: 83.0%\n",
            "The MIA has an accuracy of 0.640 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 5: 89.8%\n",
            "Test set accuracy FORGET model epoch 5: 72.2%\n",
            "Forget set accuracy FORGET model 5:: 97.0%\n",
            "The MIA has an accuracy of 0.687 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 6: 88.6%\n",
            "Test set accuracy FORGET model epoch 6: 71.3%\n",
            "Forget set accuracy FORGET model 6:: 90.0%\n",
            "The MIA has an accuracy of 0.693 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 7: 88.5%\n",
            "Test set accuracy FORGET model epoch 7: 70.1%\n",
            "Forget set accuracy FORGET model 7:: 93.0%\n",
            "The MIA has an accuracy of 0.707 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 8: 88.7%\n",
            "Test set accuracy FORGET model epoch 8: 71.1%\n",
            "Forget set accuracy FORGET model 8:: 86.0%\n",
            "The MIA has an accuracy of 0.647 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 9: 89.2%\n",
            "Test set accuracy FORGET model epoch 9: 70.8%\n",
            "Forget set accuracy FORGET model 9:: 88.0%\n",
            "The MIA has an accuracy of 0.660 on forgotten vs unseen images on FORGET model\n",
            "[0.6666666666666667, 0.7666666666666667, 0.6666666666666667, 0.6666666666666667, 0.6399999999999999, 0.6866666666666666, 0.6933333333333334, 0.7066666666666667, 0.6466666666666667, 0.6599999999999999]\n",
            "[81.64966633935191, 85.10049898799623, 87.01707277973709, 89.24291611558655, 87.84168336673346, 89.7639373171416, 88.60721442885772, 88.48496993987976, 88.71743486973948, 89.24091218788827]\n",
            "[81.0, 95.0, 81.0, 85.0, 83.0, 97.0, 90.0, 93.0, 86.0, 88.0]\n",
            "[70.78, 72.02, 71.55, 72.89999999999999, 71.87, 72.21, 71.26, 70.11, 71.11, 70.83]\n",
            "MEANS\n",
            "0.68\n",
            "87.56663063329121\n",
            "87.9\n",
            "71.464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9F7cNNckviux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}