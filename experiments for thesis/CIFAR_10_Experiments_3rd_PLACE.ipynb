{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMN22w4MTbx-",
        "outputId": "4afccf46-6352-4f8a-d660-a10316233e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on device:\", DEVICE.upper())\n",
        "\n",
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data"
      ],
      "metadata": {
        "id": "oiz4Jx9STtGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CIFAR 10 dataset\n",
        "\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=normalize\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5VyZKPgTsyD",
        "outputId": "059857d1-1b8f-454c-f883-ea3d3cd541f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 93429151.66it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NykHdWHSTs2z",
        "outputId": "0db353f7-543b-416e-f312-2b8785aeb895"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose random forget indecies from some class\n",
        "# Index of class\n",
        "class_index = 1 # cars\n",
        "class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "# Percantage of whole data ( from class )\n",
        "amount = 0.01 # 1 %\n",
        "amount_int = class_set.shape[0] * amount\n",
        "\n",
        "# Get indeces\n",
        "forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "# construct indices of retain from those of the forget set\n",
        "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "forget_mask[forget_idx] = True\n",
        "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "# split train set into a forget and a retain set\n",
        "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "# Generate forget and retain loaders\n",
        "forget_loader = torch.utils.data.DataLoader(\n",
        "    forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")\n",
        "retain_loader = torch.utils.data.DataLoader(\n",
        "    retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")"
      ],
      "metadata": {
        "id": "nbD4rJVLTrRh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add helping dicts\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": test_loader\n",
        "}\n",
        "\n",
        "dataset_sizes = {\"train\": len(train_set), \"val\": len(test_set)}"
      ],
      "metadata": {
        "id": "TLN-G2k9T-nj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_loss = 1000\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(DEVICE)\n",
        "                    labels = labels.to(DEVICE)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_loss < best_loss:\n",
        "                    best_loss = epoch_loss\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val loss: {best_loss:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "3yWjdU4eUCjx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ResNet18\n",
        "\n",
        "model_train = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_train = model_train.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_train.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "g6RsNI0EUaT7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f94VGw_Ucil",
        "outputId": "04415895-895e-4544-b874-13aefd875988"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check accuracy\n",
        "\n",
        "def accuracy(net, loader):\n",
        "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "print(f\"Train set accuracy: {100.0 * accuracy(model_train, train_loader):0.1f}%\")\n",
        "print(f\"Test set accuracy: {100.0 * accuracy(model_train, test_loader):0.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8zYw0twW30H",
        "outputId": "e85fb8dc-5ab6-41f7-d2fa-ac79d1a5a35d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 97.7%\n",
            "Test set accuracy: 76.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def unlearning(\n",
        "    net,\n",
        "    retain_loader,\n",
        "    forget_loader,\n",
        "    val_loader):\n",
        "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    class CustomCrossEntropyLoss(nn.Module):\n",
        "        def __init__(self, class_weights=None):\n",
        "            super(CustomCrossEntropyLoss, self).__init__()\n",
        "            self.class_weights = class_weights\n",
        "\n",
        "        def forward(self, input, target):\n",
        "            # Compute the standard cross-entropy loss\n",
        "            ce_loss = nn.functional.cross_entropy(input, target)\n",
        "\n",
        "            # Apply class weights to the loss if provided\n",
        "            if self.class_weights is not None:\n",
        "                # Calculate the weights for each element in the batch based on the target\n",
        "                weights = torch.tensor([self.class_weights[i] for i in target], device=input.device)\n",
        "                ce_loss = torch.mean(ce_loss * weights)\n",
        "\n",
        "            return ce_loss\n",
        "\n",
        "\n",
        "\n",
        "    # Define the vision_confuser function\n",
        "    def vision_confuser(model, std = 0.6):\n",
        "        for name, module in model.named_children():\n",
        "            if hasattr(module, 'weight'):\n",
        "                if 'conv' in name:\n",
        "\n",
        "                    actual_value = module.weight.clone().detach()\n",
        "                    new_values = torch.normal(mean=actual_value, std=std)\n",
        "                    module.weight.data.copy_(new_values)\n",
        "\n",
        "    vision_confuser(net)\n",
        "\n",
        "    epochs = 4\n",
        "\n",
        "    # w = 0.05\n",
        "\n",
        "    # class_weights = [1, w, w, w, w, w, w, w, w, w]\n",
        "    criterion = CustomCrossEntropyLoss(None)\n",
        "\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.0007,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=epochs)\n",
        "\n",
        "    net.train()\n",
        "    i=0\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        i=0\n",
        "        net.train()\n",
        "        for sample in retain_loader:\n",
        "            inputs = sample[0]\n",
        "            targets = sample[1]\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if (ep == epochs-2):\n",
        "            vision_confuser(net , 0.005) # increase model robustness before last training epoch\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    net.eval()\n",
        "    return net"
      ],
      "metadata": {
        "id": "6wc09qONYMDE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_losses(net, loader):\n",
        "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    all_losses = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        logits = net(inputs)\n",
        "        losses = criterion(logits, targets).numpy(force=True)\n",
        "        for l in losses:\n",
        "            all_losses.append(l)\n",
        "\n",
        "    return np.array(all_losses)"
      ],
      "metadata": {
        "id": "KkBF3J-5YOwN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MIA score\n",
        "\n",
        "\n",
        "def simple_mia(sample_loss, members, n_splits=10, random_state=0):\n",
        "    \"\"\"Computes cross-validation score of a membership inference attack.\n",
        "\n",
        "    Args:\n",
        "      sample_loss : array_like of shape (n,).\n",
        "        objective function evaluated on n samples.\n",
        "      members : array_like of shape (n,),\n",
        "        whether a sample was used for training.\n",
        "      n_splits: int\n",
        "        number of splits to use in the cross-validation.\n",
        "    Returns:\n",
        "      scores : array_like of size (n_splits,)\n",
        "    \"\"\"\n",
        "\n",
        "    unique_members = np.unique(members)\n",
        "    if not np.all(unique_members == np.array([0, 1])):\n",
        "        raise ValueError(\"members should only have 0 and 1s\")\n",
        "\n",
        "    attack_model = linear_model.LogisticRegression()\n",
        "    cv = model_selection.StratifiedShuffleSplit(\n",
        "        n_splits=n_splits, random_state=random_state\n",
        "    )\n",
        "    return model_selection.cross_val_score(\n",
        "        attack_model, sample_loss, members, cv=cv, scoring=\"accuracy\"\n",
        "    )"
      ],
      "metadata": {
        "id": "EjaFXOXbYTME"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = compute_losses(model_train, train_loader)\n",
        "test_losses = compute_losses(model_train, test_loader)\n",
        "\n",
        "# TRAIN MODEL\n",
        "# Get random test samples\n",
        "randomize = np.arange(len(test_losses))\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Compute forget losses on train dataset\n",
        "forget_losses = compute_losses(model_train, forget_loader)\n",
        "\n",
        "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "test_losses = test_losses[randomize][: len(forget_losses)]\n",
        "\n",
        "samples_mia = np.concatenate((test_losses, forget_losses)).reshape((-1, 1))\n",
        "labels_mia = [0] * len(test_losses) + [1] * len(forget_losses)\n",
        "\n",
        "mia_scores = simple_mia(samples_mia, labels_mia)\n",
        "\n",
        "print(\n",
        "    f\"The MIA has an accuracy of {mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtD2G9oKZPjP",
        "outputId": "596a1e62-e787-4056-cf5a-af7717a193ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIA has an accuracy of 0.900 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- 1 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.01 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJYSFgoGYVt6",
        "outputId": "d2c51083-a949-4221-a794-7fe1828b2a67"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 1 PERCENT -------\n",
            "Retain set accuracy FORGET model: 59.1%\n",
            "Test set accuracy FORGET model: 54.7%\n",
            "Forget set accuracy FORGET model: 74.0%\n",
            "The MIA has an accuracy of 0.660 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 56.0%\n",
            "Test set accuracy FORGET model: 53.1%\n",
            "Forget set accuracy FORGET model: 50.0%\n",
            "The MIA has an accuracy of 0.420 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 58.0%\n",
            "Test set accuracy FORGET model: 54.0%\n",
            "Forget set accuracy FORGET model: 32.0%\n",
            "The MIA has an accuracy of 0.670 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 57.9%\n",
            "Test set accuracy FORGET model: 53.6%\n",
            "Forget set accuracy FORGET model: 46.0%\n",
            "The MIA has an accuracy of 0.470 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 57.0%\n",
            "Test set accuracy FORGET model: 54.1%\n",
            "Forget set accuracy FORGET model: 58.0%\n",
            "The MIA has an accuracy of 0.600 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 57.6%\n",
            "Test set accuracy FORGET model: 53.7%\n",
            "Forget set accuracy FORGET model: 60.0%\n",
            "The MIA has an accuracy of 0.410 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 57.8%\n",
            "Test set accuracy FORGET model: 54.5%\n",
            "Forget set accuracy FORGET model: 58.0%\n",
            "The MIA has an accuracy of 0.540 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 61.2%\n",
            "Test set accuracy FORGET model: 56.2%\n",
            "Forget set accuracy FORGET model: 60.0%\n",
            "The MIA has an accuracy of 0.410 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 61.3%\n",
            "Test set accuracy FORGET model: 55.9%\n",
            "Forget set accuracy FORGET model: 64.0%\n",
            "The MIA has an accuracy of 0.560 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 58.3%\n",
            "Test set accuracy FORGET model: 54.5%\n",
            "Forget set accuracy FORGET model: 60.0%\n",
            "The MIA has an accuracy of 0.590 on forgotten vs unseen images on FORGET model\n",
            "[0.6599999999999999, 0.4200000000000001, 0.67, 0.47000000000000003, 0.6, 0.41, 0.5399999999999999, 0.41, 0.5599999999999999, 0.5900000000000001]\n",
            "[59.14514514514515, 56.04004004004004, 58.007687379884686, 57.91675842325479, 56.96296296296296, 57.5955955955956, 57.84984984984985, 61.169169169169166, 61.34134134134134, 58.33717042701848]\n",
            "[74.0, 50.0, 32.0, 46.0, 57.99999999999999, 60.0, 57.99999999999999, 60.0, 64.0, 60.0]\n",
            "[54.67999999999999, 53.06999999999999, 54.0, 53.63, 54.11, 53.72, 54.510000000000005, 56.2, 55.910000000000004, 54.53]\n",
            "MEANS\n",
            "0.533\n",
            "58.4365720334262\n",
            "56.2\n",
            "54.436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- 2 PERCANTAGES -----\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.02 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mac5VywIfiQL",
        "outputId": "9bee31b9-510a-4e22-b2ce-2be7e2d2b9ee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 2 PERCANTAGES -----\n",
            "Retain set accuracy FORGET model: 57.5%\n",
            "Test set accuracy FORGET model: 53.6%\n",
            "Forget set accuracy FORGET model: 72.0%\n",
            "The MIA has an accuracy of 0.693 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 59.6%\n",
            "Test set accuracy FORGET model: 55.7%\n",
            "Forget set accuracy FORGET model: 67.0%\n",
            "The MIA has an accuracy of 0.653 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 60.7%\n",
            "Test set accuracy FORGET model: 55.5%\n",
            "Forget set accuracy FORGET model: 42.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 57.2%\n",
            "Test set accuracy FORGET model: 53.7%\n",
            "Forget set accuracy FORGET model: 35.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 58.1%\n",
            "Test set accuracy FORGET model: 54.2%\n",
            "Forget set accuracy FORGET model: 54.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 61.0%\n",
            "Test set accuracy FORGET model: 56.9%\n",
            "Forget set accuracy FORGET model: 48.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 59.9%\n",
            "Test set accuracy FORGET model: 55.9%\n",
            "Forget set accuracy FORGET model: 65.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 62.7%\n",
            "Test set accuracy FORGET model: 57.3%\n",
            "Forget set accuracy FORGET model: 64.0%\n",
            "The MIA has an accuracy of 0.660 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 56.0%\n",
            "Test set accuracy FORGET model: 52.9%\n",
            "Forget set accuracy FORGET model: 63.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 61.5%\n",
            "Test set accuracy FORGET model: 56.5%\n",
            "Forget set accuracy FORGET model: 66.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "[0.6933333333333332, 0.6533333333333332, 0.6666666666666667, 0.6666666666666667, 0.6666666666666667, 0.6666666666666667, 0.6666666666666667, 0.6599999999999999, 0.6666666666666667, 0.6666666666666667]\n",
            "[57.54594096310696, 59.55792469088795, 60.6881625618725, 57.24048096192384, 58.08100038075389, 61.04008016032064, 59.930662712170104, 62.70089375175344, 56.04897697440933, 61.54185286867999]\n",
            "[72.0, 67.0, 42.0, 35.0, 54.0, 48.0, 65.0, 64.0, 63.0, 66.0]\n",
            "[53.61, 55.66, 55.55, 53.669999999999995, 54.190000000000005, 56.92, 55.910000000000004, 57.269999999999996, 52.88, 56.53]\n",
            "MEANS\n",
            "0.6673333333333334\n",
            "59.43759760258786\n",
            "57.6\n",
            "55.21900000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- 5 PERCANTAGES -----\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.05 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQdsk6KTfl9q",
        "outputId": "99499c1d-a94b-4ca1-fd18-5f9fe53eaf6e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 5 PERCANTAGES -----\n",
            "Retain set accuracy FORGET model: 58.2%\n",
            "Test set accuracy FORGET model: 54.8%\n",
            "Forget set accuracy FORGET model: 65.2%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 59.5%\n",
            "Test set accuracy FORGET model: 55.3%\n",
            "Forget set accuracy FORGET model: 75.2%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 55.2%\n",
            "Test set accuracy FORGET model: 51.9%\n",
            "Forget set accuracy FORGET model: 39.6%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 63.1%\n",
            "Test set accuracy FORGET model: 58.0%\n",
            "Forget set accuracy FORGET model: 48.8%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 58.4%\n",
            "Test set accuracy FORGET model: 54.7%\n",
            "Forget set accuracy FORGET model: 51.2%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 58.4%\n",
            "Test set accuracy FORGET model: 54.2%\n",
            "Forget set accuracy FORGET model: 53.6%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 58.2%\n",
            "Test set accuracy FORGET model: 54.6%\n",
            "Forget set accuracy FORGET model: 66.0%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 59.5%\n",
            "Test set accuracy FORGET model: 55.1%\n",
            "Forget set accuracy FORGET model: 63.2%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 55.8%\n",
            "Test set accuracy FORGET model: 53.1%\n",
            "Forget set accuracy FORGET model: 70.0%\n",
            "The MIA has an accuracy of 0.823 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 56.6%\n",
            "Test set accuracy FORGET model: 52.8%\n",
            "Forget set accuracy FORGET model: 57.2%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images on FORGET model\n",
            "[0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8233333333333333, 0.8333333333333334]\n",
            "[58.18828636893516, 59.514910376979344, 55.204083683353765, 63.1185432327049, 58.36800321575721, 58.36565709347429, 58.17304793488092, 59.54859715411207, 55.819749562840435, 56.63725706935707]\n",
            "[65.2, 75.2, 39.6, 48.8, 51.2, 53.6, 66.0, 63.2, 70.0, 57.199999999999996]\n",
            "[54.82, 55.32, 51.88, 57.98, 54.669999999999995, 54.17999999999999, 54.59, 55.15, 53.06999999999999, 52.800000000000004]\n",
            "MEANS\n",
            "0.8323333333333333\n",
            "58.29381356923951\n",
            "59.0\n",
            "54.446000000000005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- 10 % -----\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.1 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bBQIyMflpv8",
        "outputId": "78b7fc71-fa8b-4e6e-ab45-6eb78c5c3709"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 10 % -----\n",
            "Retain set accuracy FORGET model: 62.9%\n",
            "Test set accuracy FORGET model: 58.4%\n",
            "Forget set accuracy FORGET model: 67.6%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 61.9%\n",
            "Test set accuracy FORGET model: 57.5%\n",
            "Forget set accuracy FORGET model: 64.2%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 59.0%\n",
            "Test set accuracy FORGET model: 55.2%\n",
            "Forget set accuracy FORGET model: 36.8%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 55.4%\n",
            "Test set accuracy FORGET model: 52.8%\n",
            "Forget set accuracy FORGET model: 32.8%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 59.5%\n",
            "Test set accuracy FORGET model: 54.3%\n",
            "Forget set accuracy FORGET model: 47.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 60.4%\n",
            "Test set accuracy FORGET model: 55.6%\n",
            "Forget set accuracy FORGET model: 46.2%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 61.4%\n",
            "Test set accuracy FORGET model: 56.5%\n",
            "Forget set accuracy FORGET model: 64.0%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 64.0%\n",
            "Test set accuracy FORGET model: 58.0%\n",
            "Forget set accuracy FORGET model: 60.8%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 54.7%\n",
            "Test set accuracy FORGET model: 52.0%\n",
            "Forget set accuracy FORGET model: 61.4%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model: 60.3%\n",
            "Test set accuracy FORGET model: 56.0%\n",
            "Forget set accuracy FORGET model: 62.4%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images on FORGET model\n",
            "[0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.909090909090909]\n",
            "[62.917945404619616, 61.85985460420033, 58.99895008883864, 55.394216010986355, 59.46202467739655, 60.37232968541776, 61.41140837960626, 63.99507279739909, 54.71781928319031, 60.32547246002261]\n",
            "[67.60000000000001, 64.2, 36.8, 32.800000000000004, 47.0, 46.2, 64.0, 60.8, 61.4, 62.4]\n",
            "[58.36, 57.52, 55.169999999999995, 52.81, 54.290000000000006, 55.58, 56.53, 57.99999999999999, 52.03, 56.05]\n",
            "MEANS\n",
            "0.909090909090909\n",
            "59.94550933916776\n",
            "54.32000000000001\n",
            "55.63399999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "MIA_scores_retain = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "AD_score = []\n",
        "# Define model from trained params\n",
        "\n",
        "model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_forget_ft.load_state_dict(torch.load(\"model_train_params_best_loss.pt\"))\n",
        "model_forget_ft.to(DEVICE)\n",
        "\n",
        "for epoch_num in range(10):\n",
        "\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.02 # 2 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning_by_epochs(model_forget_ft, retain_loader, forget_loader, test_loader, 1)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model epoch {epoch_num}: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model epoch {epoch_num}: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model {epoch_num}:: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # Retain model\n",
        "  # Add helping dicts\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "\n",
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        "\n",
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "mean_accuracy_test = sum(Accuracy_test) / len(Accuracy_test)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)\n",
        "\n",
        "print(\"MEANS\")\n",
        "\n",
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)\n",
        "print(mean_accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvML-PLBqpsq",
        "outputId": "87174b2c-cae1-4abd-8653-b65d7ef0c01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retain set accuracy FORGET model epoch 0: 81.6%\n",
            "Test set accuracy FORGET model epoch 0: 70.8%\n",
            "Forget set accuracy FORGET model 0:: 81.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 1: 85.1%\n",
            "Test set accuracy FORGET model epoch 1: 72.0%\n",
            "Forget set accuracy FORGET model 1:: 95.0%\n",
            "The MIA has an accuracy of 0.767 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 2: 87.0%\n",
            "Test set accuracy FORGET model epoch 2: 71.5%\n",
            "Forget set accuracy FORGET model 2:: 81.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 3: 89.2%\n",
            "Test set accuracy FORGET model epoch 3: 72.9%\n",
            "Forget set accuracy FORGET model 3:: 85.0%\n",
            "The MIA has an accuracy of 0.667 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 4: 87.8%\n",
            "Test set accuracy FORGET model epoch 4: 71.9%\n",
            "Forget set accuracy FORGET model 4:: 83.0%\n",
            "The MIA has an accuracy of 0.640 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 5: 89.8%\n",
            "Test set accuracy FORGET model epoch 5: 72.2%\n",
            "Forget set accuracy FORGET model 5:: 97.0%\n",
            "The MIA has an accuracy of 0.687 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 6: 88.6%\n",
            "Test set accuracy FORGET model epoch 6: 71.3%\n",
            "Forget set accuracy FORGET model 6:: 90.0%\n",
            "The MIA has an accuracy of 0.693 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 7: 88.5%\n",
            "Test set accuracy FORGET model epoch 7: 70.1%\n",
            "Forget set accuracy FORGET model 7:: 93.0%\n",
            "The MIA has an accuracy of 0.707 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 8: 88.7%\n",
            "Test set accuracy FORGET model epoch 8: 71.1%\n",
            "Forget set accuracy FORGET model 8:: 86.0%\n",
            "The MIA has an accuracy of 0.647 on forgotten vs unseen images on FORGET model\n",
            "Retain set accuracy FORGET model epoch 9: 89.2%\n",
            "Test set accuracy FORGET model epoch 9: 70.8%\n",
            "Forget set accuracy FORGET model 9:: 88.0%\n",
            "The MIA has an accuracy of 0.660 on forgotten vs unseen images on FORGET model\n",
            "[0.6666666666666667, 0.7666666666666667, 0.6666666666666667, 0.6666666666666667, 0.6399999999999999, 0.6866666666666666, 0.6933333333333334, 0.7066666666666667, 0.6466666666666667, 0.6599999999999999]\n",
            "[81.64966633935191, 85.10049898799623, 87.01707277973709, 89.24291611558655, 87.84168336673346, 89.7639373171416, 88.60721442885772, 88.48496993987976, 88.71743486973948, 89.24091218788827]\n",
            "[81.0, 95.0, 81.0, 85.0, 83.0, 97.0, 90.0, 93.0, 86.0, 88.0]\n",
            "[70.78, 72.02, 71.55, 72.89999999999999, 71.87, 72.21, 71.26, 70.11, 71.11, 70.83]\n",
            "MEANS\n",
            "0.68\n",
            "87.56663063329121\n",
            "87.9\n",
            "71.464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9F7cNNckviux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}