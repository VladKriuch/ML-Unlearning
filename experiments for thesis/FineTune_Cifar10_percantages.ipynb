{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B96y1Mf-OtJ",
        "outputId": "c966a5d8-d053-43d9-b39b-bc05ca312bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on device:\", DEVICE.upper())\n",
        "\n",
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 - Loading dataset"
      ],
      "metadata": {
        "id": "gj3HLtBC-lqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR 10 dataset\n",
        "\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=normalize\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihzzETpC-jUM",
        "outputId": "e49a2b6b-530c-4e65-f192-17bf720ad83c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 - split train set on forget / retain"
      ],
      "metadata": {
        "id": "wm1myjb6-xUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgagptIX-2zm",
        "outputId": "a0b5f4f5-1d7c-48b9-c0e7-5323f2dc52e9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose random forget indecies from some class\n",
        "# Index of class\n",
        "class_index = 1 # cars\n",
        "class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "# Percantage of whole data ( from class )\n",
        "amount = 0.01 # 1 %\n",
        "amount_int = class_set.shape[0] * amount\n",
        "\n",
        "# Get indeces\n",
        "forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "# construct indices of retain from those of the forget set\n",
        "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "forget_mask[forget_idx] = True\n",
        "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "# split train set into a forget and a retain set\n",
        "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "# Generate forget and retain loaders\n",
        "forget_loader = torch.utils.data.DataLoader(\n",
        "    forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")\n",
        "retain_loader = torch.utils.data.DataLoader(\n",
        "    retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")"
      ],
      "metadata": {
        "id": "OicwHBBM-vNh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add helping dicts\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": test_loader\n",
        "}\n",
        "\n",
        "dataset_sizes = {\"train\": len(train_set), \"val\": len(test_set)}"
      ],
      "metadata": {
        "id": "D2785w3m_Xs_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 - Choose and train model"
      ],
      "metadata": {
        "id": "ZzyrEfA3_i9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(DEVICE)\n",
        "                    labels = labels.to(DEVICE)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model"
      ],
      "metadata": {
        "id": "nPbGOf5N_feA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ResNet18\n",
        "\n",
        "model_train = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_train = model_train.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_train.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "xduiPS5D_sfb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model_train = train_model(model_train, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDk03T-y__od",
        "outputId": "e81bad03-cace-45fe-9fd5-473f7825b18d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 1.3809 Acc: 0.5029\n",
            "val Loss: 1.2731 Acc: 0.5502\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.9771 Acc: 0.6524\n",
            "val Loss: 1.0384 Acc: 0.6399\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.7935 Acc: 0.7213\n",
            "val Loss: 0.9393 Acc: 0.6786\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.6567 Acc: 0.7706\n",
            "val Loss: 0.9556 Acc: 0.6795\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.5483 Acc: 0.8078\n",
            "val Loss: 0.8511 Acc: 0.7234\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.4587 Acc: 0.8406\n",
            "val Loss: 0.8680 Acc: 0.7216\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.3752 Acc: 0.8686\n",
            "val Loss: 0.8952 Acc: 0.7287\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.1536 Acc: 0.9524\n",
            "val Loss: 0.7961 Acc: 0.7686\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.0803 Acc: 0.9788\n",
            "val Loss: 0.8647 Acc: 0.7664\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.0463 Acc: 0.9901\n",
            "val Loss: 0.9624 Acc: 0.7660\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.0270 Acc: 0.9950\n",
            "val Loss: 1.0593 Acc: 0.7621\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.0144 Acc: 0.9980\n",
            "val Loss: 1.1752 Acc: 0.7626\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.0079 Acc: 0.9992\n",
            "val Loss: 1.2665 Acc: 0.7637\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.0049 Acc: 0.9995\n",
            "val Loss: 1.3827 Acc: 0.7630\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.0029 Acc: 0.9998\n",
            "val Loss: 1.3871 Acc: 0.7621\n",
            "\n",
            "Training complete in 5m 16s\n",
            "Best val Acc: 0.768600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model weights\n",
        "torch.save(model_train.state_dict(), \"model_train_params.pt\")"
      ],
      "metadata": {
        "id": "xfwMQf2LAJP1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 - Check accuracy on trained model"
      ],
      "metadata": {
        "id": "x6OEEjY_BujK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(net, loader):\n",
        "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "print(f\"Train set accuracy: {100.0 * accuracy(model_train, train_loader):0.1f}%\")\n",
        "print(f\"Test set accuracy: {100.0 * accuracy(model_train, test_loader):0.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKTXLydeBg1r",
        "outputId": "05b5ed5b-5749-441f-9196-cd61e009f1df"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy: 98.2%\n",
            "Test set accuracy: 76.9%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 - Apply forget mechanism"
      ],
      "metadata": {
        "id": "SegdzHaLB_ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def unlearning(net, retain, forget, validation):\n",
        "    \"\"\"Unlearning by fine-tuning.\n",
        "\n",
        "    Fine-tuning is a very simple algorithm that trains using only\n",
        "    the retain set.\n",
        "\n",
        "    Args:\n",
        "      net : nn.Module.\n",
        "        pre-trained model to use as base of unlearning.\n",
        "      retain : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the retain set. This is the subset\n",
        "        of the training set that we don't want to forget.\n",
        "      forget : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the forget set. This is the subset\n",
        "        of the training set that we want to forget. This method doesn't\n",
        "        make use of the forget set.\n",
        "      validation : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the validation set. This method doesn't\n",
        "        make use of the validation set.\n",
        "    Returns:\n",
        "      net : updated model\n",
        "    \"\"\"\n",
        "    epochs = 5\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    net.train()\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for inputs, targets in retain:\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    net.eval()\n",
        "    return net"
      ],
      "metadata": {
        "id": "ZH_lPNnXCZwp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model from trained params\n",
        "\n",
        "model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_forget_ft.load_state_dict(torch.load(\"model_train_params.pt\"))\n",
        "model_forget_ft.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC_wSWCRBzmj",
        "outputId": "3d8b0a00-2b64-439d-de55-2f3b1f03e7a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unlearn model\n",
        "%%time\n",
        "model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHoFN6VqCR9R",
        "outputId": "73dfca32-b6b2-4a53-a2b9-21214c81c616"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 39.1 s, sys: 2.1 s, total: 41.2 s\n",
            "Wall time: 1min 23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare accuracy\n",
        "print(f\"Retain set accuracy: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "print(f\"Test set accuracy: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K8RlkXcCWP6",
        "outputId": "1e9e8987-2454-47c1-d052-a221f5492f33"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 77.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 - Compare loss graphs"
      ],
      "metadata": {
        "id": "hAoijxekDMMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_losses(net, loader):\n",
        "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    all_losses = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        logits = net(inputs)\n",
        "        losses = criterion(logits, targets).numpy(force=True)\n",
        "        for l in losses:\n",
        "            all_losses.append(l)\n",
        "\n",
        "    return np.array(all_losses)\n",
        "\n",
        "\n",
        "train_losses = compute_losses(model_train, train_loader)\n",
        "test_losses = compute_losses(model_train, test_loader)"
      ],
      "metadata": {
        "id": "hY2ukoVMDDk3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def simple_mia(sample_loss, members, n_splits=10, random_state=0):\n",
        "    \"\"\"Computes cross-validation score of a membership inference attack.\n",
        "\n",
        "    Args:\n",
        "      sample_loss : array_like of shape (n,).\n",
        "        objective function evaluated on n samples.\n",
        "      members : array_like of shape (n,),\n",
        "        whether a sample was used for training.\n",
        "      n_splits: int\n",
        "        number of splits to use in the cross-validation.\n",
        "    Returns:\n",
        "      scores : array_like of size (n_splits,)\n",
        "    \"\"\"\n",
        "\n",
        "    unique_members = np.unique(members)\n",
        "    if not np.all(unique_members == np.array([0, 1])):\n",
        "        raise ValueError(\"members should only have 0 and 1s\")\n",
        "\n",
        "    attack_model = linear_model.LogisticRegression()\n",
        "    cv = model_selection.StratifiedShuffleSplit(\n",
        "        n_splits=n_splits, random_state=random_state\n",
        "    )\n",
        "    return model_selection.cross_val_score(\n",
        "        attack_model, sample_loss, members, cv=cv, scoring=\"accuracy\"\n",
        "    )\n",
        ""
      ],
      "metadata": {
        "id": "gKEHxxK8DVQp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN MODEL\n",
        "# Get random test samples\n",
        "randomize = np.arange(len(test_losses))\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Compute forget losses on train dataset\n",
        "forget_losses = compute_losses(model_train, forget_loader)\n",
        "\n",
        "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "test_losses = test_losses[randomize][: len(forget_losses)]\n",
        "\n",
        "samples_mia = np.concatenate((test_losses, forget_losses)).reshape((-1, 1))\n",
        "labels_mia = [0] * len(test_losses) + [1] * len(forget_losses)\n",
        "\n",
        "mia_scores = simple_mia(samples_mia, labels_mia)\n",
        "\n",
        "print(\n",
        "    f\"The MIA has an accuracy of {mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
        ")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8HXjdLhDxUp",
        "outputId": "e5410aa4-2949-4c04-d55d-c5900fb23ab6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIA has an accuracy of 0.780 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FORGET MODEL\n",
        "\n",
        "# Compute forget losses for forget model\n",
        "forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "# make sure we have a balanced dataset for the MIA\n",
        "samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "\n",
        "print(\n",
        "    f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KaKFOaNEGBd",
        "outputId": "59f0b1cd-e6e0-4129-c50d-5db445065593"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIA has an accuracy of 0.530 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "ax1.set_title(f\"Pre-trained model.\\nAttack accuracy: {mia_scores.mean():0.2f}\")\n",
        "ax1.hist(test_losses, density=True, alpha=0.5, bins=5, label=\"Test set\")\n",
        "ax1.hist(forget_losses, density=True, alpha=0.5, bins=5, label=\"Forget set\")\n",
        "\n",
        "ax2.set_title(\n",
        "    f\"Unlearned by fine-tuning.\\nAttack accuracy: {mia_scores_fr.mean():0.2f}\"\n",
        ")\n",
        "ax2.hist(test_losses_fr, density=True, alpha=0.5, bins=5, label=\"Test set\")\n",
        "ax2.hist(forget_losses_fr, density=True, alpha=0.5, bins=5, label=\"Forget set\")\n",
        "\n",
        "ax1.set_xlabel(\"Loss\")\n",
        "ax2.set_xlabel(\"Loss\")\n",
        "ax1.set_ylabel(\"Frequency\")\n",
        "ax1.set_yscale(\"log\")\n",
        "ax2.set_yscale(\"log\")\n",
        "ax1.set_xlim((0, np.max(test_losses)))\n",
        "ax2.set_xlim((0, np.max(test_losses)))\n",
        "for ax in (ax1, ax2):\n",
        "    ax.spines[\"top\"].set_visible(False)\n",
        "    ax.spines[\"right\"].set_visible(False)\n",
        "ax1.legend(frameon=False, fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "i0Qn32VmE2OK",
        "outputId": "f23bdc2d-f061-46d9-aebb-abe8a0f85840"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6 - Retrained model only on retain dataset"
      ],
      "metadata": {
        "id": "ANYmxQoSFeMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ResNet18\n",
        "\n",
        "model_retain_ds = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_retain_ds = model_retain_ds.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_retain_ds.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "XRPVvg5bFF4z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add helping dicts\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": retain_loader,\n",
        "    \"val\": test_loader\n",
        "}\n",
        "\n",
        "dataset_sizes = {\"train\": len(retain_set), \"val\": len(test_set)}\n",
        "\n",
        "# Train model\n",
        "model_retain_ds = train_model(model_retain_ds, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkSK5UKcFnxY",
        "outputId": "bd1354e3-f222-439e-f02e-ca03292e3720"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 1.3746 Acc: 0.5051\n",
            "val Loss: 1.2275 Acc: 0.5639\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.9891 Acc: 0.6487\n",
            "val Loss: 0.9950 Acc: 0.6563\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.8018 Acc: 0.7188\n",
            "val Loss: 0.9206 Acc: 0.6832\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.6667 Acc: 0.7646\n",
            "val Loss: 0.8603 Acc: 0.7072\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.5599 Acc: 0.8021\n",
            "val Loss: 0.9153 Acc: 0.6949\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.4718 Acc: 0.8341\n",
            "val Loss: 1.0103 Acc: 0.6846\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.3800 Acc: 0.8670\n",
            "val Loss: 0.9287 Acc: 0.7239\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.1611 Acc: 0.9507\n",
            "val Loss: 0.7741 Acc: 0.7740\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.0880 Acc: 0.9761\n",
            "val Loss: 0.8341 Acc: 0.7721\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.0529 Acc: 0.9876\n",
            "val Loss: 0.9246 Acc: 0.7700\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.0290 Acc: 0.9938\n",
            "val Loss: 1.0551 Acc: 0.7677\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.0157 Acc: 0.9975\n",
            "val Loss: 1.2036 Acc: 0.7644\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.0086 Acc: 0.9988\n",
            "val Loss: 1.3097 Acc: 0.7669\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.0056 Acc: 0.9993\n",
            "val Loss: 1.4231 Acc: 0.7645\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.0034 Acc: 0.9996\n",
            "val Loss: 1.4114 Acc: 0.7671\n",
            "\n",
            "Training complete in 5m 11s\n",
            "Best val Acc: 0.774000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MIA attack on retain model\n",
        "\n",
        "# Compute forget losses for forget model\n",
        "forget_losses_rt = compute_losses(model_retain_ds, forget_loader)\n",
        "test_losses_rt = compute_losses(model_retain_ds, test_loader)\n",
        "\n",
        "# Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "test_losses_rt = test_losses_rt[randomize][: len(forget_losses)]\n",
        "\n",
        "# make sure we have a balanced dataset for the MIA\n",
        "samples_mia_rt = np.concatenate((test_losses_rt, forget_losses_rt)).reshape((-1, 1))\n",
        "labels_mia_rt = [0] * len(test_losses_rt) + [1] * len(forget_losses_rt)\n",
        "\n",
        "mia_scores_rt = simple_mia(samples_mia_rt, labels_mia_rt)\n",
        "\n",
        "print(\n",
        "    f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y0XBl8dF6uz",
        "outputId": "2d0ac039-acf8-48b6-8c31-cd32881793f4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIA has an accuracy of 0.530 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate AD statistic"
      ],
      "metadata": {
        "id": "xwf9L9BRMQUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AD = np.linalg.norm(forget_losses_fr-forget_losses_rt)"
      ],
      "metadata": {
        "id": "I31lBxVxMKyU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KaOGb2GMShk",
        "outputId": "3677b261-efa3-4b31-9685-b8d54348570b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.8024845"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7 - Gradient map visualisation"
      ],
      "metadata": {
        "id": "jtmf0m2kMcPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.01 # 1 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0jU_0ZYMknB",
        "outputId": "7dc0961e-a3c3-442c-c754-b4f39bcfa8e5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retain set accuracy: 97.0%\n",
            "Test set accuracy: 75.0%\n",
            "The MIA has an accuracy of 0.550 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.7%\n",
            "Test set accuracy: 77.0%\n",
            "The MIA has an accuracy of 0.590 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 76.9%\n",
            "The MIA has an accuracy of 0.550 on forgotten vs unseen images\n",
            "Retain set accuracy: 98.7%\n",
            "Test set accuracy: 75.6%\n",
            "The MIA has an accuracy of 0.550 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.5%\n",
            "Test set accuracy: 76.2%\n",
            "The MIA has an accuracy of 0.510 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 76.5%\n",
            "The MIA has an accuracy of 0.500 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.7%\n",
            "Test set accuracy: 76.9%\n",
            "The MIA has an accuracy of 0.470 on forgotten vs unseen images\n",
            "Retain set accuracy: 96.6%\n",
            "Test set accuracy: 75.4%\n",
            "The MIA has an accuracy of 0.650 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 77.0%\n",
            "The MIA has an accuracy of 0.540 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.1%\n",
            "Test set accuracy: 76.1%\n",
            "The MIA has an accuracy of 0.620 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXvdoG6ZNZ1M",
        "outputId": "a7cf89a1-3ca0-412a-fb1a-dde670ef686a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.55, 0.59, 0.55, 0.5499999999999999, 0.5099999999999999, 0.5, 0.47000000000000003, 0.65, 0.54, 0.62]\n",
            "[96.96296296296296, 99.72172172172172, 99.76376376376376, 98.70873455986867, 99.49149149149149, 99.84184184184184, 99.71971971971972, 96.63463463463464, 99.84384384384384, 99.08908908908909]\n",
            "[75.05, 76.99000000000001, 76.91, 75.58, 76.2, 76.46, 76.94, 75.38, 76.97, 76.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)"
      ],
      "metadata": {
        "id": "OmWtBawhUgI-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsNHq8X2U08R",
        "outputId": "f7571bd6-077f-4bf5-c19b-1b9e95fdc192"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.553\n",
            "98.97778036289375\n",
            "76.25800000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation 2 %\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.02 # 2 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uyNlqmfOHDP",
        "outputId": "6b973276-5a99-49d7-f6f7-3d977ce25e44"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retain set accuracy: 98.4%\n",
            "Test set accuracy: 76.1%\n",
            "The MIA has an accuracy of 0.687 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.3%\n",
            "Test set accuracy: 75.7%\n",
            "The MIA has an accuracy of 0.640 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 77.1%\n",
            "The MIA has an accuracy of 0.653 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 76.8%\n",
            "The MIA has an accuracy of 0.673 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.3%\n",
            "Test set accuracy: 76.3%\n",
            "The MIA has an accuracy of 0.673 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.5%\n",
            "Test set accuracy: 76.3%\n",
            "The MIA has an accuracy of 0.700 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.4%\n",
            "Test set accuracy: 76.4%\n",
            "The MIA has an accuracy of 0.633 on forgotten vs unseen images\n",
            "Retain set accuracy: 97.5%\n",
            "Test set accuracy: 76.0%\n",
            "The MIA has an accuracy of 0.680 on forgotten vs unseen images\n",
            "Retain set accuracy: 98.7%\n",
            "Test set accuracy: 75.6%\n",
            "The MIA has an accuracy of 0.687 on forgotten vs unseen images\n",
            "Retain set accuracy: 97.9%\n",
            "Test set accuracy: 75.8%\n",
            "The MIA has an accuracy of 0.653 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuvwUHh1VHbh",
        "outputId": "3194ba97-ae6c-464a-e481-ed2cdf0a47b0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6866666666666668, 0.6399999999999999, 0.6533333333333333, 0.6733333333333333, 0.6733333333333335, 0.7, 0.6333333333333332, 0.6799999999999999, 0.6866666666666666, 0.6533333333333334]\n",
            "[98.44695603382631, 99.2605358610048, 99.84569447506063, 99.8056112224449, 99.33269207646988, 99.46092184368737, 99.4188376753507, 97.46893787575151, 98.65130260521042, 97.94000360699758]\n",
            "[76.07000000000001, 75.73, 77.14, 76.78, 76.28, 76.27000000000001, 76.36, 76.01, 75.6, 75.84]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)"
      ],
      "metadata": {
        "id": "xN3JStUgafkT"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iou45Mmgai5w",
        "outputId": "b9ae822a-f9ad-4ba9-93ed-4c4685e9da12"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6679999999999999\n",
            "98.9631493275804\n",
            "76.208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation 2 %\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.05 # 2 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMiu8QmXajDz",
        "outputId": "8f356b6d-ce82-4b26-a862-37c192cfd783"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retain set accuracy: 98.2%\n",
            "Test set accuracy: 75.5%\n",
            "The MIA has an accuracy of 0.820 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.3%\n",
            "Test set accuracy: 75.9%\n",
            "The MIA has an accuracy of 0.817 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.6%\n",
            "Test set accuracy: 76.5%\n",
            "The MIA has an accuracy of 0.850 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.1%\n",
            "Test set accuracy: 76.0%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images\n",
            "Retain set accuracy: 96.7%\n",
            "Test set accuracy: 75.6%\n",
            "The MIA has an accuracy of 0.827 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.1%\n",
            "Test set accuracy: 76.4%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images\n",
            "Retain set accuracy: 93.6%\n",
            "Test set accuracy: 74.2%\n",
            "The MIA has an accuracy of 0.823 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.6%\n",
            "Test set accuracy: 76.5%\n",
            "The MIA has an accuracy of 0.830 on forgotten vs unseen images\n",
            "Retain set accuracy: 98.9%\n",
            "Test set accuracy: 76.7%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 76.6%\n",
            "The MIA has an accuracy of 0.833 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztV6oXO6amCK",
        "outputId": "d009bb5a-3fa1-4e9f-f46d-c8c761f293ce"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.82, 0.8166666666666667, 0.8500000000000002, 0.8333333333333334, 0.8266666666666665, 0.8333333333333334, 0.8233333333333333, 0.8299999999999998, 0.8333333333333334, 0.8333333333333334]\n",
            "[98.20728741684587, 99.28251301324437, 99.56990111745317, 99.12575115059188, 96.69360025727609, 99.12970072156453, 93.64862420356562, 99.64225420049844, 98.8805820169621, 99.75278369578325]\n",
            "[75.53, 75.94999999999999, 76.48, 75.97, 75.6, 76.37, 74.16, 76.51, 76.71, 76.61]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)"
      ],
      "metadata": {
        "id": "v_rMYx8cf_eI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9SGMhz7gBy8",
        "outputId": "99c6e256-8eb7-47a9-e9cc-3c09c7b27687"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8299999999999998\n",
            "98.39329977937854\n",
            "75.989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalisation 2 %\n",
        "# Calculating score across 10 different classes\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "MIA_scores = []\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "AD_score = []\n",
        "\n",
        "for class_num in classes:\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(\"model_train_params.pt\"))\n",
        "  model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount = 0.1 # 2 %\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "\n",
        "  # MIA\n",
        "\n",
        "  # Compute forget losses for forget model\n",
        "  forget_losses_fr = compute_losses(model_ft_forget, forget_loader)\n",
        "  test_losses_fr = compute_losses(model_ft_forget, test_loader)\n",
        "\n",
        "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
        "  test_losses_fr = test_losses_fr[randomize][: len(forget_losses)]\n",
        "\n",
        "  # make sure we have a balanced dataset for the MIA\n",
        "  samples_mia_fr = np.concatenate((test_losses_fr, forget_losses_fr)).reshape((-1, 1))\n",
        "  labels_mia_fr = [0] * len(test_losses_fr) + [1] * len(forget_losses_fr)\n",
        "\n",
        "  mia_scores_fr = simple_mia(samples_mia_fr, labels_mia_fr)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr.mean():.3f} on forgotten vs unseen images\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxRsRkkkgDaS",
        "outputId": "454400cb-3e9f-41fa-f549-1f3407312116"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retain set accuracy: 96.2%\n",
            "Test set accuracy: 75.4%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.2%\n",
            "Test set accuracy: 76.3%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "Retain set accuracy: 98.2%\n",
            "Test set accuracy: 75.8%\n",
            "The MIA has an accuracy of 0.900 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.7%\n",
            "Test set accuracy: 76.5%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.9%\n",
            "Test set accuracy: 76.8%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "Retain set accuracy: 97.0%\n",
            "Test set accuracy: 75.5%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.3%\n",
            "Test set accuracy: 75.8%\n",
            "The MIA has an accuracy of 0.902 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.4%\n",
            "Test set accuracy: 76.1%\n",
            "The MIA has an accuracy of 0.907 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.3%\n",
            "Test set accuracy: 76.8%\n",
            "The MIA has an accuracy of 0.904 on forgotten vs unseen images\n",
            "Retain set accuracy: 99.8%\n",
            "Test set accuracy: 77.1%\n",
            "The MIA has an accuracy of 0.909 on forgotten vs unseen images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIA_scores = [m.mean() for m in MIA_scores]\n",
        "print(MIA_scores)\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6XFZnMjgF6U",
        "outputId": "d49ecbcf-323e-49ab-a853-7c03eb9e1fdf"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.909090909090909, 0.909090909090909, 0.8999999999999998, 0.909090909090909, 0.909090909090909, 0.909090909090909, 0.9018181818181816, 0.907272727272727, 0.9036363636363637, 0.909090909090909]\n",
            "[96.1777652142309, 99.16819769437322, 98.22921293865848, 99.70114896108879, 99.89095315024232, 96.98731927954123, 99.31145885916204, 99.39017002544324, 99.2831758339391, 99.76173168564736]\n",
            "[75.38, 76.25999999999999, 75.77000000000001, 76.52, 76.85, 75.46000000000001, 75.81, 76.12, 76.8, 77.10000000000001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean MIA\n",
        "mean_mia_1 = sum(MIA_scores) / len(MIA_scores)\n",
        "\n",
        "# Mean Accuracy Retain\n",
        "mean_accuracy_retain = sum(Accuracy_retain) / len(Accuracy_retain)\n",
        "\n",
        "# Mean Accuracy forget\n",
        "mean_accuracy_forget = sum(Accuracy_forget) / len(Accuracy_forget)"
      ],
      "metadata": {
        "id": "bff5tt0hg6Sy"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_mia_1)\n",
        "print(mean_accuracy_retain)\n",
        "print(mean_accuracy_forget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHNqFIW5g7vC",
        "outputId": "1514c9d5-1cff-4353-b4e7-83329f376a82"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9067272727272726\n",
            "98.79011336423267\n",
            "76.207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uMVY7WoZkyvg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}