{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys-grbQTQApH",
        "outputId": "125e4050-b88f-4d32-8125-4d07bd4cba2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: CUDA\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on device:\", DEVICE.upper())\n",
        "\n",
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory"
      ],
      "metadata": {
        "id": "p1r58T5xQUpG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR 10 dataset\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "# we split held out data into test and validation set\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=normalize\n",
        ")\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz_mQmXOQWqu",
        "outputId": "1c7835c6-c648-4417-a4de-802011e3d38f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13188017.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(np.array(train_set.targets) == 1)[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5G3h37GQZS0",
        "outputId": "d209931f-cfb9-4800-a269-14d209c643ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose random forget indecies from cars\n",
        "# Index of class\n",
        "class_index = 1\n",
        "class_set = np.where(np.array(train_set.targets) == 1)[0]\n",
        "# Percantage of whole data ( from class )\n",
        "amount = 0.1 # 10 %\n",
        "amount_int = class_set.shape[0] * amount\n",
        "\n",
        "# Get indeces\n",
        "forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "# construct indices of retain from those of the forget set\n",
        "forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "forget_mask[forget_idx] = True\n",
        "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "# split train set into a forget and a retain set\n",
        "forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "forget_loader = torch.utils.data.DataLoader(\n",
        "    forget_set, batch_size=256, shuffle=True, num_workers=2\n",
        ")\n",
        "retain_loader = torch.utils.data.DataLoader(\n",
        "    retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        ")\n"
      ],
      "metadata": {
        "id": "VJOStqaJQcU2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": test_loader\n",
        "}\n",
        "\n",
        "dataset_sizes = {\"train\": len(train_set), \"val\": len(test_set)}\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(DEVICE)\n",
        "                    labels = labels.to(DEVICE)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model"
      ],
      "metadata": {
        "id": "ttNfvarJQeFi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = resnet18(weights=None, num_classes=10)\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 10\n",
        "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
        "# model_ft.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "model_ft = model_ft.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "5e18OhSvQh1e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFqYSspcQkEz",
        "outputId": "c52f9f70-d3e0-48fe-b8d7-7d443930bbca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 1.3797 Acc: 0.5043\n",
            "val Loss: 1.1638 Acc: 0.5866\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.9742 Acc: 0.6572\n",
            "val Loss: 0.9782 Acc: 0.6557\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.7955 Acc: 0.7217\n",
            "val Loss: 0.9502 Acc: 0.6741\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.6601 Acc: 0.7668\n",
            "val Loss: 0.8870 Acc: 0.6997\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.5535 Acc: 0.8049\n",
            "val Loss: 0.9101 Acc: 0.7031\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.4575 Acc: 0.8372\n",
            "val Loss: 0.8126 Acc: 0.7381\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.3671 Acc: 0.8693\n",
            "val Loss: 0.8807 Acc: 0.7344\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.1551 Acc: 0.9525\n",
            "val Loss: 0.7870 Acc: 0.7758\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.0804 Acc: 0.9780\n",
            "val Loss: 0.8682 Acc: 0.7738\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.0464 Acc: 0.9896\n",
            "val Loss: 0.9669 Acc: 0.7718\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.0252 Acc: 0.9953\n",
            "val Loss: 1.0843 Acc: 0.7668\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.0133 Acc: 0.9980\n",
            "val Loss: 1.2156 Acc: 0.7684\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.0076 Acc: 0.9990\n",
            "val Loss: 1.3208 Acc: 0.7669\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.0045 Acc: 0.9996\n",
            "val Loss: 1.3988 Acc: 0.7686\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.0027 Acc: 0.9999\n",
            "val Loss: 1.4177 Acc: 0.7709\n",
            "\n",
            "Training complete in 5m 14s\n",
            "Best val Acc: 0.775800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sch = 'linear'\n",
        "init_rate = 0.3\n",
        "init_method = 'snip_little_grad'\n",
        "lr = 0.001\n",
        "epoch = 5\n",
        "weight_decay = 5e-4\n",
        "\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "class LinearAnnealingLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, num_annealing_steps, num_total_steps):\n",
        "        self.num_annealing_steps = num_annealing_steps\n",
        "        self.num_total_steps = num_total_steps\n",
        "\n",
        "        super().__init__(optimizer)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if self._step_count <= self.num_annealing_steps:\n",
        "            return [base_lr * self._step_count / self.num_annealing_steps for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            return [base_lr * (self.num_total_steps - self._step_count) / (self.num_total_steps - self.num_annealing_steps) for base_lr in self.base_lrs]\n",
        "\n",
        "class IncreasingLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, num_total_steps):\n",
        "        self.num_total_steps = num_total_steps\n",
        "\n",
        "        super().__init__(optimizer)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [base_lr * self._step_count / self.num_total_steps for base_lr in self.base_lrs]\n",
        "\n",
        "def mp_importance_score(model): #weight maginute\n",
        "    score_dict = {}\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (Conv2d,)):\n",
        "            score_dict[(m, \"weight\")] = m.weight.data.abs()\n",
        "    return score_dict\n",
        "\n",
        "def mp_prune(model, ratio):\n",
        "    score_dict = mp_importance_score(model)\n",
        "\n",
        "    prune.global_unstructured(\n",
        "        parameters=score_dict.keys(),\n",
        "        pruning_method=prune.L1Unstructured,\n",
        "        amount=ratio,\n",
        "        importance_scores=score_dict,\n",
        "    )\n",
        "\n",
        "def remove_prune(model):\n",
        "    print(\"Remove hooks for multiplying masks (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            prune.remove(m, \"weight\")\n",
        "\n",
        "def pruning_model_random(model, px):\n",
        "    print(\"Apply Unstructured Random Pruning Globally (all conv layers)\")\n",
        "    parameters_to_prune = []\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            parameters_to_prune.append((m, \"weight\"))\n",
        "    parameters_to_prune = tuple(parameters_to_prune)\n",
        "    prune.global_unstructured(\n",
        "        parameters_to_prune,\n",
        "        pruning_method=prune.RandomUnstructured,\n",
        "        amount=px,\n",
        "    )\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_random(model, px):\n",
        "    print(\"Apply Unstructured random re init no grads Globally (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            prob = torch.rand_like(mask.float(), device=DEVICE)\n",
        "            topk = torch.topk(prob.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            m.weight.data[mask] = nn.Conv2d(in_c, out_c, ke, device=DEVICE).weight[mask]\n",
        "\n",
        "def re_init_model_random_diffrent_init(model, px):\n",
        "    print(\"Apply Unstructured random re init no grads Globally (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            prob = torch.rand_like(mask.float(), device=DEVICE)\n",
        "            topk = torch.topk(prob.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            temp_weight = torch.empty_like(mask, dtype=torch.float)\n",
        "            nn.init.kaiming_normal_(temp_weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            m.weight.data[mask] = temp_weight[mask]\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_mp(model, px): # re init smallest weight\n",
        "    print(\"Apply Unstructured mp re init no grads Globally (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            value = -m.weight.abs()\n",
        "            topk = torch.topk(value.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            m.weight.data[mask] = nn.Conv2d(in_c, out_c, ke, device=DEVICE).weight[mask]\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_mp_ver2(model, px): # re init Biggest weight\n",
        "    print(\"Apply Unstructured mp re init no grads Globally (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            value = m.weight.abs()\n",
        "            topk = torch.topk(value.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            m.weight.data[mask] = nn.Conv2d(in_c, out_c, ke, device=DEVICE).weight[mask]\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_mp(model, px): # re init smallest weight\n",
        "    print(\"Apply Unstructured mp re init no grads Globally (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            value = -m.weight.abs()\n",
        "            topk = torch.topk(value.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            m.weight.data[mask] = nn.Conv2d(in_c, out_c, ke, device=DEVICE).weight[mask]\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_snip(model, px): # re init Biggest gradients\n",
        "    print(\"Apply Unstructured mp re init no grads Globally (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            value = m.weight.grad.abs()\n",
        "            topk = torch.topk(value.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            m.weight.data[mask] = nn.Conv2d(in_c, out_c, ke, device=DEVICE).weight[mask]\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_snip_ver2(model, px): # re init smallest gradients\n",
        "    print(\"Apply Unstructured snip ve2 re init no grads Globally (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            value = -m.weight.grad.abs()\n",
        "            topk = torch.topk(value.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            m.weight.data[mask] = nn.Conv2d(in_c, out_c, ke, device=DEVICE).weight[mask]\n",
        "def get_grads_for_snip(model, retain_loader, forget_loader):\n",
        "    indices = torch.randperm(len(retain_loader.dataset), dtype=torch.int32, device='cpu')[:len(forget_loader.dataset)]\n",
        "    retain_dataset = Subset(retain_loader.dataset, indices)\n",
        "    retain_loader = DataLoader(retain_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    model.zero_grad()\n",
        "    for sample in retain_loader:\n",
        "        inputs = sample[0]\n",
        "        targets = sample[1]\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = F.cross_entropy(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "    for sample in forget_loader:\n",
        "        inputs = sample[0]\n",
        "        targets = sample[1]\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = -F.cross_entropy(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "def get_all_grads_for_snip(model, retain_loader, forget_loader):\n",
        "    retain_weight = len(forget_loader.dataset) / len(retain_loader.dataset)\n",
        "    model.zero_grad()\n",
        "    for sample in retain_loader:\n",
        "        inputs = sample[0]\n",
        "        targets = sample[1]\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = retain_weight * F.cross_entropy(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "    for sample in forget_loader:\n",
        "        inputs = sample[0]\n",
        "        targets = sample[1]\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = -F.cross_entropy(outputs, targets)\n",
        "        loss.backward()\n",
        "from functools import partial\n",
        "from types import MethodType\n",
        "\n",
        "def zero_grads(mask, g):\n",
        "    return g*mask\n",
        "\n",
        "def zero_grads_ver2(mask, g):\n",
        "    out = g.clone()\n",
        "    out[~mask] = 0\n",
        "    return out\n",
        "\n",
        "def zero_grads_ver3(self, g):\n",
        "    out = g.clone()\n",
        "    out[~self.mask] = 0\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_random_zero_grad(model, px):\n",
        "    print('re_init_model_random_zero_grad')\n",
        "    print(\"Apply Unstructured random re init no grads Globally (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            prob = torch.rand_like(mask.float(), device=DEVICE)\n",
        "            topk = torch.topk(prob.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            m.weight.data[mask] = nn.Conv2d(in_c, out_c, ke, device=DEVICE).weight[mask]\n",
        "            m.weight.register_hook(partial(zero_grads, mask))\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_random_zero_grad_ver2(model, px):\n",
        "    print('re_init_model_random_zero_grad_ver2')\n",
        "    print(\"Apply Unstructured random re init no grads Globally (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            prob = torch.rand_like(mask.float(), device=DEVICE)\n",
        "            topk = torch.topk(prob.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            m.weight.data[mask] = nn.Conv2d(in_c, out_c, ke, device=DEVICE).weight[mask]\n",
        "            m.weight.register_hook(partial(zero_grads_ver2, mask))\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_random_zero_grad_ver3(model, px):\n",
        "    print('re_init_model_random_zero_grad_ver3')\n",
        "    print(\"Apply Unstructured random re init no grads Globally (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            prob = torch.rand_like(mask.float(), device=DEVICE)\n",
        "            topk = torch.topk(prob.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "            m.weight.data[mask] = nn.Conv2d(in_c, out_c, ke, device=DEVICE).weight[mask]\n",
        "\n",
        "            m.mask = mask\n",
        "            m.backward_fn = MethodType(zero_grads_ver3, m)\n",
        "\n",
        "            m.weight.register_hook(m.backward_fn)\n",
        "class Masker(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, mask):\n",
        "        ctx.save_for_backward(mask)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad):\n",
        "        mask, = ctx.saved_tensors\n",
        "        return grad * mask, None\n",
        "\n",
        "\n",
        "class MaskConv2d(nn.Conv2d):\n",
        "    def __init__(self, mask, in_channels, out_channels, kernel_size, stride=1,\n",
        "                 padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device='cpu'):\n",
        "        super(MaskConv2d, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
        "                                     padding, dilation, groups, bias, padding_mode, device=device)\n",
        "        self.mask = mask\n",
        "\n",
        "    def forward(self, input):\n",
        "        masked_weight = Masker.apply(self.weight, self.mask)\n",
        "        return super(MaskConv2d, self)._conv_forward(input, masked_weight, self.bias)\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_random_zero_grad_Maskconv(model, px):\n",
        "    print(\"Apply Unstructured random re init no grads Globally (all conv layers)\")\n",
        "    for name, m in list(model.named_modules()):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            prob = torch.rand_like(mask.float(), device=DEVICE)\n",
        "            topk = torch.topk(prob.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            new_conv = MaskConv2d(mask, m.in_channels, m.out_channels, m.kernel_size, m.stride,\n",
        "                 m.padding, m.dilation, m.groups, m.bias!=None, m.padding_mode, device=DEVICE)\n",
        "            #nn.init.kaiming_normal_(new_conv.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            new_conv.weight.data[~mask] = m.weight[~mask]\n",
        "            setattr(model, name, new_conv)\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_random_little_grad_Maskconv_fanout(model, px):\n",
        "    print(\"Apply Unstructured re_init_model_random_little_grad_Maskconv_fanout (all conv layers)\")\n",
        "    for name, m in list(model.named_modules()):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            prob = torch.rand_like(mask.float(), device=DEVICE)\n",
        "            topk = torch.topk(prob.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "            grad_mask = mask.clone().float()\n",
        "            grad_mask[grad_mask==0] += 0.1\n",
        "\n",
        "            new_conv = MaskConv2d(grad_mask, m.in_channels, m.out_channels, m.kernel_size, m.stride,\n",
        "                 m.padding, m.dilation, m.groups, m.bias!=None, m.padding_mode, device=DEVICE)\n",
        "            nn.init.kaiming_normal_(new_conv.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            new_conv.weight.data[~mask] = m.weight[~mask]\n",
        "            setattr(model, name, new_conv)\n",
        "@torch.no_grad()\n",
        "def re_init_model_snip_ver2_zero_grad(model, px): # re init smallest gradients\n",
        "    print(\"Apply Unstructured re_init_model_snip_ver2_zero_grad Globally (all conv layers)\")\n",
        "    for name, m in list(model.named_modules()):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            value = -m.weight.grad.abs()\n",
        "            topk = torch.topk(value.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "\n",
        "            new_conv = MaskConv2d(mask, m.in_channels, m.out_channels, m.kernel_size, m.stride,\n",
        "                 m.padding, m.dilation, m.groups, m.bias!=None, m.padding_mode, device=DEVICE)\n",
        "            nn.init.kaiming_normal_(new_conv.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "\n",
        "            new_conv.weight.data[~mask] = m.weight[~mask]\n",
        "            set_layer(model, name, new_conv)\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_snip_ver2_little_grad(model, px): # re init smallest gradients\n",
        "    print(\"Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\")\n",
        "    for name, m in list(model.named_modules()):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            value = -m.weight.grad.abs()\n",
        "            topk = torch.topk(value.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "            grad_mask = mask.clone().float()\n",
        "            grad_mask[grad_mask==0] += 0.1\n",
        "\n",
        "            new_conv = MaskConv2d(grad_mask, m.in_channels, m.out_channels, m.kernel_size, m.stride,\n",
        "                 m.padding, m.dilation, m.groups, m.bias!=None, m.padding_mode, device=DEVICE)\n",
        "            nn.init.kaiming_normal_(new_conv.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "\n",
        "            new_conv.weight.data[~mask] = m.weight[~mask]\n",
        "\n",
        "            set_layer(model, name, new_conv)\n",
        "\n",
        "def set_layer(model, layer_name, layer):\n",
        "    splited = layer_name.split('.')\n",
        "    if len(splited) == 1:\n",
        "        setattr(model, splited[0], layer)\n",
        "    elif len(splited) == 3:\n",
        "        setattr(getattr(model, splited[0])[int(splited[1])], splited[2], layer)\n",
        "    elif len(splited) == 4:\n",
        "        getattr(getattr(model, splited[0])[int(splited[1])], splited[2])[int(splited[3])] = layer\n",
        "\n",
        "@torch.no_grad()\n",
        "def replace_maskconv(model):\n",
        "    print(\"Remove Maskconv\")\n",
        "    for name, m in list(model.named_modules()):\n",
        "        if isinstance(m, MaskConv2d):\n",
        "            conv = nn.Conv2d(m.in_channels, m.out_channels, m.kernel_size, m.stride,\n",
        "                 m.padding, m.dilation, m.groups, m.bias!=None, m.padding_mode, device=DEVICE)\n",
        "            conv.weight.data = m.weight\n",
        "            conv.bias = m.bias\n",
        "            set_layer(model, name, conv)\n",
        "@torch.no_grad()\n",
        "def reinit_topn(model, n):\n",
        "    print(f\"Reinit top {n} conv2d(only 5 layer available)\")\n",
        "    target_layer = ['layer4.0.conv1', 'layer4.0.conv2', 'layer4.0.downsample.0','layer4.1.conv1', 'layer4.1.conv2']\n",
        "    target_layer = target_layer[-n:]\n",
        "    for name, m in list(model.named_modules()):\n",
        "        if name in target_layer:\n",
        "            nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "@torch.no_grad()\n",
        "def reinit_batchnorm(model):\n",
        "    print(\"Reinit BatchNorm2d\")\n",
        "    for name, m in list(model.named_modules()):\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "def snip_importance_score(model):\n",
        "    score_dict = {}\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d,)):\n",
        "            score_dict[(m, \"weight\")] = -m.weight.grad.abs()\n",
        "    return score_dict\n",
        "\n",
        "@torch.no_grad()\n",
        "def prune_model_snip_ver2(model, px): # re init smallest gradients\n",
        "    print(\"Apply Unstructured snip ver2 prune grads Globally (all conv layers)\")\n",
        "\n",
        "    score_dict = snip_importance_score(model)\n",
        "    prune.global_unstructured(\n",
        "        parameters=score_dict.keys(),\n",
        "        pruning_method=prune.L1Unstructured,\n",
        "        amount=px,\n",
        "        importance_scores=score_dict,\n",
        "    )\n",
        "\n",
        "def remove_prune(model):\n",
        "    print(\"Remove hooks for multiplying masks (all conv layers)\")\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            prune.remove(m, \"weight\")\n"
      ],
      "metadata": {
        "id": "h28_D54zQly7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, Subset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "def unlearning(\n",
        "    net,\n",
        "    retain_loader,\n",
        "    forget_loader,\n",
        "    val_loader):\n",
        "    if init_method=='random':\n",
        "        re_init_model_random(net, init_rate)\n",
        "    elif init_method=='random_init2':\n",
        "        re_init_model_random_diffrent_init(net, init_rate)\n",
        "    elif init_method=='mp':\n",
        "        re_init_model_mp(net, init_rate)\n",
        "    elif init_method=='reversed_mp':\n",
        "        re_init_model_mp_ver2(net, init_rate)\n",
        "    elif init_method=='snip':\n",
        "        get_grads_for_snip(net, retain_loader, forget_loader)\n",
        "        re_init_model_snip_ver2(net, init_rate)\n",
        "    elif init_method=='random_zero_grad':\n",
        "        re_init_model_random_zero_grad(net, init_rate)\n",
        "    elif init_method=='random_zero_grad_ver2':\n",
        "        re_init_model_random_zero_grad_ver2(net, init_rate)\n",
        "    elif init_method=='random_zero_grad_ver3':\n",
        "        re_init_model_random_zero_grad_ver3(net, init_rate)\n",
        "    elif init_method=='maskconv':\n",
        "        re_init_model_random_zero_grad_Maskconv(net, init_rate)\n",
        "    elif init_method=='little_grad':\n",
        "        re_init_model_random_little_grad_Maskconv_fanout(net, init_rate)\n",
        "    elif init_method=='snip_zero_grad':\n",
        "        replace_maskconv(net)\n",
        "        get_grads_for_snip(net, retain_loader, forget_loader)\n",
        "        re_init_model_snip_ver2_zero_grad(net, init_rate)\n",
        "    elif init_method=='snip_little_grad':\n",
        "        replace_maskconv(net)\n",
        "        get_grads_for_snip(net, retain_loader, forget_loader)\n",
        "        re_init_model_snip_ver2_little_grad(net, init_rate)\n",
        "    elif init_method=='snip_and_reinit_bn':\n",
        "        get_grads_for_snip(net, retain_loader, forget_loader)\n",
        "        re_init_model_snip_ver2(net, init_rate)\n",
        "        reinit_batchnorm(net)\n",
        "    elif init_method=='reinit_bn':\n",
        "        reinit_batchnorm(net)\n",
        "    elif init_method=='snip_and_topn_reinit':\n",
        "        get_grads_for_snip(net, retain_loader, forget_loader)\n",
        "        re_init_model_snip_ver2(net, init_rate)\n",
        "        reinit_topn(net, 1)\n",
        "    elif init_method=='prune_snip':\n",
        "        get_grads_for_snip(net, retain_loader, forget_loader)\n",
        "        prune_model_snip_ver2(net, init_rate)\n",
        "    elif init_method=='all_snip_reinit':\n",
        "        get_all_grads_for_snip(net, retain_loader, forget_loader)\n",
        "        re_init_model_snip_ver2(net, init_rate)\n",
        "    else:\n",
        "        raise \"not implemented\"\n",
        "\n",
        "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
        "    epochs = epoch\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr,\n",
        "                      momentum=0.9, weight_decay=weight_decay)\n",
        "    if sch=='cosine':\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    elif sch=='linear':\n",
        "        scheduler = LinearAnnealingLR(optimizer, num_annealing_steps=(epochs+1)//2, num_total_steps=epochs+1)\n",
        "    elif sch=='increase':\n",
        "        scheduler = IncreasingLR(optimizer, num_total_steps=epochs)\n",
        "    elif sch=='decrease':\n",
        "        print('decrease')\n",
        "        scheduler = LinearAnnealingLR(optimizer, num_annealing_steps=1, num_total_steps=epochs+1)\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        for sample in retain_loader:\n",
        "            inputs = sample[0]\n",
        "            targets = sample[1]\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "    #remove_prune(net)\n",
        "    net.eval()"
      ],
      "metadata": {
        "id": "zX2K5STjWJZr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model_ft_forget = unlearning(model_ft, retain_loader, forget_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omVPIY18TZri",
        "outputId": "7338cc83-e95d-4f67-cfda-446630daa7dc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remove Maskconv\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "CPU times: user 58.4 s, sys: 1.96 s, total: 1min\n",
            "Wall time: 1min 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(forget_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHwTHdd8ThqF",
        "outputId": "f93b77e6-4c41-4992-a9d7-fb9866018bb1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "smyceZBuTrGr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}