{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d55jE14Du6I5",
        "outputId": "35d4da5d-6dee-4877-9747-e0569f607263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: CUDA\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Imports\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "from tempfile import TemporaryDirectory\n",
        "import seaborn as sns\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on device:\", DEVICE.upper())\n",
        "\n",
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(1991)\n",
        "torch.manual_seed(1991)\n",
        "torch.cuda.manual_seed(1991)\n",
        "\n",
        "import random\n",
        "random.seed(1991)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1991)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR 10 dataset\n",
        "torch.manual_seed(1991)\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=normalize\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1tCXbX1vIYb",
        "outputId": "d3a90b5a-3cc3-441b-b952-05c367680433"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def unlearning(\n",
        "    net,\n",
        "    retain_loader,\n",
        "    forget_loader,\n",
        "    val_loader):\n",
        "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    class CustomCrossEntropyLoss(nn.Module):\n",
        "        def __init__(self, class_weights=None):\n",
        "            super(CustomCrossEntropyLoss, self).__init__()\n",
        "            self.class_weights = class_weights\n",
        "\n",
        "        def forward(self, input, target):\n",
        "            # Compute the standard cross-entropy loss\n",
        "            ce_loss = nn.functional.cross_entropy(input, target)\n",
        "\n",
        "            # Apply class weights to the loss if provided\n",
        "            if self.class_weights is not None:\n",
        "                # Calculate the weights for each element in the batch based on the target\n",
        "                weights = torch.tensor([self.class_weights[i] for i in target], device=input.device)\n",
        "                ce_loss = torch.mean(ce_loss * weights)\n",
        "\n",
        "            return ce_loss\n",
        "\n",
        "\n",
        "\n",
        "    # Define the vision_confuser function\n",
        "    def vision_confuser(model, std = 0.6):\n",
        "        for name, module in model.named_modules():\n",
        "            if hasattr(module, 'weight'):\n",
        "                if 'conv' in name:\n",
        "                    actual_value = module.weight.clone().detach()\n",
        "                    new_values = torch.normal(mean=actual_value, std=std)\n",
        "                    module.weight.data.copy_(new_values)\n",
        "\n",
        "    vision_confuser(net)\n",
        "\n",
        "    epochs = 4\n",
        "\n",
        "    # w = 0.05\n",
        "\n",
        "    # class_weights = [1, w, w, w, w, w, w, w, w, w]\n",
        "    criterion = CustomCrossEntropyLoss(None)\n",
        "\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.0007,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=epochs)\n",
        "\n",
        "    net.train()\n",
        "    i=0\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        i=0\n",
        "        net.train()\n",
        "        for sample in retain_loader:\n",
        "            inputs = sample[0]\n",
        "            targets = sample[1]\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if (ep == epochs-2):\n",
        "            vision_confuser(net , 0.005) # increase model robustness before last training epoch\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    net.eval()\n",
        "    return net"
      ],
      "metadata": {
        "id": "Tw-ww32qvJW3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def train_mia_on_class(model, class_index, train_set, test_set, no_class=True, splits_num=5):\n",
        "  model = model.to(\"cpu\")\n",
        "\n",
        "  if not no_class:\n",
        "    # Select indencies where class is class_index\n",
        "    train_class_set = np.where(np.array(train_set.targets) == class_index)[0]\n",
        "    test_class_set = np.where(np.array(test_set.targets) == class_index)[0]\n",
        "  else:\n",
        "    train_class_set = np.arange(len(train_set))\n",
        "    test_class_set = np.arange(len(test_set))\n",
        "\n",
        "  max_len = min([len(train_class_set), len(test_class_set)])\n",
        "  # Make equal sizes\n",
        "  train_class_set = train_class_set[:max_len]\n",
        "  test_class_set = test_class_set[:max_len]\n",
        "\n",
        "  # Obtain subsets\n",
        "  train_class_set = torch.utils.data.Subset(train_set, train_class_set)\n",
        "  test_class_set = torch.utils.data.Subset(test_set, test_class_set)\n",
        "\n",
        "\n",
        "  # Make them\n",
        "  class_test_loader = torch.utils.data.DataLoader(\n",
        "    test_class_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "\n",
        "  class_train_loader = torch.utils.data.DataLoader(\n",
        "    train_class_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "  # Obtain train and test logits\n",
        "  logits_train = []\n",
        "  for i, (images, labels) in enumerate(class_train_loader, 0):\n",
        "    for img, label in zip(images, labels):\n",
        "      logits = model(img.unsqueeze(0))\n",
        "      losses = criterion(logits, label.unsqueeze(0)).numpy(force=True)\n",
        "\n",
        "      logits_train.append(np.concatenate((logits.detach().numpy()[0], losses)))\n",
        "\n",
        "  logits_test = []\n",
        "  for i, (images, labels) in enumerate(class_test_loader, 0):\n",
        "    for img, label in zip(images, labels):\n",
        "      logits = model(img.unsqueeze(0))\n",
        "      losses = criterion(logits, label.unsqueeze(0)).numpy(force=True)\n",
        "\n",
        "      logits_test.append((np.concatenate((logits.detach().numpy()[0], losses))))\n",
        "\n",
        "  logits_train, logits_test = np.array(logits_train), np.array(logits_test)\n",
        "  # Create dataset\n",
        "  ys = [1] * max_len + [0] * max_len\n",
        "  ys = np.array(ys)\n",
        "  p = np.random.permutation(len(ys))\n",
        "  logits = np.concatenate((logits_train, logits_test))\n",
        "\n",
        "  logits = logits[p]\n",
        "  ys = ys[p]\n",
        "\n",
        "  # Fit logitstic regression\n",
        "  clf = LogisticRegression(random_state=0, max_iter=1000)\n",
        "  cv = model_selection.StratifiedShuffleSplit(\n",
        "        n_splits=splits_num, random_state=0\n",
        "    )\n",
        "\n",
        "  clf = model_selection.cross_val_score(\n",
        "        clf, logits, ys, cv=cv, scoring=\"accuracy\"\n",
        "    )\n",
        "\n",
        "  # Output score\n",
        "  # print(f\"Mean MIA attack score for class {class_index} is: \" + str(clf.mean()))\n",
        "  return clf.mean()\n",
        ""
      ],
      "metadata": {
        "id": "t6nnrpeJvgt7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Check accuracy\n",
        "\n",
        "def accuracy(net, loader):\n",
        "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (inputs, targets) in enumerate(loader, 0):\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n",
        ""
      ],
      "metadata": {
        "id": "OegQZT5CvmH9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_losses(net, loader):\n",
        "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    all_losses = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        logits = net(inputs)\n",
        "        losses = criterion(logits, targets).numpy(force=True)\n",
        "        for l in losses:\n",
        "            all_losses.append(l)\n",
        "\n",
        "    return np.array(all_losses)"
      ],
      "metadata": {
        "id": "GZ2ahz57vnK2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "mwsA1V-KvpZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"----- 5 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Baseline\"\n",
        "model_params = \"cifar10_resnet18_baseline.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  model_ft_forget.eval()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nedeXz6pyFyW",
        "outputId": "d48ce99c-2be1-43dd-93ec-ee623851fbaf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT -------\n",
            "Model name: Resnet18 Baseline\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 97.6\n",
            "MIA score before on forget set: 0.87\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 30.6%\n",
            "Test set accuracy FORGET model: 29.9%\n",
            "Forget set accuracy FORGET model: 32.0%\n",
            "\n",
            "The MIA has an accuracy of 0.660 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 96.8\n",
            "MIA score before on forget set: 0.97\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 31.0%\n",
            "Test set accuracy FORGET model: 29.9%\n",
            "Forget set accuracy FORGET model: 27.2%\n",
            "\n",
            "The MIA has an accuracy of 0.684 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 93.2\n",
            "MIA score before on forget set: 0.92\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 31.8%\n",
            "Test set accuracy FORGET model: 29.7%\n",
            "Forget set accuracy FORGET model: 11.2%\n",
            "\n",
            "The MIA has an accuracy of 0.628 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 85.2\n",
            "MIA score before on forget set: 0.86\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 31.5%\n",
            "Test set accuracy FORGET model: 29.9%\n",
            "Forget set accuracy FORGET model: 10.8%\n",
            "\n",
            "The MIA has an accuracy of 0.680 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 94.8\n",
            "MIA score before on forget set: 0.98\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 31.6%\n",
            "Test set accuracy FORGET model: 30.0%\n",
            "Forget set accuracy FORGET model: 32.0%\n",
            "\n",
            "The MIA has an accuracy of 0.728 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 88.4\n",
            "MIA score before on forget set: 0.92\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 30.6%\n",
            "Test set accuracy FORGET model: 28.5%\n",
            "Forget set accuracy FORGET model: 22.4%\n",
            "\n",
            "The MIA has an accuracy of 0.708 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 96.8\n",
            "MIA score before on forget set: 0.94\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 31.7%\n",
            "Test set accuracy FORGET model: 30.8%\n",
            "Forget set accuracy FORGET model: 35.2%\n",
            "\n",
            "The MIA has an accuracy of 0.708 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 95.19999999999999\n",
            "MIA score before on forget set: 0.94\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 32.2%\n",
            "Test set accuracy FORGET model: 31.8%\n",
            "Forget set accuracy FORGET model: 17.2%\n",
            "\n",
            "The MIA has an accuracy of 0.668 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 98.4\n",
            "MIA score before on forget set: 0.91\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 31.7%\n",
            "Test set accuracy FORGET model: 30.0%\n",
            "Forget set accuracy FORGET model: 41.2%\n",
            "\n",
            "The MIA has an accuracy of 0.728 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 95.6\n",
            "MIA score before on forget set: 0.88\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 30.8%\n",
            "Test set accuracy FORGET model: 29.7%\n",
            "Forget set accuracy FORGET model: 31.2%\n",
            "\n",
            "The MIA has an accuracy of 0.708 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qImxcHeGuPC",
        "outputId": "23628a2d-3f4c-4e34-b8d8-d3b748f8a238"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.87, 0.97, 0.92, 0.86, 0.98, 0.92, 0.94, 0.94, 0.91, 0.88]\n",
            "[0.66, 0.6839999999999999, 0.628, 0.6799999999999999, 0.728, 0.708, 0.708, 0.668, 0.728, 0.708]\n",
            "[97.6, 96.8, 93.2, 85.2, 94.8, 88.4, 96.8, 95.19999999999999, 98.4, 95.6]\n",
            "[30.574592519645478, 31.004682758204876, 31.822018569878214, 31.516430509496534, 31.617558387265344, 30.593130062508795, 31.679864935482577, 32.17034789074904, 31.73697220603308, 30.776806351120488]\n",
            "[32.0, 27.200000000000003, 11.200000000000001, 10.8, 32.0, 22.400000000000002, 35.199999999999996, 17.2, 41.199999999999996, 31.2]\n",
            "[29.89, 29.89, 29.69, 29.880000000000003, 30.020000000000003, 28.51, 30.830000000000002, 31.78, 29.99, 29.67]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean_mia_score_before_baseline = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_baseline = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_baseline = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_baseline = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_baseline = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_baseline = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "83iCLrv_Gy-K"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(mean_mia_score_before_baseline)\n",
        "print(mean_mia_score_after_baseline)\n",
        "\n",
        "print(mean_accuracy_forget_before_baseline)\n",
        "\n",
        "print(mean_accuracy_forget_after_baseline)\n",
        "print(mean_accuracy_retain_baseline)\n",
        "print(mean_accuracy_test_baseline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKzA-39nG0AQ",
        "outputId": "f8b40651-e650-4610-e2a0-475ec1f6e304"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9190000000000002\n",
            "0.69\n",
            "94.2\n",
            "26.04\n",
            "31.349240419038445\n",
            "30.015000000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout model"
      ],
      "metadata": {
        "id": "NLBE_L_uG1_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_model(model_train_reg):\n",
        "  from collections import OrderedDict\n",
        "\n",
        "  layer1 = model_train_reg.layer1\n",
        "\n",
        "  for indx in range(len(layer1)):\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer1[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer1[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "\n",
        "\n",
        "  layer2 = model_train_reg.layer2\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer2[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer2[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  layer3 = model_train_reg.layer3\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer3[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "    model_train_reg.layer3[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  layer4 = model_train_reg.layer4\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer4[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer4[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  return model_train_reg"
      ],
      "metadata": {
        "id": "VZ60IiYSG0y2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"----- 5 PERCENT DROPOUT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Dropout\"\n",
        "model_params = \"cifar10_resnet18_l2_dropout_regularization.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  model_forget_ft = modify_model(model_forget_ft)\n",
        "\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  model_ft_forget.eval()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npVh10qJKoir",
        "outputId": "5d934b95-b2a0-4834-829b-adc9746d320a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT DROPOUT -------\n",
            "Model name: Resnet18 Dropout\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 84.0\n",
            "MIA score before on forget set: 0.93\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 10.1%\n",
            "Test set accuracy FORGET model: 10.1%\n",
            "Forget set accuracy FORGET model: 0.0%\n",
            "\n",
            "The MIA has an accuracy of 0.836 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 87.6\n",
            "MIA score before on forget set: 0.96\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 11.0%\n",
            "Test set accuracy FORGET model: 11.0%\n",
            "Forget set accuracy FORGET model: 0.0%\n",
            "\n",
            "The MIA has an accuracy of 0.884 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 69.6\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 10.3%\n",
            "Test set accuracy FORGET model: 10.5%\n",
            "Forget set accuracy FORGET model: 0.0%\n",
            "\n",
            "The MIA has an accuracy of 0.828 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 60.0\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 10.2%\n",
            "Test set accuracy FORGET model: 10.1%\n",
            "Forget set accuracy FORGET model: 0.0%\n",
            "\n",
            "The MIA has an accuracy of 0.552 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 76.4\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 9.8%\n",
            "Test set accuracy FORGET model: 10.2%\n",
            "Forget set accuracy FORGET model: 96.0%\n",
            "\n",
            "The MIA has an accuracy of 0.904 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 70.39999999999999\n",
            "MIA score before on forget set: 0.87\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 10.5%\n",
            "Test set accuracy FORGET model: 10.5%\n",
            "Forget set accuracy FORGET model: 0.0%\n",
            "\n",
            "The MIA has an accuracy of 0.656 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 85.2\n",
            "MIA score before on forget set: 0.84\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 10.1%\n",
            "Test set accuracy FORGET model: 10.0%\n",
            "Forget set accuracy FORGET model: 2.0%\n",
            "\n",
            "The MIA has an accuracy of 0.824 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 84.39999999999999\n",
            "MIA score before on forget set: 0.93\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 10.1%\n",
            "Test set accuracy FORGET model: 10.1%\n",
            "Forget set accuracy FORGET model: 0.0%\n",
            "\n",
            "The MIA has an accuracy of 0.584 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 87.6\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 10.7%\n",
            "Test set accuracy FORGET model: 10.6%\n",
            "Forget set accuracy FORGET model: 0.0%\n",
            "\n",
            "The MIA has an accuracy of 0.796 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 87.2\n",
            "MIA score before on forget set: 0.86\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 10.4%\n",
            "Test set accuracy FORGET model: 10.2%\n",
            "Forget set accuracy FORGET model: 0.0%\n",
            "\n",
            "The MIA has an accuracy of 0.880 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptwIrwT-Kpbd",
        "outputId": "c535a265-3ecf-47d4-d66b-7acd29ff570a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9299999999999999, 0.96, 0.89, 0.89, 0.89, 0.87, 0.84, 0.9299999999999999, 0.89, 0.86]\n",
            "[0.836, 0.884, 0.828, 0.552, 0.9039999999999999, 0.656, 0.8240000000000001, 0.5840000000000001, 0.7959999999999999, 0.8800000000000001]\n",
            "[84.0, 87.6, 69.6, 60.0, 76.4, 70.39999999999999, 85.2, 84.39999999999999, 87.6, 87.2]\n",
            "[10.11958597125917, 10.973109851682143, 10.324590493417746, 10.177257928373328, 9.799823136908111, 10.453759897110244, 10.140092054750466, 10.065117774740735, 10.7160801495267, 10.443171540548688]\n",
            "[0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 2.0, 0.0, 0.0, 0.0]\n",
            "[10.07, 11.020000000000001, 10.459999999999999, 10.07, 10.23, 10.489999999999998, 10.03, 10.09, 10.639999999999999, 10.15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mean_mia_score_before_dropout = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_dropout = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_dropout = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_dropout = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_dropout = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_dropout = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "bPwkRa1vKqki"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(mean_mia_score_before_dropout)\n",
        "print(mean_mia_score_after_dropout)\n",
        "\n",
        "print(mean_accuracy_forget_before_dropout)\n",
        "\n",
        "print(mean_accuracy_forget_after_dropout)\n",
        "print(mean_accuracy_retain_dropout)\n",
        "print(mean_accuracy_test_dropout)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em3PGhyIKrnf",
        "outputId": "75e7d300-c08a-47cc-e994-01fd513bb18b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8949999999999999\n",
            "0.7744\n",
            "79.24\n",
            "9.8\n",
            "10.321258879831735\n",
            "10.325000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation model"
      ],
      "metadata": {
        "id": "8VC4WL84KtfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CIFAR 10 dataset\n",
        "torch.manual_seed(1991)\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "         transforms.RandomRotation(30), # Randomly rotate some images by 20 degrees\n",
        "         transforms.RandomHorizontalFlip(), # Randomly horizontal flip the images\n",
        "         transforms.ColorJitter(brightness = 0.1, # Randomly adjust color jitter of the images\n",
        "                                                            contrast = 0.1,\n",
        "                                                            saturation = 0.1),\n",
        "         transforms.RandomAdjustSharpness(sharpness_factor = 2,\n",
        "                                                                      p = 0.1), # Randomly adjust sharpness\n",
        "          transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "to_tensor_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=to_tensor_transform\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSXTEMx9KsZx",
        "outputId": "8d1f8372-7b4a-4111-f681-0dff6fd81365"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"----- 5 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Augmentation\"\n",
        "model_params = \"cifar10_resnet18_augmentation.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  model_forget_ft.eval()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsXrHdjAKugC",
        "outputId": "ca971fbf-facf-4cd8-fe96-1796cf16f178"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT -------\n",
            "Model name: Resnet18 Augmentation\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 83.6\n",
            "MIA score before on forget set: 0.86\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 24.0%\n",
            "Test set accuracy FORGET model: 26.6%\n",
            "Forget set accuracy FORGET model: 32.0%\n",
            "\n",
            "The MIA has an accuracy of 0.708 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 77.60000000000001\n",
            "MIA score before on forget set: 0.96\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 23.7%\n",
            "Test set accuracy FORGET model: 26.2%\n",
            "Forget set accuracy FORGET model: 14.8%\n",
            "\n",
            "The MIA has an accuracy of 0.660 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 73.6\n",
            "MIA score before on forget set: 0.83\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 23.9%\n",
            "Test set accuracy FORGET model: 26.4%\n",
            "Forget set accuracy FORGET model: 10.4%\n",
            "\n",
            "The MIA has an accuracy of 0.636 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 66.4\n",
            "MIA score before on forget set: 0.81\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 23.6%\n",
            "Test set accuracy FORGET model: 26.3%\n",
            "Forget set accuracy FORGET model: 8.8%\n",
            "\n",
            "The MIA has an accuracy of 0.680 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 72.8\n",
            "MIA score before on forget set: 0.85\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 24.4%\n",
            "Test set accuracy FORGET model: 26.5%\n",
            "Forget set accuracy FORGET model: 27.2%\n",
            "\n",
            "The MIA has an accuracy of 0.700 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 64.4\n",
            "MIA score before on forget set: 0.85\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 24.4%\n",
            "Test set accuracy FORGET model: 26.5%\n",
            "Forget set accuracy FORGET model: 16.4%\n",
            "\n",
            "The MIA has an accuracy of 0.676 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 83.6\n",
            "MIA score before on forget set: 0.93\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 23.8%\n",
            "Test set accuracy FORGET model: 25.9%\n",
            "Forget set accuracy FORGET model: 26.0%\n",
            "\n",
            "The MIA has an accuracy of 0.724 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 78.8\n",
            "MIA score before on forget set: 0.86\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 23.7%\n",
            "Test set accuracy FORGET model: 25.5%\n",
            "Forget set accuracy FORGET model: 15.2%\n",
            "\n",
            "The MIA has an accuracy of 0.712 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 86.8\n",
            "MIA score before on forget set: 0.93\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 23.6%\n",
            "Test set accuracy FORGET model: 25.9%\n",
            "Forget set accuracy FORGET model: 37.2%\n",
            "\n",
            "The MIA has an accuracy of 0.644 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 79.2\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 23.2%\n",
            "Test set accuracy FORGET model: 25.5%\n",
            "Forget set accuracy FORGET model: 28.8%\n",
            "\n",
            "The MIA has an accuracy of 0.704 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP_1oFSBKvUC",
        "outputId": "9897d34a-bbe2-46ea-aebd-7e1580cb7125"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.86, 0.96, 0.83, 0.81, 0.85, 0.85, 0.9299999999999999, 0.86, 0.9299999999999999, 0.89]\n",
            "[0.708, 0.66, 0.636, 0.6799999999999999, 0.7000000000000001, 0.676, 0.724, 0.7120000000000001, 0.644, 0.704]\n",
            "[83.6, 77.60000000000001, 73.6, 66.4, 72.8, 64.4, 83.6, 78.8, 86.8, 79.2]\n",
            "[24.196012220614247, 23.710179881418952, 24.160520868918674, 23.76961877775768, 24.147356150893344, 23.940831256531876, 23.87900713496131, 23.525392391326193, 23.45351501266128, 23.1545310207609]\n",
            "[29.2, 19.2, 7.6, 9.6, 22.0, 18.8, 33.6, 16.0, 34.8, 26.400000000000002]\n",
            "[26.57, 26.179999999999996, 26.41, 26.31, 26.450000000000003, 26.479999999999997, 25.86, 25.509999999999998, 25.900000000000002, 25.490000000000002]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mean_mia_score_before_aug = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_aug = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_aug = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_aug = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_aug = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_aug = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "FUBSPxBMKwUU"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(mean_mia_score_before_aug)\n",
        "print(mean_mia_score_after_aug)\n",
        "\n",
        "print(mean_accuracy_forget_before_aug)\n",
        "\n",
        "print(mean_accuracy_forget_after_aug)\n",
        "print(mean_accuracy_retain_aug)\n",
        "print(mean_accuracy_test_aug)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIZc0hRYKxdc",
        "outputId": "9e6bcc4d-4acb-4acc-b361-4b01a25a7d29"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.877\n",
            "0.6844\n",
            "76.67999999999999\n",
            "21.720000000000002\n",
            "23.793696471584447\n",
            "26.115999999999996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnRPRuVJKyNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}