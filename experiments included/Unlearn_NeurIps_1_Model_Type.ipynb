{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpnieODSzJTY",
        "outputId": "b46fa58f-b980-4f0c-f8c5-67d251962487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "from tempfile import TemporaryDirectory\n",
        "import seaborn as sns\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on device:\", DEVICE.upper())\n",
        "\n",
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(1991)\n",
        "torch.manual_seed(1991)\n",
        "torch.cuda.manual_seed(1991)\n",
        "\n",
        "import random\n",
        "random.seed(1991)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1991)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CIFAR 10 dataset\n",
        "torch.manual_seed(1991)\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=normalize\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5hNOpjGzYgZ",
        "outputId": "577bd47a-950d-4a57-b6ee-7e03ae3f1a7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12980334.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts,StepLR\n",
        "def kl_loss_sym(x,y):\n",
        "    kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
        "    return kl_loss(nn.LogSoftmax(dim=-1)(x),y)\n",
        "\n",
        "def unlearning(\n",
        "        net,\n",
        "        retain_loader,\n",
        "        forget_loader,\n",
        "        val_loader,\n",
        "):\n",
        "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
        "    print('-----------------------------------')\n",
        "    epochs = 8\n",
        "    retain_bs = 256\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.005,\n",
        "                          momentum=0.9, weight_decay=0)\n",
        "    optimizer_retain = optim.SGD(net.parameters(), lr=0.001*retain_bs/64, momentum=0.9, weight_decay=1e-2)\n",
        "    ##the learning rate is associated with the batchsize we used\n",
        "    optimizer_forget = optim.SGD(net.parameters(), lr=3e-4, momentum=0.9, weight_decay=0)\n",
        "    total_step = int(len(forget_loader)*epochs)\n",
        "    retain_ld = DataLoader(retain_loader.dataset, batch_size=retain_bs, shuffle=True)\n",
        "    retain_ld4fgt = DataLoader(retain_loader.dataset, batch_size=256, shuffle=True)\n",
        "    scheduler = CosineAnnealingLR(optimizer_forget, T_max=total_step, eta_min=1e-6)\n",
        "\n",
        "    net.train()\n",
        "    for sample in forget_loader: ##First Stage\n",
        "        inputs, output = sample\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        uniform_label = torch.ones_like(outputs).to(DEVICE) / outputs.shape[1] ##uniform pseudo label\n",
        "        loss = kl_loss_sym(outputs, uniform_label) ##optimize the distance between logits and pseudo labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    net.train()\n",
        "    for ep in range(epochs): ##Second Stage\n",
        "        net.train()\n",
        "        for sample_forget, sample_retain in zip(forget_loader, retain_ld4fgt):##Forget Round\n",
        "            t = 1.15 ##temperature coefficient\n",
        "            inputs_forget,inputs_retain = sample_forget[0],sample_retain[0]\n",
        "            inputs_forget, inputs_retain = inputs_forget.to(DEVICE), inputs_retain.to(DEVICE)\n",
        "            optimizer_forget.zero_grad()\n",
        "            outputs_forget,outputs_retain = net(inputs_forget),net(inputs_retain).detach()\n",
        "            loss = (-1 * nn.LogSoftmax(dim=-1)(outputs_forget @ outputs_retain.T/t)).mean() ##Contrastive Learning loss\n",
        "            loss.backward()\n",
        "            optimizer_forget.step()\n",
        "            scheduler.step()\n",
        "        for sample in retain_ld: ##Retain Round\n",
        "            inputs, labels = sample\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer_retain.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer_retain.step()\n",
        "\n",
        "    print('-----------------------------------')\n",
        "    return net"
      ],
      "metadata": {
        "id": "vYtPgBL_zZ9V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def train_mia_on_class(model, class_index, train_set, test_set, no_class=True, splits_num=5):\n",
        "  model = model.to(\"cpu\")\n",
        "\n",
        "  if not no_class:\n",
        "    # Select indencies where class is class_index\n",
        "    train_class_set = np.where(np.array(train_set.targets) == class_index)[0]\n",
        "    test_class_set = np.where(np.array(test_set.targets) == class_index)[0]\n",
        "  else:\n",
        "    train_class_set = np.arange(len(train_set))\n",
        "    test_class_set = np.arange(len(test_set))\n",
        "\n",
        "  max_len = min([len(train_class_set), len(test_class_set)])\n",
        "  # Make equal sizes\n",
        "  train_class_set = train_class_set[:max_len]\n",
        "  test_class_set = test_class_set[:max_len]\n",
        "\n",
        "  # Obtain subsets\n",
        "  train_class_set = torch.utils.data.Subset(train_set, train_class_set)\n",
        "  test_class_set = torch.utils.data.Subset(test_set, test_class_set)\n",
        "\n",
        "\n",
        "  # Make them\n",
        "  class_test_loader = torch.utils.data.DataLoader(\n",
        "    test_class_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "\n",
        "  class_train_loader = torch.utils.data.DataLoader(\n",
        "    train_class_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "  # Obtain train and test logits\n",
        "  logits_train = []\n",
        "  for i, (images, labels) in enumerate(class_train_loader, 0):\n",
        "    for img, label in zip(images, labels):\n",
        "      logits = model(img.unsqueeze(0))\n",
        "      losses = criterion(logits, label.unsqueeze(0)).numpy(force=True)\n",
        "\n",
        "      logits_train.append(np.concatenate((logits.detach().numpy()[0], losses)))\n",
        "\n",
        "  logits_test = []\n",
        "  for i, (images, labels) in enumerate(class_test_loader, 0):\n",
        "    for img, label in zip(images, labels):\n",
        "      logits = model(img.unsqueeze(0))\n",
        "      losses = criterion(logits, label.unsqueeze(0)).numpy(force=True)\n",
        "\n",
        "      logits_test.append((np.concatenate((logits.detach().numpy()[0], losses))))\n",
        "\n",
        "  logits_train, logits_test = np.array(logits_train), np.array(logits_test)\n",
        "  # Create dataset\n",
        "  ys = [1] * max_len + [0] * max_len\n",
        "  ys = np.array(ys)\n",
        "  p = np.random.permutation(len(ys))\n",
        "  logits = np.concatenate((logits_train, logits_test))\n",
        "\n",
        "  logits = logits[p]\n",
        "  ys = ys[p]\n",
        "\n",
        "  # Fit logitstic regression\n",
        "  clf = LogisticRegression(random_state=0, max_iter=1000)\n",
        "  cv = model_selection.StratifiedShuffleSplit(\n",
        "        n_splits=splits_num, random_state=0\n",
        "    )\n",
        "\n",
        "  clf = model_selection.cross_val_score(\n",
        "        clf, logits, ys, cv=cv, scoring=\"accuracy\"\n",
        "    )\n",
        "\n",
        "  # Output score\n",
        "  # print(f\"Mean MIA attack score for class {class_index} is: \" + str(clf.mean()))\n",
        "  return clf.mean()"
      ],
      "metadata": {
        "id": "SeZRAvZvzbpq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Check accuracy\n",
        "\n",
        "def accuracy(net, loader):\n",
        "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (inputs, targets) in enumerate(loader, 0):\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "C0ww-qC7zdMY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_losses(net, loader):\n",
        "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    all_losses = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        logits = net(inputs)\n",
        "        losses = criterion(logits, targets).numpy(force=True)\n",
        "        for l in losses:\n",
        "            all_losses.append(l)\n",
        "\n",
        "    return np.array(all_losses)"
      ],
      "metadata": {
        "id": "b3upUnMIzeeo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plain network without regularization\n",
        "## 5 %"
      ],
      "metadata": {
        "id": "BNz4tlNkzgzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"----- 5 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Baseline\"\n",
        "model_params = \"cifar10_resnet18_baseline.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  model_ft_forget.eval()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0u_Pa4QzfQj",
        "outputId": "b0cbbae8-7d32-4031-b146-030afc455f3f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT -------\n",
            "Model name: Resnet18 Baseline\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 95.6\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.6%\n",
            "Test set accuracy FORGET model: 74.5%\n",
            "Forget set accuracy FORGET model: 13.2%\n",
            "\n",
            "The MIA has an accuracy of 0.948 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 97.6\n",
            "MIA score before on forget set: 0.96\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.6%\n",
            "Test set accuracy FORGET model: 75.4%\n",
            "Forget set accuracy FORGET model: 12.8%\n",
            "\n",
            "The MIA has an accuracy of 0.964 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 92.80000000000001\n",
            "MIA score before on forget set: 0.91\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.5%\n",
            "Test set accuracy FORGET model: 75.4%\n",
            "Forget set accuracy FORGET model: 11.6%\n",
            "\n",
            "The MIA has an accuracy of 0.912 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 84.8\n",
            "MIA score before on forget set: 0.88\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.6%\n",
            "Test set accuracy FORGET model: 75.1%\n",
            "Forget set accuracy FORGET model: 10.8%\n",
            "\n",
            "The MIA has an accuracy of 0.876 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 94.8\n",
            "MIA score before on forget set: 0.91\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.7%\n",
            "Test set accuracy FORGET model: 74.9%\n",
            "Forget set accuracy FORGET model: 9.6%\n",
            "\n",
            "The MIA has an accuracy of 0.964 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 89.60000000000001\n",
            "MIA score before on forget set: 0.87\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.6%\n",
            "Test set accuracy FORGET model: 75.0%\n",
            "Forget set accuracy FORGET model: 10.0%\n",
            "\n",
            "The MIA has an accuracy of 0.904 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 97.6\n",
            "MIA score before on forget set: 0.94\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.6%\n",
            "Test set accuracy FORGET model: 75.4%\n",
            "Forget set accuracy FORGET model: 10.0%\n",
            "\n",
            "The MIA has an accuracy of 0.928 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 96.8\n",
            "MIA score before on forget set: 0.87\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.7%\n",
            "Test set accuracy FORGET model: 75.3%\n",
            "Forget set accuracy FORGET model: 9.6%\n",
            "\n",
            "The MIA has an accuracy of 0.924 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 97.2\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.7%\n",
            "Test set accuracy FORGET model: 75.5%\n",
            "Forget set accuracy FORGET model: 13.2%\n",
            "\n",
            "The MIA has an accuracy of 0.908 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 96.8\n",
            "MIA score before on forget set: 0.91\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 99.6%\n",
            "Test set accuracy FORGET model: 75.5%\n",
            "Forget set accuracy FORGET model: 13.6%\n",
            "\n",
            "The MIA has an accuracy of 0.932 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEtL09c10670",
        "outputId": "19ab6c36-ff1b-4e5d-8893-865a49dde42f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9, 0.96, 0.91, 0.88, 0.9099999999999999, 0.87, 0.94, 0.87, 0.9, 0.9099999999999999]\n",
            "[0.9480000000000001, 0.9640000000000001, 0.9119999999999999, 0.876, 0.9640000000000001, 0.9040000000000001, 0.9279999999999999, 0.924, 0.908, 0.932]\n",
            "[95.6, 97.6, 92.80000000000001, 84.8, 94.8, 89.60000000000001, 97.6, 96.8, 97.2, 96.8]\n",
            "[99.56792604501608, 99.64025162288723, 99.46940006029544, 99.5598255381585, 99.67037163588125, 99.59603673854936, 99.51563630516922, 99.75880366618426, 99.71459581139204, 99.59407591986013]\n",
            "[13.200000000000001, 12.8, 11.600000000000001, 10.8, 9.6, 10.0, 10.0, 9.6, 13.200000000000001, 13.600000000000001]\n",
            "[74.62, 75.16000000000001, 75.27000000000001, 75.22999999999999, 75.33999999999999, 74.92, 75.33, 75.14, 75.19, 75.24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean_mia_score_before_baseline = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_baseline = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_baseline = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_baseline = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_baseline = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_baseline = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "RKn0c8cd0_Rb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(mean_mia_score_before_baseline)\n",
        "print(mean_mia_score_after_baseline)\n",
        "\n",
        "print(mean_accuracy_forget_before_baseline)\n",
        "\n",
        "print(mean_accuracy_forget_after_baseline)\n",
        "print(mean_accuracy_retain_baseline)\n",
        "print(mean_accuracy_test_baseline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4yV165u1Agz",
        "outputId": "a8befb70-8615-4b20-8b16-0f40ab3c5c28"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.905\n",
            "0.9259999999999999\n",
            "94.35999999999999\n",
            "11.440000000000001\n",
            "99.60869233433937\n",
            "75.144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout model"
      ],
      "metadata": {
        "id": "NWZ15auD1IZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_model(model_train_reg):\n",
        "  from collections import OrderedDict\n",
        "\n",
        "  layer1 = model_train_reg.layer1\n",
        "\n",
        "  for indx in range(len(layer1)):\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer1[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer1[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "\n",
        "\n",
        "  layer2 = model_train_reg.layer2\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer2[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer2[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  layer3 = model_train_reg.layer3\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer3[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "    model_train_reg.layer3[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  layer4 = model_train_reg.layer4\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer4[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer4[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  return model_train_reg"
      ],
      "metadata": {
        "id": "x3h_jZGl1LAG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"----- 5 PERCENT DROPOUT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Dropout\"\n",
        "model_params = \"cifar10_resnet18_l2_dropout_regularization.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  model_forget_ft = modify_model(model_forget_ft)\n",
        "\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  model_ft_forget.eval()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A98CjAu1Muy",
        "outputId": "696cf185-0a1a-465a-d25f-417203f5e4e5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT DROPOUT -------\n",
            "Model name: Resnet18 Dropout\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 84.0\n",
            "MIA score before on forget set: 0.85\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 79.7%\n",
            "Test set accuracy FORGET model: 74.4%\n",
            "Forget set accuracy FORGET model: 15.6%\n",
            "\n",
            "The MIA has an accuracy of 0.904 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 90.0\n",
            "MIA score before on forget set: 0.93\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 80.2%\n",
            "Test set accuracy FORGET model: 74.5%\n",
            "Forget set accuracy FORGET model: 15.6%\n",
            "\n",
            "The MIA has an accuracy of 0.908 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 78.0\n",
            "MIA score before on forget set: 0.85\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 79.8%\n",
            "Test set accuracy FORGET model: 74.3%\n",
            "Forget set accuracy FORGET model: 16.8%\n",
            "\n",
            "The MIA has an accuracy of 0.896 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 61.199999999999996\n",
            "MIA score before on forget set: 0.86\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 79.0%\n",
            "Test set accuracy FORGET model: 73.9%\n",
            "Forget set accuracy FORGET model: 11.2%\n",
            "\n",
            "The MIA has an accuracy of 0.876 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 79.60000000000001\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 79.6%\n",
            "Test set accuracy FORGET model: 74.0%\n",
            "Forget set accuracy FORGET model: 10.8%\n",
            "\n",
            "The MIA has an accuracy of 0.908 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 70.0\n",
            "MIA score before on forget set: 0.84\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 79.8%\n",
            "Test set accuracy FORGET model: 74.2%\n",
            "Forget set accuracy FORGET model: 10.8%\n",
            "\n",
            "The MIA has an accuracy of 0.880 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 80.80000000000001\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 79.8%\n",
            "Test set accuracy FORGET model: 74.3%\n",
            "Forget set accuracy FORGET model: 13.6%\n",
            "\n",
            "The MIA has an accuracy of 0.848 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 85.6\n",
            "MIA score before on forget set: 0.94\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 79.8%\n",
            "Test set accuracy FORGET model: 73.9%\n",
            "Forget set accuracy FORGET model: 15.2%\n",
            "\n",
            "The MIA has an accuracy of 0.916 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 87.2\n",
            "MIA score before on forget set: 0.86\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 80.1%\n",
            "Test set accuracy FORGET model: 74.8%\n",
            "Forget set accuracy FORGET model: 16.0%\n",
            "\n",
            "The MIA has an accuracy of 0.912 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 88.8\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 79.7%\n",
            "Test set accuracy FORGET model: 74.8%\n",
            "Forget set accuracy FORGET model: 16.8%\n",
            "\n",
            "The MIA has an accuracy of 0.920 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_9yIMa01RGW",
        "outputId": "54294bd8-8f24-4117-bb02-062d09019b09"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.85, 0.9299999999999999, 0.85, 0.86, 0.8999999999999999, 0.84, 0.9, 0.94, 0.8600000000000001, 0.89]\n",
            "[0.9039999999999999, 0.908, 0.8960000000000001, 0.876, 0.908, 0.8800000000000001, 0.8480000000000001, 0.916, 0.9119999999999999, 0.9199999999999999]\n",
            "[84.0, 90.0, 78.0, 61.199999999999996, 79.60000000000001, 70.0, 80.80000000000001, 85.6, 87.2, 88.8]\n",
            "[79.62497739011596, 80.18488745980707, 80.12821801081212, 79.33716536699092, 79.37854242874944, 79.74876896794292, 79.69811472444427, 79.79781739252768, 80.15515716697483, 79.73350483349077]\n",
            "[13.200000000000001, 15.6, 10.8, 11.600000000000001, 11.600000000000001, 12.4, 13.600000000000001, 17.2, 15.2, 13.600000000000001]\n",
            "[73.89, 74.63, 74.33, 73.57000000000001, 74.11, 74.16, 74.31, 74.33999999999999, 74.44, 74.11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mean_mia_score_before_dropout = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_dropout = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_dropout = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_dropout = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_dropout = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_dropout = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "F4p2iMbz1Suj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(mean_mia_score_before_dropout)\n",
        "print(mean_mia_score_after_dropout)\n",
        "\n",
        "print(mean_accuracy_forget_before_dropout)\n",
        "\n",
        "print(mean_accuracy_forget_after_dropout)\n",
        "print(mean_accuracy_retain_dropout)\n",
        "print(mean_accuracy_test_dropout)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-pKdaQj1T1I",
        "outputId": "ef5536fb-8807-4d5e-b3e5-39b528b52cf0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.882\n",
            "0.8968000000000002\n",
            "80.52000000000001\n",
            "13.48\n",
            "79.77871537418561\n",
            "74.189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation model"
      ],
      "metadata": {
        "id": "syzh6Cbf1VyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CIFAR 10 dataset\n",
        "torch.manual_seed(1991)\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "         transforms.RandomRotation(30), # Randomly rotate some images by 20 degrees\n",
        "         transforms.RandomHorizontalFlip(), # Randomly horizontal flip the images\n",
        "         transforms.ColorJitter(brightness = 0.1, # Randomly adjust color jitter of the images\n",
        "                                                            contrast = 0.1,\n",
        "                                                            saturation = 0.1),\n",
        "         transforms.RandomAdjustSharpness(sharpness_factor = 2,\n",
        "                                                                      p = 0.1), # Randomly adjust sharpness\n",
        "          transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "to_tensor_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=to_tensor_transform\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6TnRvnS1Uts",
        "outputId": "e0538bd6-dc39-493b-a154-d1aa50d6dda1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"----- 5 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Augmentation\"\n",
        "model_params = \"cifar10_resnet18_augmentation.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  model_forget_ft.eval()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeL0R0vf1YFz",
        "outputId": "20c904e3-7197-47b2-c1b5-9b7831dbb386"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT -------\n",
            "Model name: Resnet18 Augmentation\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 78.8\n",
            "MIA score before on forget set: 0.92\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 77.6%\n",
            "Test set accuracy FORGET model: 77.0%\n",
            "Forget set accuracy FORGET model: 16.8%\n",
            "\n",
            "The MIA has an accuracy of 0.884 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 80.4\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 77.1%\n",
            "Test set accuracy FORGET model: 76.7%\n",
            "Forget set accuracy FORGET model: 12.4%\n",
            "\n",
            "The MIA has an accuracy of 0.912 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 75.2\n",
            "MIA score before on forget set: 0.88\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 77.3%\n",
            "Test set accuracy FORGET model: 77.1%\n",
            "Forget set accuracy FORGET model: 14.4%\n",
            "\n",
            "The MIA has an accuracy of 0.856 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 66.0\n",
            "MIA score before on forget set: 0.8\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 77.7%\n",
            "Test set accuracy FORGET model: 76.8%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "\n",
            "The MIA has an accuracy of 0.880 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 72.8\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 77.4%\n",
            "Test set accuracy FORGET model: 76.7%\n",
            "Forget set accuracy FORGET model: 11.2%\n",
            "\n",
            "The MIA has an accuracy of 0.880 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 71.6\n",
            "MIA score before on forget set: 0.87\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 77.8%\n",
            "Test set accuracy FORGET model: 77.3%\n",
            "Forget set accuracy FORGET model: 10.4%\n",
            "\n",
            "The MIA has an accuracy of 0.876 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 84.8\n",
            "MIA score before on forget set: 0.88\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 77.9%\n",
            "Test set accuracy FORGET model: 77.0%\n",
            "Forget set accuracy FORGET model: 12.0%\n",
            "\n",
            "The MIA has an accuracy of 0.900 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 82.0\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 77.2%\n",
            "Test set accuracy FORGET model: 76.8%\n",
            "Forget set accuracy FORGET model: 13.6%\n",
            "\n",
            "The MIA has an accuracy of 0.848 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 86.8\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 77.0%\n",
            "Test set accuracy FORGET model: 76.5%\n",
            "Forget set accuracy FORGET model: 14.4%\n",
            "\n",
            "The MIA has an accuracy of 0.920 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 80.4\n",
            "MIA score before on forget set: 0.77\n",
            "\n",
            "\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "Retain set accuracy FORGET model: 77.6%\n",
            "Test set accuracy FORGET model: 77.0%\n",
            "Forget set accuracy FORGET model: 11.2%\n",
            "\n",
            "The MIA has an accuracy of 0.908 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp5m_n1W1alJ",
        "outputId": "eb881d1f-9c32-4c37-f4a7-3a0d824bbbcc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.92, 0.8999999999999999, 0.88, 0.8, 0.89, 0.87, 0.8799999999999999, 0.89, 0.89, 0.77]\n",
            "[0.884, 0.9120000000000001, 0.8560000000000001, 0.8800000000000001, 0.8800000000000001, 0.876, 0.9, 0.8480000000000001, 0.9200000000000002, 0.908]\n",
            "[78.8, 80.4, 75.2, 66.0, 72.8, 71.6, 84.8, 82.0, 86.8, 80.4]\n",
            "[77.4570888772762, 77.13952647023355, 77.65831306899254, 77.89367902723345, 77.52029905940992, 77.72709003215435, 77.69560061900837, 77.31594074729162, 77.19671999356862, 77.85951160687368]\n",
            "[16.400000000000002, 14.000000000000002, 12.8, 10.8, 13.600000000000001, 11.600000000000001, 11.600000000000001, 15.2, 10.8, 11.200000000000001]\n",
            "[77.19, 76.55999999999999, 77.03999999999999, 76.5, 76.73, 77.16, 77.03999999999999, 76.89, 76.39, 77.14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mean_mia_score_before_aug = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_aug = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_aug = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_aug = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_aug = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_aug = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "wA5ectdq1cB0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(mean_mia_score_before_aug)\n",
        "print(mean_mia_score_after_aug)\n",
        "\n",
        "print(mean_accuracy_forget_before_aug)\n",
        "\n",
        "print(mean_accuracy_forget_after_aug)\n",
        "print(mean_accuracy_retain_aug)\n",
        "print(mean_accuracy_test_aug)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ7QBYiK1dCj",
        "outputId": "8efa1258-f142-4a80-d74d-210b30dbe451"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.869\n",
            "0.8864000000000001\n",
            "77.87999999999998\n",
            "12.8\n",
            "77.54637695020423\n",
            "76.86399999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sPIg81521ede"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}