{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rovoKPi6RDj",
        "outputId": "c153759a-310f-4acd-c13f-671dd23d1b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "from tempfile import TemporaryDirectory\n",
        "import seaborn as sns\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on device:\", DEVICE.upper())\n",
        "\n",
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(1991)\n",
        "torch.manual_seed(1991)\n",
        "torch.cuda.manual_seed(1991)\n",
        "\n",
        "import random\n",
        "random.seed(1991)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1991)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR 10 dataset\n",
        "torch.manual_seed(1991)\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=normalize\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78PaWuAD6bHt",
        "outputId": "0faf3ac4-6458-4f72-b0ff-275ab7f77b1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43298769.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unlearning algorithm\n",
        "def unlearning(net, retain, forget, validation, epochs):\n",
        "    \"\"\"Unlearning by fine-tuning.\n",
        "\n",
        "    Fine-tuning is a very simple algorithm that trains using only\n",
        "    the retain set.\n",
        "\n",
        "    Args:\n",
        "      net : nn.Module.\n",
        "        pre-trained model to use as base of unlearning.\n",
        "      retain : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the retain set. This is the subset\n",
        "        of the training set that we don't want to forget.\n",
        "      forget : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the forget set. This is the subset\n",
        "        of the training set that we want to forget. This method doesn't\n",
        "        make use of the forget set.\n",
        "      validation : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the validation set. This method doesn't\n",
        "        make use of the validation set.\n",
        "    Returns:\n",
        "      net : updated model\n",
        "    \"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    net.train()\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for inputs, targets in retain:\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    net.eval()\n",
        "    return net\n"
      ],
      "metadata": {
        "id": "x_VxXgyC6hHf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def train_mia_on_class(model, class_index, train_set, test_set, no_class=True, splits_num=5):\n",
        "  model = model.to(\"cpu\")\n",
        "\n",
        "  if not no_class:\n",
        "    # Select indencies where class is class_index\n",
        "    train_class_set = np.where(np.array(train_set.targets) == class_index)[0]\n",
        "    test_class_set = np.where(np.array(test_set.targets) == class_index)[0]\n",
        "  else:\n",
        "    train_class_set = np.arange(len(train_set))\n",
        "    test_class_set = np.arange(len(test_set))\n",
        "\n",
        "  max_len = min([len(train_class_set), len(test_class_set)])\n",
        "  # Make equal sizes\n",
        "  train_class_set = train_class_set[:max_len]\n",
        "  test_class_set = test_class_set[:max_len]\n",
        "\n",
        "  # Obtain subsets\n",
        "  train_class_set = torch.utils.data.Subset(train_set, train_class_set)\n",
        "  test_class_set = torch.utils.data.Subset(test_set, test_class_set)\n",
        "\n",
        "\n",
        "  # Make them\n",
        "  class_test_loader = torch.utils.data.DataLoader(\n",
        "    test_class_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "\n",
        "  class_train_loader = torch.utils.data.DataLoader(\n",
        "    train_class_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "  # Obtain train and test logits\n",
        "  logits_train = []\n",
        "  for i, (images, labels) in enumerate(class_train_loader, 0):\n",
        "    for img, label in zip(images, labels):\n",
        "      logits = model(img.unsqueeze(0))\n",
        "      losses = criterion(logits, label.unsqueeze(0)).numpy(force=True)\n",
        "\n",
        "      logits_train.append(np.concatenate((logits.detach().numpy()[0], losses)))\n",
        "\n",
        "  logits_test = []\n",
        "  for i, (images, labels) in enumerate(class_test_loader, 0):\n",
        "    for img, label in zip(images, labels):\n",
        "      logits = model(img.unsqueeze(0))\n",
        "      losses = criterion(logits, label.unsqueeze(0)).numpy(force=True)\n",
        "\n",
        "      logits_test.append((np.concatenate((logits.detach().numpy()[0], losses))))\n",
        "\n",
        "  logits_train, logits_test = np.array(logits_train), np.array(logits_test)\n",
        "  # Create dataset\n",
        "  ys = [1] * max_len + [0] * max_len\n",
        "  ys = np.array(ys)\n",
        "  p = np.random.permutation(len(ys))\n",
        "  logits = np.concatenate((logits_train, logits_test))\n",
        "\n",
        "  logits = logits[p]\n",
        "  ys = ys[p]\n",
        "\n",
        "  # Fit logitstic regression\n",
        "  clf = LogisticRegression(random_state=0, max_iter=1000)\n",
        "  cv = model_selection.StratifiedShuffleSplit(\n",
        "        n_splits=splits_num, random_state=0\n",
        "    )\n",
        "\n",
        "  clf = model_selection.cross_val_score(\n",
        "        clf, logits, ys, cv=cv, scoring=\"accuracy\"\n",
        "    )\n",
        "\n",
        "  # Output score\n",
        "  # print(f\"Mean MIA attack score for class {class_index} is: \" + str(clf.mean()))\n",
        "  return clf.mean()"
      ],
      "metadata": {
        "id": "cRK7Onpm6juS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check accuracy\n",
        "\n",
        "def accuracy(net, loader):\n",
        "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (inputs, targets) in enumerate(loader, 0):\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "EF_QVWrp6nN1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_losses(net, loader):\n",
        "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    all_losses = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        logits = net(inputs)\n",
        "        losses = criterion(logits, targets).numpy(force=True)\n",
        "        for l in losses:\n",
        "            all_losses.append(l)\n",
        "\n",
        "    return np.array(all_losses)\n"
      ],
      "metadata": {
        "id": "BOd3xK2s6oqq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SstF6qWF6p-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plain network without regularization\n",
        "### 5 % of dataset class; 5 epochs"
      ],
      "metadata": {
        "id": "_EhbyFZ56qfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"----- 5 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Baseline\"\n",
        "model_params = \"cifar10_resnet18_baseline.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader, 5)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8IQKri06wMm",
        "outputId": "144d1b2f-bd9c-497b-c596-a751fe6dd864"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT -------\n",
            "Model name: Resnet18 Baseline\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 94.8\n",
            "MIA score before on forget set: 0.88\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 99.4%\n",
            "Test set accuracy FORGET model: 76.6%\n",
            "Forget set accuracy FORGET model: 85.2%\n",
            "\n",
            "The MIA has an accuracy of 0.892 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 98.4\n",
            "MIA score before on forget set: 0.94\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 92.9%\n",
            "Test set accuracy FORGET model: 75.0%\n",
            "Forget set accuracy FORGET model: 84.8%\n",
            "\n",
            "The MIA has an accuracy of 0.924 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 89.60000000000001\n",
            "MIA score before on forget set: 0.87\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 98.7%\n",
            "Test set accuracy FORGET model: 76.1%\n",
            "Forget set accuracy FORGET model: 67.2%\n",
            "\n",
            "The MIA has an accuracy of 0.860 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 84.0\n",
            "MIA score before on forget set: 0.84\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 96.3%\n",
            "Test set accuracy FORGET model: 75.5%\n",
            "Forget set accuracy FORGET model: 68.4%\n",
            "\n",
            "The MIA has an accuracy of 0.776 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 94.0\n",
            "MIA score before on forget set: 0.92\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 99.4%\n",
            "Test set accuracy FORGET model: 76.5%\n",
            "Forget set accuracy FORGET model: 85.6%\n",
            "\n",
            "The MIA has an accuracy of 0.896 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 88.0\n",
            "MIA score before on forget set: 0.93\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 99.4%\n",
            "Test set accuracy FORGET model: 76.8%\n",
            "Forget set accuracy FORGET model: 73.2%\n",
            "\n",
            "The MIA has an accuracy of 0.868 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 94.39999999999999\n",
            "MIA score before on forget set: 0.87\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 96.8%\n",
            "Test set accuracy FORGET model: 75.2%\n",
            "Forget set accuracy FORGET model: 81.6%\n",
            "\n",
            "The MIA has an accuracy of 0.880 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 96.8\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 95.3%\n",
            "Test set accuracy FORGET model: 75.2%\n",
            "Forget set accuracy FORGET model: 81.2%\n",
            "\n",
            "The MIA has an accuracy of 0.892 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 96.0\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 96.3%\n",
            "Test set accuracy FORGET model: 75.7%\n",
            "Forget set accuracy FORGET model: 89.6%\n",
            "\n",
            "The MIA has an accuracy of 0.908 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 95.6\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 95.8%\n",
            "Test set accuracy FORGET model: 75.2%\n",
            "Forget set accuracy FORGET model: 86.8%\n",
            "\n",
            "The MIA has an accuracy of 0.888 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JIsYuB-7lXR",
        "outputId": "656ee3e6-b5d1-4841-9528-fe4674bb4dc9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.88, 0.94, 0.87, 0.84, 0.92, 0.9299999999999999, 0.87, 0.9, 0.9, 0.9]\n",
            "[0.892, 0.924, 0.86, 0.776, 0.8959999999999999, 0.868, 0.8800000000000001, 0.892, 0.908, 0.8880000000000001]\n",
            "[94.8, 98.4, 89.60000000000001, 84.0, 94.0, 88.0, 94.39999999999999, 96.8, 96.0, 95.6]\n",
            "[99.41915385388404, 92.90925535122099, 98.74989950960689, 96.2883324625216, 99.41917720119781, 99.43924106604494, 96.82061176092287, 95.25283382908594, 96.25796338350851, 95.80553099123725]\n",
            "[85.2, 84.8, 67.2, 68.4, 85.6, 73.2, 81.6, 81.2, 89.60000000000001, 86.8]\n",
            "[76.63, 75.02, 76.13, 75.47, 76.53, 76.82, 75.18, 75.17, 75.67, 75.16000000000001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean_mia_score_before_baseline = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_baseline = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_baseline = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_baseline = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_baseline = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_baseline = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "Lzxc2VoE8hbk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(mean_mia_score_before_baseline)\n",
        "print(mean_mia_score_after_baseline)\n",
        "\n",
        "print(mean_accuracy_forget_before_baseline)\n",
        "\n",
        "print(mean_accuracy_forget_after_baseline)\n",
        "print(mean_accuracy_retain_baseline)\n",
        "print(mean_accuracy_test_baseline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzqqwdsq8n7-",
        "outputId": "9e9a8272-1d53-4e7c-c32f-edd65b232de0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8950000000000001\n",
            "0.8784000000000001\n",
            "93.16\n",
            "80.36\n",
            "97.03619994092307\n",
            "75.77799999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout model"
      ],
      "metadata": {
        "id": "i2aD51ew-u8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1991)\n",
        "model_train_reg = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "model_train_reg = model_train_reg.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_train_reg.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "# Decay LR by a factor of 0.001 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.0005)"
      ],
      "metadata": {
        "id": "6dg2vAlk-uIJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_model(model_train_reg):\n",
        "  from collections import OrderedDict\n",
        "\n",
        "  layer1 = model_train_reg.layer1\n",
        "\n",
        "  for indx in range(len(layer1)):\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer1[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer1[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "\n",
        "\n",
        "  layer2 = model_train_reg.layer2\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer2[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer2[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  layer3 = model_train_reg.layer3\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer3[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "    model_train_reg.layer3[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  layer4 = model_train_reg.layer4\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer4[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer4[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  return model_train_reg"
      ],
      "metadata": {
        "id": "fCWbaEzN-84O"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train_reg = modify_model(model_train_reg)"
      ],
      "metadata": {
        "id": "a013hg0Q_Dhm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train_reg.load_state_dict(torch.load(\"cifar10_resnet18_l2_dropout_regularization.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_WTDkVJAZVB",
        "outputId": "9e1bd06b-ec67-4524-a953-e60fad72ad0e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"----- 5 PERCENT DROPOUT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Dropout\"\n",
        "model_params = \"cifar10_resnet18_l2_dropout_regularization.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  model_forget_ft = modify_model(model_forget_ft)\n",
        "\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader, 5)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZe-hVIQAhv3",
        "outputId": "680845a9-2177-4b8f-c90b-4de54054a388"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT DROPOUT -------\n",
            "Model name: Resnet18 Dropout\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 86.4\n",
            "MIA score before on forget set: 0.92\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 85.1%\n",
            "Test set accuracy FORGET model: 78.1%\n",
            "Forget set accuracy FORGET model: 86.0%\n",
            "\n",
            "The MIA has an accuracy of 0.880 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 85.2\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 84.6%\n",
            "Test set accuracy FORGET model: 77.5%\n",
            "Forget set accuracy FORGET model: 82.8%\n",
            "\n",
            "The MIA has an accuracy of 0.920 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 67.60000000000001\n",
            "MIA score before on forget set: 0.86\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 83.2%\n",
            "Test set accuracy FORGET model: 76.3%\n",
            "Forget set accuracy FORGET model: 72.0%\n",
            "\n",
            "The MIA has an accuracy of 0.852 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 57.199999999999996\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 85.7%\n",
            "Test set accuracy FORGET model: 78.2%\n",
            "Forget set accuracy FORGET model: 59.6%\n",
            "\n",
            "The MIA has an accuracy of 0.872 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 74.4\n",
            "MIA score before on forget set: 0.96\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 86.0%\n",
            "Test set accuracy FORGET model: 78.4%\n",
            "Forget set accuracy FORGET model: 78.4%\n",
            "\n",
            "The MIA has an accuracy of 0.916 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 69.19999999999999\n",
            "MIA score before on forget set: 0.84\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 84.5%\n",
            "Test set accuracy FORGET model: 77.0%\n",
            "Forget set accuracy FORGET model: 68.8%\n",
            "\n",
            "The MIA has an accuracy of 0.848 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 80.80000000000001\n",
            "MIA score before on forget set: 0.83\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 84.3%\n",
            "Test set accuracy FORGET model: 77.0%\n",
            "Forget set accuracy FORGET model: 84.8%\n",
            "\n",
            "The MIA has an accuracy of 0.864 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 80.80000000000001\n",
            "MIA score before on forget set: 0.84\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 85.0%\n",
            "Test set accuracy FORGET model: 77.0%\n",
            "Forget set accuracy FORGET model: 76.0%\n",
            "\n",
            "The MIA has an accuracy of 0.904 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 88.0\n",
            "MIA score before on forget set: 0.86\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 84.7%\n",
            "Test set accuracy FORGET model: 77.7%\n",
            "Forget set accuracy FORGET model: 92.4%\n",
            "\n",
            "The MIA has an accuracy of 0.884 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 89.60000000000001\n",
            "MIA score before on forget set: 0.93\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 84.2%\n",
            "Test set accuracy FORGET model: 77.0%\n",
            "Forget set accuracy FORGET model: 86.4%\n",
            "\n",
            "The MIA has an accuracy of 0.876 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MWebXf-A-Dx",
        "outputId": "4bc68a2b-07cc-4ab3-ffce-d99964e52380"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9199999999999999, 0.9, 0.86, 0.8999999999999999, 0.96, 0.8400000000000001, 0.8300000000000001, 0.84, 0.86, 0.9299999999999999]\n",
            "[0.8799999999999999, 0.9199999999999999, 0.852, 0.8719999999999999, 0.916, 0.8480000000000001, 0.8640000000000001, 0.9039999999999999, 0.884, 0.876]\n",
            "[86.4, 85.2, 67.60000000000001, 57.199999999999996, 74.4, 69.19999999999999, 80.80000000000001, 80.80000000000001, 88.0, 89.60000000000001]\n",
            "[85.07978616503878, 84.59822325843149, 83.2448946776009, 85.67006994131361, 85.9511606873681, 84.48088749547811, 84.32180396728099, 84.98502723234922, 84.72978676367144, 84.17604501607717]\n",
            "[86.0, 82.8, 72.0, 59.599999999999994, 78.4, 68.8, 84.8, 76.0, 92.4, 86.4]\n",
            "[78.12, 77.53, 76.32, 78.19, 78.42, 76.98, 77.0, 77.03, 77.71000000000001, 77.03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean_mia_score_before_dropout = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_dropout = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_dropout = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_dropout = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_dropout = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_dropout = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "dJGhk0p8BBJv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(mean_mia_score_before_dropout)\n",
        "print(mean_mia_score_after_dropout)\n",
        "\n",
        "print(mean_accuracy_forget_before_dropout)\n",
        "\n",
        "print(mean_accuracy_forget_after_dropout)\n",
        "print(mean_accuracy_retain_dropout)\n",
        "print(mean_accuracy_test_dropout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgXmLJFrBIG5",
        "outputId": "7be27657-a6c8-4757-e6ce-e706f28b3e25"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.884\n",
            "0.8815999999999999\n",
            "77.92000000000002\n",
            "78.72\n",
            "84.72376852046098\n",
            "77.43299999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation model"
      ],
      "metadata": {
        "id": "A82HpBb5BVvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR 10 dataset\n",
        "torch.manual_seed(1991)\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "         transforms.RandomRotation(30), # Randomly rotate some images by 20 degrees\n",
        "         transforms.RandomHorizontalFlip(), # Randomly horizontal flip the images\n",
        "         transforms.ColorJitter(brightness = 0.1, # Randomly adjust color jitter of the images\n",
        "                                                            contrast = 0.1,\n",
        "                                                            saturation = 0.1),\n",
        "         transforms.RandomAdjustSharpness(sharpness_factor = 2,\n",
        "                                                                      p = 0.1), # Randomly adjust sharpness\n",
        "          transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "to_tensor_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=to_tensor_transform\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRWiJ642BVBb",
        "outputId": "da3217ee-d043-44df-d258-a6f8fce858ed"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"----- 5 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Augmentation\"\n",
        "model_params = \"cifar10_resnet18_augmentation.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader, 5)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg2P1jWXBbmf",
        "outputId": "4295b2da-227a-42b7-848b-e6952bc6fcc3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT -------\n",
            "Model name: Resnet18 Augmentation\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 81.2\n",
            "MIA score before on forget set: 0.93\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 75.8%\n",
            "Test set accuracy FORGET model: 76.6%\n",
            "Forget set accuracy FORGET model: 79.2%\n",
            "\n",
            "The MIA has an accuracy of 0.880 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 82.39999999999999\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 75.4%\n",
            "Test set accuracy FORGET model: 76.0%\n",
            "Forget set accuracy FORGET model: 80.8%\n",
            "\n",
            "The MIA has an accuracy of 0.900 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 63.2\n",
            "MIA score before on forget set: 0.81\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 74.7%\n",
            "Test set accuracy FORGET model: 75.8%\n",
            "Forget set accuracy FORGET model: 60.8%\n",
            "\n",
            "The MIA has an accuracy of 0.852 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 67.2\n",
            "MIA score before on forget set: 0.87\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 77.4%\n",
            "Test set accuracy FORGET model: 76.9%\n",
            "Forget set accuracy FORGET model: 56.8%\n",
            "\n",
            "The MIA has an accuracy of 0.864 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 80.80000000000001\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 76.9%\n",
            "Test set accuracy FORGET model: 77.0%\n",
            "Forget set accuracy FORGET model: 77.2%\n",
            "\n",
            "The MIA has an accuracy of 0.892 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 67.60000000000001\n",
            "MIA score before on forget set: 0.85\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 75.6%\n",
            "Test set accuracy FORGET model: 76.2%\n",
            "Forget set accuracy FORGET model: 63.6%\n",
            "\n",
            "The MIA has an accuracy of 0.848 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 81.6\n",
            "MIA score before on forget set: 0.85\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 77.0%\n",
            "Test set accuracy FORGET model: 77.7%\n",
            "Forget set accuracy FORGET model: 77.6%\n",
            "\n",
            "The MIA has an accuracy of 0.900 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 81.2\n",
            "MIA score before on forget set: 0.85\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 75.2%\n",
            "Test set accuracy FORGET model: 76.2%\n",
            "Forget set accuracy FORGET model: 75.2%\n",
            "\n",
            "The MIA has an accuracy of 0.872 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 86.0\n",
            "MIA score before on forget set: 0.92\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 77.4%\n",
            "Test set accuracy FORGET model: 77.1%\n",
            "Forget set accuracy FORGET model: 84.8%\n",
            "\n",
            "The MIA has an accuracy of 0.848 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 78.8\n",
            "MIA score before on forget set: 0.87\n",
            "\n",
            "\n",
            "Retain set accuracy FORGET model: 75.8%\n",
            "Test set accuracy FORGET model: 76.1%\n",
            "Forget set accuracy FORGET model: 73.6%\n",
            "\n",
            "The MIA has an accuracy of 0.888 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq2Lb687BlXP",
        "outputId": "5455f23c-316e-41c9-afee-4fdb64f624a4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9299999999999999, 0.8999999999999999, 0.81, 0.87, 0.8999999999999999, 0.85, 0.85, 0.85, 0.92, 0.87]\n",
            "[0.8800000000000001, 0.9, 0.852, 0.8640000000000001, 0.892, 0.8480000000000001, 0.9, 0.8720000000000001, 0.8480000000000001, 0.8879999999999999]\n",
            "[81.2, 82.39999999999999, 63.2, 67.2, 80.80000000000001, 67.60000000000001, 81.6, 81.2, 86.0, 78.8]\n",
            "[75.80697029384572, 75.37484423362946, 74.65482243704403, 77.21170465050847, 76.8677265692521, 75.41049500572784, 76.68562471110754, 75.45724966836838, 77.48703726034005, 75.93705408284262]\n",
            "[78.8, 80.4, 57.599999999999994, 55.2, 75.2, 60.4, 79.60000000000001, 76.4, 84.8, 72.39999999999999]\n",
            "[76.63, 76.03, 75.82, 76.91, 77.05, 76.21, 77.73, 76.16000000000001, 77.12, 76.09]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean_mia_score_before_aug = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_aug = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_aug = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_aug = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_aug = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_aug = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "8klYyY8JBoPq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(mean_mia_score_before_aug)\n",
        "print(mean_mia_score_after_aug)\n",
        "\n",
        "print(mean_accuracy_forget_before_aug)\n",
        "\n",
        "print(mean_accuracy_forget_after_aug)\n",
        "print(mean_accuracy_retain_aug)\n",
        "print(mean_accuracy_test_aug)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZqLx3vUBvMy",
        "outputId": "b077177c-66ee-451b-8c41-cfd888b3412b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.875\n",
            "0.8744\n",
            "77.0\n",
            "72.08\n",
            "76.08935289126661\n",
            "76.575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bPxdNcReB2kH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}