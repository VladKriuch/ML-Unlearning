{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "836x45ch43CH",
        "outputId": "72c0648a-24bd-468e-9f4a-07eff52f85c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "from tempfile import TemporaryDirectory\n",
        "import seaborn as sns\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on device:\", DEVICE.upper())\n",
        "\n",
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(1991)\n",
        "torch.manual_seed(1991)\n",
        "torch.cuda.manual_seed(1991)\n",
        "\n",
        "import random\n",
        "random.seed(1991)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1991)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CIFAR 10 dataset\n",
        "torch.manual_seed(1991)\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=normalize\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S01nm77p4-Ht",
        "outputId": "25d2a735-185e-4c2c-9a84-a48a13cafe07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 49343891.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, Subset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "4jmGLz056QYX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sch = 'linear'\n",
        "init_rate = 0.3\n",
        "init_method = 'snip_little_grad'\n",
        "lr = 0.001\n",
        "epoch = 5\n",
        "weight_decay = 5e-4\n",
        "\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "class LinearAnnealingLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, num_annealing_steps, num_total_steps):\n",
        "        self.num_annealing_steps = num_annealing_steps\n",
        "        self.num_total_steps = num_total_steps\n",
        "\n",
        "        super().__init__(optimizer)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if self._step_count <= self.num_annealing_steps:\n",
        "            return [base_lr * self._step_count / self.num_annealing_steps for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            return [base_lr * (self.num_total_steps - self._step_count) / (self.num_total_steps - self.num_annealing_steps) for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "def set_layer(model, layer_name, layer):\n",
        "    splited = layer_name.split('.')\n",
        "    if len(splited) == 1:\n",
        "        setattr(model, splited[0], layer)\n",
        "    elif len(splited) == 3:\n",
        "        setattr(getattr(model, splited[0])[int(splited[1])], splited[2], layer)\n",
        "    elif len(splited) == 4:\n",
        "        getattr(getattr(model, splited[0])[int(splited[1])], splited[2])[int(splited[3])] = layer\n",
        "\n",
        "class Masker(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, mask):\n",
        "        ctx.save_for_backward(mask)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad):\n",
        "        mask, = ctx.saved_tensors\n",
        "        return grad * mask, None\n",
        "\n",
        "class MaskConv2d(nn.Conv2d):\n",
        "    def __init__(self, mask, in_channels, out_channels, kernel_size, stride=1,\n",
        "                 padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device='cpu'):\n",
        "        super(MaskConv2d, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
        "                                     padding, dilation, groups, bias, padding_mode, device=device)\n",
        "        self.mask = mask\n",
        "\n",
        "    def forward(self, input):\n",
        "        masked_weight = Masker.apply(self.weight, self.mask)\n",
        "        return super(MaskConv2d, self)._conv_forward(input, masked_weight, self.bias)\n",
        "\n",
        "@torch.no_grad()\n",
        "def replace_maskconv(model):\n",
        "    print(\"Remove Maskconv\")\n",
        "    for name, m in list(model.named_modules()):\n",
        "        if isinstance(m, MaskConv2d):\n",
        "            conv = nn.Conv2d(m.in_channels, m.out_channels, m.kernel_size, m.stride,\n",
        "                 m.padding, m.dilation, m.groups, m.bias!=None, m.padding_mode, device=DEVICE)\n",
        "            conv.weight.data = m.weight\n",
        "            conv.bias = m.bias\n",
        "            set_layer(model, name, conv)\n",
        "\n",
        "def get_grads_for_snip(model, retain_loader, forget_loader):\n",
        "    indices = torch.randperm(len(retain_loader.dataset), dtype=torch.int32, device='cpu')[:len(forget_loader.dataset)]\n",
        "    retain_dataset = torch.utils.data.Subset(retain_loader.dataset, indices)\n",
        "    retain_loader = DataLoader(retain_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    model.zero_grad()\n",
        "    for sample in retain_loader:\n",
        "        inputs = sample[0]\n",
        "        targets = sample[1]\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = F.cross_entropy(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "    for sample in forget_loader:\n",
        "        inputs = sample[0]\n",
        "        targets = sample[1]\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = -F.cross_entropy(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "@torch.no_grad()\n",
        "def re_init_model_snip_ver2_little_grad(model, px): # re init smallest gradients\n",
        "    print(\"Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\")\n",
        "    for name, m in list(model.named_modules()):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            mask = torch.zeros_like(m.weight, device=DEVICE).bool()\n",
        "            nparams_toprune = round(px*mask.nelement())\n",
        "\n",
        "            out_c, in_c, ke, _ = mask.shape\n",
        "            value = -m.weight.grad.abs()\n",
        "            topk = torch.topk(value.view(-1), k=nparams_toprune)\n",
        "            mask.view(-1)[topk.indices] = True\n",
        "            grad_mask = mask.clone().float()\n",
        "            grad_mask[grad_mask==0] += 0.1\n",
        "\n",
        "            new_conv = MaskConv2d(grad_mask, m.in_channels, m.out_channels, m.kernel_size, m.stride,\n",
        "                 m.padding, m.dilation, m.groups, m.bias!=None, m.padding_mode, device=DEVICE)\n",
        "            nn.init.kaiming_normal_(new_conv.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "\n",
        "            new_conv.weight.data[~mask] = m.weight[~mask]\n",
        "\n",
        "            set_layer(model, name, new_conv)\n",
        "\n",
        "\n",
        "def unlearning(\n",
        "    net,\n",
        "    retain_loader,\n",
        "    forget_loader,\n",
        "    val_loader):\n",
        "    if init_method=='snip_little_grad':\n",
        "        # replace_maskconv(net)\n",
        "        get_grads_for_snip(net, retain_loader, forget_loader)\n",
        "        re_init_model_snip_ver2_little_grad(net, init_rate)\n",
        "\n",
        "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
        "    epochs = epoch\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr,\n",
        "                      momentum=0.9, weight_decay=weight_decay)\n",
        "\n",
        "    if sch=='linear':\n",
        "        scheduler = LinearAnnealingLR(optimizer, num_annealing_steps=(epochs+1)//2, num_total_steps=epochs+1)\n",
        "    net.train()\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        for sample in retain_loader:\n",
        "            inputs = sample[0]\n",
        "            targets = sample[1]\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "    #remove_prune(net)\n",
        "    net.eval()\n",
        "    return net\n",
        ""
      ],
      "metadata": {
        "id": "ootEb02R5Ikf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def train_mia_on_class(model, class_index, train_set, test_set, no_class=True, splits_num=5):\n",
        "  model = model.to(\"cpu\")\n",
        "\n",
        "  if not no_class:\n",
        "    # Select indencies where class is class_index\n",
        "    train_class_set = np.where(np.array(train_set.targets) == class_index)[0]\n",
        "    test_class_set = np.where(np.array(test_set.targets) == class_index)[0]\n",
        "  else:\n",
        "    train_class_set = np.arange(len(train_set))\n",
        "    test_class_set = np.arange(len(test_set))\n",
        "\n",
        "  max_len = min([len(train_class_set), len(test_class_set)])\n",
        "  # Make equal sizes\n",
        "  train_class_set = train_class_set[:max_len]\n",
        "  test_class_set = test_class_set[:max_len]\n",
        "\n",
        "  # Obtain subsets\n",
        "  train_class_set = torch.utils.data.Subset(train_set, train_class_set)\n",
        "  test_class_set = torch.utils.data.Subset(test_set, test_class_set)\n",
        "\n",
        "\n",
        "  # Make them\n",
        "  class_test_loader = torch.utils.data.DataLoader(\n",
        "    test_class_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "\n",
        "  class_train_loader = torch.utils.data.DataLoader(\n",
        "    train_class_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "  # Obtain train and test logits\n",
        "  logits_train = []\n",
        "  for i, (images, labels) in enumerate(class_train_loader, 0):\n",
        "    for img, label in zip(images, labels):\n",
        "      logits = model(img.unsqueeze(0))\n",
        "      losses = criterion(logits, label.unsqueeze(0)).numpy(force=True)\n",
        "\n",
        "      logits_train.append(np.concatenate((logits.detach().numpy()[0], losses)))\n",
        "\n",
        "  logits_test = []\n",
        "  for i, (images, labels) in enumerate(class_test_loader, 0):\n",
        "    for img, label in zip(images, labels):\n",
        "      logits = model(img.unsqueeze(0))\n",
        "      losses = criterion(logits, label.unsqueeze(0)).numpy(force=True)\n",
        "\n",
        "      logits_test.append((np.concatenate((logits.detach().numpy()[0], losses))))\n",
        "\n",
        "  logits_train, logits_test = np.array(logits_train), np.array(logits_test)\n",
        "  # Create dataset\n",
        "  ys = [1] * max_len + [0] * max_len\n",
        "  ys = np.array(ys)\n",
        "  p = np.random.permutation(len(ys))\n",
        "  logits = np.concatenate((logits_train, logits_test))\n",
        "\n",
        "  logits = logits[p]\n",
        "  ys = ys[p]\n",
        "\n",
        "  # Fit logitstic regression\n",
        "  clf = LogisticRegression(random_state=0, max_iter=1000)\n",
        "  cv = model_selection.StratifiedShuffleSplit(\n",
        "        n_splits=splits_num, random_state=0\n",
        "    )\n",
        "\n",
        "  clf = model_selection.cross_val_score(\n",
        "        clf, logits, ys, cv=cv, scoring=\"accuracy\"\n",
        "    )\n",
        "\n",
        "  # Output score\n",
        "  # print(f\"Mean MIA attack score for class {class_index} is: \" + str(clf.mean()))\n",
        "  return clf.mean()"
      ],
      "metadata": {
        "id": "Lxg3tetK5QN3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Check accuracy\n",
        "\n",
        "def accuracy(net, loader):\n",
        "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (inputs, targets) in enumerate(loader, 0):\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "FVtadcTy5R6q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_losses(net, loader):\n",
        "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    all_losses = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        logits = net(inputs)\n",
        "        losses = criterion(logits, targets).numpy(force=True)\n",
        "        for l in losses:\n",
        "            all_losses.append(l)\n",
        "\n",
        "    return np.array(all_losses)"
      ],
      "metadata": {
        "id": "SuXH8Guw5S-p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plain network without regularization\n",
        "## 5 %"
      ],
      "metadata": {
        "id": "sk66aClX5VAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"----- 5 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Baseline\"\n",
        "model_params = \"cifar10_resnet18_baseline.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  model_ft_forget.eval()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvSj6qha5Tsd",
        "outputId": "3f98356a-0d42-4315-f834-a381ceb6d11e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT -------\n",
            "Model name: Resnet18 Baseline\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 94.8\n",
            "MIA score before on forget set: 0.91\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 78.4%\n",
            "Test set accuracy FORGET model: 68.5%\n",
            "Forget set accuracy FORGET model: 78.4%\n",
            "\n",
            "The MIA has an accuracy of 0.860 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 98.4\n",
            "MIA score before on forget set: 0.94\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 78.6%\n",
            "Test set accuracy FORGET model: 67.9%\n",
            "Forget set accuracy FORGET model: 88.0%\n",
            "\n",
            "The MIA has an accuracy of 0.896 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 89.60000000000001\n",
            "MIA score before on forget set: 0.84\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 78.2%\n",
            "Test set accuracy FORGET model: 68.9%\n",
            "Forget set accuracy FORGET model: 64.0%\n",
            "\n",
            "The MIA has an accuracy of 0.832 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 84.0\n",
            "MIA score before on forget set: 0.84\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 79.1%\n",
            "Test set accuracy FORGET model: 69.5%\n",
            "Forget set accuracy FORGET model: 64.4%\n",
            "\n",
            "The MIA has an accuracy of 0.848 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 94.0\n",
            "MIA score before on forget set: 0.96\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 78.8%\n",
            "Test set accuracy FORGET model: 69.6%\n",
            "Forget set accuracy FORGET model: 76.0%\n",
            "\n",
            "The MIA has an accuracy of 0.912 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 88.0\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 78.6%\n",
            "Test set accuracy FORGET model: 69.0%\n",
            "Forget set accuracy FORGET model: 64.8%\n",
            "\n",
            "The MIA has an accuracy of 0.828 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 94.39999999999999\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 79.3%\n",
            "Test set accuracy FORGET model: 69.6%\n",
            "Forget set accuracy FORGET model: 84.0%\n",
            "\n",
            "The MIA has an accuracy of 0.864 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 96.8\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 79.2%\n",
            "Test set accuracy FORGET model: 69.0%\n",
            "Forget set accuracy FORGET model: 76.4%\n",
            "\n",
            "The MIA has an accuracy of 0.896 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 96.0\n",
            "MIA score before on forget set: 0.91\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 78.6%\n",
            "Test set accuracy FORGET model: 69.4%\n",
            "Forget set accuracy FORGET model: 89.2%\n",
            "\n",
            "The MIA has an accuracy of 0.880 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 95.6\n",
            "MIA score before on forget set: 0.91\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 78.7%\n",
            "Test set accuracy FORGET model: 68.7%\n",
            "Forget set accuracy FORGET model: 78.0%\n",
            "\n",
            "The MIA has an accuracy of 0.832 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfmr_CcA6Ix_",
        "outputId": "20709075-5a22-4a5c-c54c-eb60353af19c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.91, 0.94, 0.84, 0.8400000000000001, 0.96, 0.89, 0.89, 0.89, 0.9099999999999999, 0.9099999999999999]\n",
            "[0.86, 0.8960000000000001, 0.8320000000000001, 0.8480000000000001, 0.9120000000000001, 0.828, 0.8640000000000001, 0.8960000000000001, 0.8799999999999999, 0.8320000000000001]\n",
            "[94.8, 98.4, 89.60000000000001, 84.0, 94.0, 88.0, 94.39999999999999, 96.8, 96.0, 95.6]\n",
            "[78.37403276052657, 78.61722439955783, 78.20966315620227, 79.13468108195009, 78.7828848202263, 78.55448808136029, 79.31588890228707, 79.1603022751025, 78.61894330673847, 78.66789934882226]\n",
            "[78.4, 88.0, 64.0, 64.4, 76.0, 64.8, 84.0, 76.4, 89.2, 78.0]\n",
            "[68.45, 67.88, 68.89, 69.45, 69.58, 68.97, 69.58, 68.97, 69.36, 68.71000000000001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean_mia_score_before_baseline = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_baseline = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_baseline = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_baseline = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_baseline = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_baseline = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "cY1zi71U6Jz2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(mean_mia_score_before_baseline)\n",
        "print(mean_mia_score_after_baseline)\n",
        "\n",
        "print(mean_accuracy_forget_before_baseline)\n",
        "\n",
        "print(mean_accuracy_forget_after_baseline)\n",
        "print(mean_accuracy_retain_baseline)\n",
        "print(mean_accuracy_test_baseline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ulUXg4d6KtQ",
        "outputId": "1bb0caee-dbc6-4301-bfed-8d505cb2c143"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.898\n",
            "0.8648000000000001\n",
            "93.16\n",
            "76.32000000000001\n",
            "78.74360081327737\n",
            "68.98400000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout"
      ],
      "metadata": {
        "id": "BjYB8GwR6TzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_model(model_train_reg):\n",
        "  from collections import OrderedDict\n",
        "\n",
        "  layer1 = model_train_reg.layer1\n",
        "\n",
        "  for indx in range(len(layer1)):\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer1[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer1[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "\n",
        "\n",
        "  layer2 = model_train_reg.layer2\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer2[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer2[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  layer3 = model_train_reg.layer3\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer3[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "    model_train_reg.layer3[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  layer4 = model_train_reg.layer4\n",
        "\n",
        "  for indx in [1]:\n",
        "    modified_layers = OrderedDict()\n",
        "    for name, feature in layer4[indx].named_children():\n",
        "      modified_layers[name] = feature\n",
        "      if isinstance(feature, nn.ReLU):\n",
        "        modified_layers[\"dropout\"] = nn.Dropout(p=0.3)\n",
        "\n",
        "    model_train_reg.layer4[indx] = nn.Sequential(modified_layers)\n",
        "\n",
        "  return model_train_reg"
      ],
      "metadata": {
        "id": "Kqtk2Q4d6Ldz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"----- 5 PERCENT DROPOUT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Dropout\"\n",
        "model_params = \"cifar10_resnet18_l2_dropout_regularization.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  model_forget_ft = modify_model(model_forget_ft)\n",
        "\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  model_ft_forget.eval()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrqz9mRK6TB0",
        "outputId": "7b1989d3-6cfc-4822-9b54-aa7a73a62d88"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT DROPOUT -------\n",
            "Model name: Resnet18 Dropout\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 86.4\n",
            "MIA score before on forget set: 0.88\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 73.3%\n",
            "Test set accuracy FORGET model: 70.8%\n",
            "Forget set accuracy FORGET model: 76.0%\n",
            "\n",
            "The MIA has an accuracy of 0.908 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 85.2\n",
            "MIA score before on forget set: 0.95\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 73.8%\n",
            "Test set accuracy FORGET model: 71.0%\n",
            "Forget set accuracy FORGET model: 80.8%\n",
            "\n",
            "The MIA has an accuracy of 0.944 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 67.60000000000001\n",
            "MIA score before on forget set: 0.85\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 73.2%\n",
            "Test set accuracy FORGET model: 70.6%\n",
            "Forget set accuracy FORGET model: 52.0%\n",
            "\n",
            "The MIA has an accuracy of 0.888 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 57.199999999999996\n",
            "MIA score before on forget set: 0.88\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 73.9%\n",
            "Test set accuracy FORGET model: 71.5%\n",
            "Forget set accuracy FORGET model: 51.6%\n",
            "\n",
            "The MIA has an accuracy of 0.888 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 74.4\n",
            "MIA score before on forget set: 0.91\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 73.3%\n",
            "Test set accuracy FORGET model: 70.7%\n",
            "Forget set accuracy FORGET model: 72.4%\n",
            "\n",
            "The MIA has an accuracy of 0.872 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 69.19999999999999\n",
            "MIA score before on forget set: 0.88\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 73.5%\n",
            "Test set accuracy FORGET model: 70.7%\n",
            "Forget set accuracy FORGET model: 71.2%\n",
            "\n",
            "The MIA has an accuracy of 0.824 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 80.80000000000001\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 73.5%\n",
            "Test set accuracy FORGET model: 70.3%\n",
            "Forget set accuracy FORGET model: 78.4%\n",
            "\n",
            "The MIA has an accuracy of 0.848 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 80.80000000000001\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 72.9%\n",
            "Test set accuracy FORGET model: 70.0%\n",
            "Forget set accuracy FORGET model: 71.2%\n",
            "\n",
            "The MIA has an accuracy of 0.880 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 88.0\n",
            "MIA score before on forget set: 0.88\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 72.9%\n",
            "Test set accuracy FORGET model: 70.5%\n",
            "Forget set accuracy FORGET model: 84.0%\n",
            "\n",
            "The MIA has an accuracy of 0.900 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 89.60000000000001\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 73.3%\n",
            "Test set accuracy FORGET model: 71.0%\n",
            "Forget set accuracy FORGET model: 86.4%\n",
            "\n",
            "The MIA has an accuracy of 0.940 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghSeP2nl6XBN",
        "outputId": "28528d23-0693-46f2-aa63-9e76b9a1510b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.88, 0.95, 0.85, 0.88, 0.91, 0.88, 0.89, 0.89, 0.88, 0.9]\n",
            "[0.908, 0.944, 0.8880000000000001, 0.8879999999999999, 0.8720000000000001, 0.8240000000000001, 0.8480000000000001, 0.8800000000000001, 0.9, 0.9399999999999998]\n",
            "[86.4, 85.2, 67.60000000000001, 57.199999999999996, 74.4, 69.19999999999999, 80.80000000000001, 80.80000000000001, 88.0, 89.60000000000001]\n",
            "[73.33896056915471, 73.84933874663344, 73.21916706866055, 73.94083125653188, 73.29715606471711, 73.50576791671692, 73.45700102498141, 72.90230520328798, 72.8621098538899, 73.30586816720258]\n",
            "[76.0, 80.80000000000001, 52.0, 51.6, 72.39999999999999, 71.2, 78.4, 71.2, 84.0, 86.4]\n",
            "[70.76, 71.02000000000001, 70.6, 71.45, 70.7, 70.67999999999999, 70.28999999999999, 70.02000000000001, 70.54, 71.03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mean_mia_score_before_dropout = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_dropout = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_dropout = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_dropout = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_dropout = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_dropout = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "5ck0J6J36Xya"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(mean_mia_score_before_dropout)\n",
        "print(mean_mia_score_after_dropout)\n",
        "\n",
        "print(mean_accuracy_forget_before_dropout)\n",
        "\n",
        "print(mean_accuracy_forget_after_dropout)\n",
        "print(mean_accuracy_retain_dropout)\n",
        "print(mean_accuracy_test_dropout)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzcO749z6YeR",
        "outputId": "e2a83460-de90-44c4-9d18-3af3220921f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8910000000000002\n",
            "0.8892000000000001\n",
            "77.92000000000002\n",
            "72.4\n",
            "73.36785058717764\n",
            "70.70899999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation model"
      ],
      "metadata": {
        "id": "2ozdO1H26dkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CIFAR 10 dataset\n",
        "torch.manual_seed(1991)\n",
        "# Transformations\n",
        "normalize = transforms.Compose(\n",
        "    [\n",
        "         transforms.RandomRotation(30), # Randomly rotate some images by 20 degrees\n",
        "         transforms.RandomHorizontalFlip(), # Randomly horizontal flip the images\n",
        "         transforms.ColorJitter(brightness = 0.1, # Randomly adjust color jitter of the images\n",
        "                                                            contrast = 0.1,\n",
        "                                                            saturation = 0.1),\n",
        "         transforms.RandomAdjustSharpness(sharpness_factor = 2,\n",
        "                                                                      p = 0.1), # Randomly adjust sharpness\n",
        "          transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "to_tensor_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# Train data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=normalize\n",
        ")\n",
        "# Train loader\n",
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# Test data\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=to_tensor_transform\n",
        ")\n",
        "# Test loader\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5Cf97MK6ZJT",
        "outputId": "87064257-2c7c-43bf-98fa-5fa622e40376"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"----- 5 PERCENT -------\")\n",
        "# Generalisation algorithm\n",
        "# Calculating score across 10 different classes\n",
        "# Model parameters\n",
        "model_name = \"Resnet18 Augmentation\"\n",
        "model_params = \"cifar10_resnet18_augmentation.pt\"\n",
        "\n",
        "# Percantage of class to forget\n",
        "amount = 0.05\n",
        "\n",
        "# Show different classes\n",
        "classes = np.unique(np.array(train_set.targets))\n",
        "\n",
        "# mia scores\n",
        "MIA_scores_before = []\n",
        "MIA_scores = []\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_forget_before = []\n",
        "\n",
        "Accuracy_retain = []\n",
        "Accuracy_forget = []\n",
        "Accuracy_test = []\n",
        "\n",
        "\n",
        "print(f\"Model name: {model_name}\")\n",
        "print(f\"Amount: {100 * amount}\")\n",
        "\n",
        "for class_num in classes:\n",
        "  print(f\"------ UNLEARNING CLASS {class_num} ------\\n\")\n",
        "  # Define model from trained params\n",
        "\n",
        "  model_forget_ft = resnet18(weights=None, num_classes=10) # Load resnet18 from pytorch\n",
        "  model_forget_ft.load_state_dict(torch.load(model_params))\n",
        "  model_forget_ft.eval()\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "\n",
        "  # --- FORMING DATASET ------\n",
        "  # Choose random forget indecies from some class\n",
        "  # Index of class\n",
        "  class_index = class_num # cars\n",
        "  class_set = np.where(np.array(train_set.targets) == class_num)[0]\n",
        "\n",
        "  # Percantage of whole data ( from class )\n",
        "  amount_int = class_set.shape[0] * amount\n",
        "\n",
        "  # Get indeces\n",
        "  forget_idx = np.random.choice(class_set, int(amount_int))\n",
        "\n",
        "  # construct indices of retain from those of the forget set\n",
        "  forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
        "  forget_mask[forget_idx] = True\n",
        "  retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "  # split train set into a forget and a retain set\n",
        "  forget_set = torch.utils.data.Subset(train_set, forget_idx)\n",
        "  retain_set = torch.utils.data.Subset(train_set, retain_idx)\n",
        "\n",
        "  # Generate forget and retain loaders\n",
        "  forget_loader = torch.utils.data.DataLoader(\n",
        "      forget_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  retain_loader = torch.utils.data.DataLoader(\n",
        "      retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
        "  )\n",
        "  # ---------\n",
        "\n",
        "  # --- EVALUATING MODEL BEFORE ----\n",
        "  accuracy_forget = 100.0 * accuracy(model_forget_ft, forget_loader)\n",
        "  Accuracy_forget_before.append(accuracy_forget)\n",
        "  print(f\"Accuracy before on forget set: {accuracy_forget}\")\n",
        "\n",
        "  mia_attack = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 2)\n",
        "  MIA_scores_before.append(mia_attack)\n",
        "  print(f\"MIA score before on forget set: {np.round(mia_attack, 3)}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_forget_ft = model_forget_ft.to(DEVICE)\n",
        "  # --------------\n",
        "\n",
        "  # Unlearn\n",
        "  model_ft_forget = unlearning(model_forget_ft, retain_loader, forget_loader, test_loader)\n",
        "\n",
        "  # Compare accuracy\n",
        "  print(f\"Retain set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, retain_loader):0.1f}%\")\n",
        "  print(f\"Test set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, test_loader):0.1f}%\")\n",
        "  print(f\"Forget set accuracy FORGET model: {100.0 * accuracy(model_ft_forget, forget_loader):0.1f}%\")\n",
        "\n",
        "  Accuracy_retain.append(100.0 * accuracy(model_ft_forget, retain_loader))\n",
        "  Accuracy_forget.append(100.0 * accuracy(model_ft_forget, forget_loader))\n",
        "  Accuracy_test.append(100.0 * accuracy(model_ft_forget, test_loader))\n",
        "  print()\n",
        "  model_forget_ft.eval()\n",
        "  mia_scores_fr = train_mia_on_class(model_forget_ft, class_num, forget_set, test_set, True, 5)\n",
        "  MIA_scores.append(mia_scores_fr)\n",
        "  print(\n",
        "      f\"The MIA has an accuracy of {mia_scores_fr:.3f} on forgotten vs unseen images on FORGET model\"\n",
        "  )\n",
        "  print()\n",
        "  print('-' * 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivlx9cJX6fkF",
        "outputId": "7f143418-64b8-4711-803e-da23d1d37a18"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 5 PERCENT -------\n",
            "Model name: Resnet18 Augmentation\n",
            "Amount: 5.0\n",
            "------ UNLEARNING CLASS 0 ------\n",
            "\n",
            "Accuracy before on forget set: 79.60000000000001\n",
            "MIA score before on forget set: 0.9\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 68.5%\n",
            "Test set accuracy FORGET model: 71.7%\n",
            "Forget set accuracy FORGET model: 72.0%\n",
            "\n",
            "The MIA has an accuracy of 0.848 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 1 ------\n",
            "\n",
            "Accuracy before on forget set: 85.2\n",
            "MIA score before on forget set: 0.92\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 68.9%\n",
            "Test set accuracy FORGET model: 71.8%\n",
            "Forget set accuracy FORGET model: 83.2%\n",
            "\n",
            "The MIA has an accuracy of 0.924 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 2 ------\n",
            "\n",
            "Accuracy before on forget set: 65.60000000000001\n",
            "MIA score before on forget set: 0.78\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 68.2%\n",
            "Test set accuracy FORGET model: 71.9%\n",
            "Forget set accuracy FORGET model: 57.2%\n",
            "\n",
            "The MIA has an accuracy of 0.848 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 3 ------\n",
            "\n",
            "Accuracy before on forget set: 59.599999999999994\n",
            "MIA score before on forget set: 0.82\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 68.1%\n",
            "Test set accuracy FORGET model: 71.6%\n",
            "Forget set accuracy FORGET model: 50.0%\n",
            "\n",
            "The MIA has an accuracy of 0.860 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 4 ------\n",
            "\n",
            "Accuracy before on forget set: 80.80000000000001\n",
            "MIA score before on forget set: 0.86\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 69.1%\n",
            "Test set accuracy FORGET model: 72.5%\n",
            "Forget set accuracy FORGET model: 69.6%\n",
            "\n",
            "The MIA has an accuracy of 0.872 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 5 ------\n",
            "\n",
            "Accuracy before on forget set: 66.8\n",
            "MIA score before on forget set: 0.89\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 69.1%\n",
            "Test set accuracy FORGET model: 72.2%\n",
            "Forget set accuracy FORGET model: 54.0%\n",
            "\n",
            "The MIA has an accuracy of 0.868 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 6 ------\n",
            "\n",
            "Accuracy before on forget set: 81.6\n",
            "MIA score before on forget set: 0.92\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 68.8%\n",
            "Test set accuracy FORGET model: 71.6%\n",
            "Forget set accuracy FORGET model: 75.2%\n",
            "\n",
            "The MIA has an accuracy of 0.888 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 7 ------\n",
            "\n",
            "Accuracy before on forget set: 81.6\n",
            "MIA score before on forget set: 0.86\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 68.3%\n",
            "Test set accuracy FORGET model: 72.0%\n",
            "Forget set accuracy FORGET model: 76.8%\n",
            "\n",
            "The MIA has an accuracy of 0.884 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 8 ------\n",
            "\n",
            "Accuracy before on forget set: 88.8\n",
            "MIA score before on forget set: 0.95\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 68.5%\n",
            "Test set accuracy FORGET model: 71.2%\n",
            "Forget set accuracy FORGET model: 84.0%\n",
            "\n",
            "The MIA has an accuracy of 0.908 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n",
            "------ UNLEARNING CLASS 9 ------\n",
            "\n",
            "Accuracy before on forget set: 79.2\n",
            "MIA score before on forget set: 0.83\n",
            "\n",
            "\n",
            "Apply Unstructured re_init_model_snip_ver2_little_grad Globally (all conv layers)\n",
            "Retain set accuracy FORGET model: 68.5%\n",
            "Test set accuracy FORGET model: 71.2%\n",
            "Forget set accuracy FORGET model: 70.8%\n",
            "\n",
            "The MIA has an accuracy of 0.860 on forgotten vs unseen images on FORGET model\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mia scores\n",
        "print(MIA_scores_before)\n",
        "print(MIA_scores)\n",
        "\n",
        "# Accuracy\n",
        "print(Accuracy_forget_before)\n",
        "\n",
        "print(Accuracy_retain)\n",
        "print(Accuracy_forget)\n",
        "print(Accuracy_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC6F9yx86gof",
        "outputId": "99b3b4ef-59d9-4403-8ffb-e1217cc55ea1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8999999999999999, 0.9199999999999999, 0.78, 0.8200000000000001, 0.86, 0.8899999999999999, 0.9199999999999999, 0.86, 0.95, 0.8300000000000001]\n",
            "[0.8480000000000001, 0.924, 0.8480000000000001, 0.86, 0.8720000000000001, 0.868, 0.8880000000000001, 0.884, 0.908, 0.86]\n",
            "[79.60000000000001, 85.2, 65.60000000000001, 59.599999999999994, 80.80000000000001, 66.8, 81.6, 81.6, 88.8, 79.2]\n",
            "[68.80853800699441, 68.87687422116815, 68.36023072130556, 68.36086659431649, 68.90639760416457, 69.00335631167474, 68.78956570670633, 68.30807573260441, 68.25837051328429, 68.56924653817553]\n",
            "[74.4, 80.80000000000001, 58.4, 44.4, 64.8, 54.0, 73.2, 71.2, 82.39999999999999, 70.0]\n",
            "[71.67999999999999, 71.76, 71.86, 71.61, 72.53, 72.23, 71.57, 72.0, 71.22, 71.22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mean_mia_score_before_aug = np.mean(np.array(MIA_scores_before))\n",
        "mean_mia_score_after_aug = np.mean(np.array(MIA_scores))\n",
        "\n",
        "mean_accuracy_forget_before_aug = np.mean(np.array(Accuracy_forget_before))\n",
        "\n",
        "mean_accuracy_forget_after_aug = np.mean(np.array(Accuracy_forget))\n",
        "mean_accuracy_retain_aug = np.mean(np.array(Accuracy_retain))\n",
        "mean_accuracy_test_aug = np.mean(np.array(Accuracy_test))"
      ],
      "metadata": {
        "id": "ZxsNXhhS6hVl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(mean_mia_score_before_aug)\n",
        "print(mean_mia_score_after_aug)\n",
        "\n",
        "print(mean_accuracy_forget_before_aug)\n",
        "\n",
        "print(mean_accuracy_forget_after_aug)\n",
        "print(mean_accuracy_retain_aug)\n",
        "print(mean_accuracy_test_aug)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPsmiZ_w6iCD",
        "outputId": "248b247b-8e07-40c8-aa9a-6ce5c84661af"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.873\n",
            "0.8760000000000001\n",
            "76.88\n",
            "67.36\n",
            "68.62415219503944\n",
            "71.768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2Gf5vk56jA5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}